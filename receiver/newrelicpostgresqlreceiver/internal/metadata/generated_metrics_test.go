// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"testing"

	"github.com/stretchr/testify/assert"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver/receivertest"
	"go.uber.org/zap"
	"go.uber.org/zap/zaptest/observer"
)

type testDataSet int

const (
	testDataSetDefault testDataSet = iota
	testDataSetAll
	testDataSetNone
)

func TestMetricsBuilder(t *testing.T) {
	tests := []struct {
		name        string
		metricsSet  testDataSet
		resAttrsSet testDataSet
		expectEmpty bool
	}{
		{
			name: "default",
		},
		{
			name:        "all_set",
			metricsSet:  testDataSetAll,
			resAttrsSet: testDataSetAll,
		},
		{
			name:        "none_set",
			metricsSet:  testDataSetNone,
			resAttrsSet: testDataSetNone,
			expectEmpty: true,
		},
		{
			name:        "filter_set_include",
			resAttrsSet: testDataSetAll,
		},
		{
			name:        "filter_set_exclude",
			resAttrsSet: testDataSetAll,
			expectEmpty: true,
		},
	}
	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			start := pcommon.Timestamp(1_000_000_000)
			ts := pcommon.Timestamp(1_000_001_000)
			observedZapCore, observedLogs := observer.New(zap.WarnLevel)
			settings := receivertest.NewNopSettings(receivertest.NopType)
			settings.Logger = zap.New(observedZapCore)
			mb := NewMetricsBuilder(loadMetricsBuilderConfig(t, tt.name), settings, WithStartTime(start))

			expectedWarnings := 0

			assert.Equal(t, expectedWarnings, observedLogs.Len())

			defaultMetricsCount := 0
			allMetricsCount := 0

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBackendsDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBgwriterBuffersAllocatedDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBgwriterBuffersWritesDataPoint(ts, 1, AttributeBgBufferSourceBackend)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBgwriterCheckpointCountDataPoint(ts, 1, AttributeBgCheckpointTypeRequested)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBgwriterDurationDataPoint(ts, 1, AttributeBgDurationTypeSync)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBgwriterMaxwrittenDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBlksHitDataPoint(ts, 1, "postgresql.database.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBlksReadDataPoint(ts, 1, "postgresql.database.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBlockedSessionPidDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.text-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBlockingSessionDurationDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.blocked.query.text-val", "postgresql.blocking.query.text-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBlockingSessionPidDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.text-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBlockingSessionWaitEventDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.blocked.query.text-val", "postgresql.blocking.query.text-val", "postgresql.wait.event-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBlockingSessionWaitEventTypeDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.blocked.query.text-val", "postgresql.blocking.query.text-val", "postgresql.wait.event.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBlocksHitDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.table.name-val", AttributeSourceHeapRead)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBlocksReadDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.table.name-val", AttributeSourceHeapRead)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlCommitsDataPoint(ts, 1, "postgresql.database.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlConnectionCountDataPoint(ts, 1, "postgresql.database.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlConnectionMaxDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlDatabaseCountDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlDatabaseLocksDataPoint(ts, 1, "postgresql.database.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlDbSizeDataPoint(ts, 1, "postgresql.database.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlDeadlocksDataPoint(ts, 1, "postgresql.database.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlExecutionPlanActualLoopsDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.node.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlExecutionPlanActualRowsDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.node.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlExecutionPlanActualTotalTimeDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.node.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlExecutionPlanAsyncCapableDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.node.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlExecutionPlanCostActualDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.node.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlExecutionPlanCostEstimateDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.node.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlExecutionPlanIoReadTimeDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.node.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlExecutionPlanIoWriteTimeDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.node.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlExecutionPlanParallelAwareDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.node.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlExecutionPlanPlanRowsDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.node.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlExecutionPlanPlanWidthDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.node.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlExecutionPlanSharedHitBlocksDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.node.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlExecutionPlanSharedReadBlocksDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.node.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlExecutionPlanSharedWrittenBlocksDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.node.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlExecutionPlanStartupTimeDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.node.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlExecutionPlanTempReadBlocksDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.node.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlExecutionPlanTempWrittenBlocksDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.node.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlIndexScansDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.schema.name-val", "postgresql.table.name-val", "postgresql.index.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlIndexSizeDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.schema.name-val", "postgresql.table.name-val", "postgresql.index.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlOperationsDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.table.name-val", AttributeOperationIns)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlQueryAvgDiskReadsDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.schema.name-val", "postgresql.query.id-val", "postgresql.query.text-val", "postgresql.statement.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlQueryAvgDiskWritesDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.schema.name-val", "postgresql.query.id-val", "postgresql.query.text-val", "postgresql.statement.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlQueryAvgElapsedTimeDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.schema.name-val", "postgresql.query.id-val", "postgresql.query.text-val", "postgresql.statement.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlQueryCPUTimeDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.schema.name-val", "postgresql.query.id-val", "postgresql.query.text-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlQueryExecutionCountDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.schema.name-val", "postgresql.query.id-val", "postgresql.query.text-val", "postgresql.statement.type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationDataDelayDataPoint(ts, 1, "replication_client-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRollbacksDataPoint(ts, 1, "postgresql.database.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRowsDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.table.name-val", AttributeStateDead)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSequentialScansDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.schema.name-val", "postgresql.table.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlTableCountDataPoint(ts, 1, "postgresql.database.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlTableScansDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.schema.name-val", "postgresql.table.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlTableSizeDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.schema.name-val", "postgresql.table.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlTableVacuumCountDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.schema.name-val", "postgresql.table.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlTempFilesDataPoint(ts, 1, "postgresql.database.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlTupDeletedDataPoint(ts, 1, "postgresql.database.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlTupFetchedDataPoint(ts, 1, "postgresql.database.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlTupInsertedDataPoint(ts, 1, "postgresql.database.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlTupReturnedDataPoint(ts, 1, "postgresql.database.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlTupUpdatedDataPoint(ts, 1, "postgresql.database.name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWaitEventTotalTimeDataPoint(ts, 1, "postgresql.database.name-val", "postgresql.query.id-val", "postgresql.query.text-val", "postgresql.wait.event.name-val", "postgresql.wait.category-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalAgeDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalDelayDataPoint(ts, 1, "replication_client-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalLagDataPoint(ts, 1)

			rb := mb.NewResourceBuilder()
			rb.SetPostgresqlDatabaseName("postgresql.database.name-val")
			rb.SetPostgresqlIndexName("postgresql.index.name-val")
			rb.SetPostgresqlSchemaName("postgresql.schema.name-val")
			rb.SetPostgresqlTableName("postgresql.table.name-val")
			res := rb.Emit()
			metrics := mb.Emit(WithResource(res))

			if tt.expectEmpty {
				assert.Equal(t, 0, metrics.ResourceMetrics().Len())
				return
			}

			assert.Equal(t, 1, metrics.ResourceMetrics().Len())
			rm := metrics.ResourceMetrics().At(0)
			assert.Equal(t, res, rm.Resource())
			assert.Equal(t, 1, rm.ScopeMetrics().Len())
			ms := rm.ScopeMetrics().At(0).Metrics()
			if tt.metricsSet == testDataSetDefault {
				assert.Equal(t, defaultMetricsCount, ms.Len())
			}
			if tt.metricsSet == testDataSetAll {
				assert.Equal(t, allMetricsCount, ms.Len())
			}
			validatedMetrics := make(map[string]bool)
			for i := 0; i < ms.Len(); i++ {
				switch ms.At(i).Name() {
				case "postgresql.backends":
					assert.False(t, validatedMetrics["postgresql.backends"], "Found a duplicate in the metrics slice: postgresql.backends")
					validatedMetrics["postgresql.backends"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "The number of backends.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.False(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "postgresql.bgwriter.buffers.allocated":
					assert.False(t, validatedMetrics["postgresql.bgwriter.buffers.allocated"], "Found a duplicate in the metrics slice: postgresql.bgwriter.buffers.allocated")
					validatedMetrics["postgresql.bgwriter.buffers.allocated"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of buffers allocated.", ms.At(i).Description())
					assert.Equal(t, "{buffers}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "postgresql.bgwriter.buffers.writes":
					assert.False(t, validatedMetrics["postgresql.bgwriter.buffers.writes"], "Found a duplicate in the metrics slice: postgresql.bgwriter.buffers.writes")
					validatedMetrics["postgresql.bgwriter.buffers.writes"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of buffers written.", ms.At(i).Description())
					assert.Equal(t, "{buffers}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("source")
					assert.True(t, ok)
					assert.Equal(t, "backend", attrVal.Str())
				case "postgresql.bgwriter.checkpoint.count":
					assert.False(t, validatedMetrics["postgresql.bgwriter.checkpoint.count"], "Found a duplicate in the metrics slice: postgresql.bgwriter.checkpoint.count")
					validatedMetrics["postgresql.bgwriter.checkpoint.count"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "The number of checkpoints performed.", ms.At(i).Description())
					assert.Equal(t, "{checkpoints}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("type")
					assert.True(t, ok)
					assert.Equal(t, "requested", attrVal.Str())
				case "postgresql.bgwriter.duration":
					assert.False(t, validatedMetrics["postgresql.bgwriter.duration"], "Found a duplicate in the metrics slice: postgresql.bgwriter.duration")
					validatedMetrics["postgresql.bgwriter.duration"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total time spent writing and syncing files to disk by checkpoints.", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("type")
					assert.True(t, ok)
					assert.Equal(t, "sync", attrVal.Str())
				case "postgresql.bgwriter.maxwritten":
					assert.False(t, validatedMetrics["postgresql.bgwriter.maxwritten"], "Found a duplicate in the metrics slice: postgresql.bgwriter.maxwritten")
					validatedMetrics["postgresql.bgwriter.maxwritten"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times the background writer stopped a cleaning scan because it had written too many buffers.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "postgresql.blks_hit":
					assert.False(t, validatedMetrics["postgresql.blks_hit"], "Found a duplicate in the metrics slice: postgresql.blks_hit")
					validatedMetrics["postgresql.blks_hit"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times disk blocks were found already in the buffer cache.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
				case "postgresql.blks_read":
					assert.False(t, validatedMetrics["postgresql.blks_read"], "Found a duplicate in the metrics slice: postgresql.blks_read")
					validatedMetrics["postgresql.blks_read"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of disk blocks read in this database.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
				case "postgresql.blocked.session.pid":
					assert.False(t, validatedMetrics["postgresql.blocked.session.pid"], "Found a duplicate in the metrics slice: postgresql.blocked.session.pid")
					validatedMetrics["postgresql.blocked.session.pid"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Process ID of the blocked session.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.text")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.text-val", attrVal.Str())
				case "postgresql.blocking.session.duration":
					assert.False(t, validatedMetrics["postgresql.blocking.session.duration"], "Found a duplicate in the metrics slice: postgresql.blocking.session.duration")
					validatedMetrics["postgresql.blocking.session.duration"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Duration for which the session has been blocking.", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.blocked.query.text")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.blocked.query.text-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.blocking.query.text")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.blocking.query.text-val", attrVal.Str())
				case "postgresql.blocking.session.pid":
					assert.False(t, validatedMetrics["postgresql.blocking.session.pid"], "Found a duplicate in the metrics slice: postgresql.blocking.session.pid")
					validatedMetrics["postgresql.blocking.session.pid"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Process ID of the blocking session.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.text")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.text-val", attrVal.Str())
				case "postgresql.blocking.session.wait_event":
					assert.False(t, validatedMetrics["postgresql.blocking.session.wait_event"], "Found a duplicate in the metrics slice: postgresql.blocking.session.wait_event")
					validatedMetrics["postgresql.blocking.session.wait_event"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Wait event for the blocking session.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.blocked.query.text")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.blocked.query.text-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.blocking.query.text")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.blocking.query.text-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.wait.event")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.wait.event-val", attrVal.Str())
				case "postgresql.blocking.session.wait_event_type":
					assert.False(t, validatedMetrics["postgresql.blocking.session.wait_event_type"], "Found a duplicate in the metrics slice: postgresql.blocking.session.wait_event_type")
					validatedMetrics["postgresql.blocking.session.wait_event_type"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Wait event type for the blocking session.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.blocked.query.text")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.blocked.query.text-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.blocking.query.text")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.blocking.query.text-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.wait.event.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.wait.event.type-val", attrVal.Str())
				case "postgresql.blocks_hit":
					assert.False(t, validatedMetrics["postgresql.blocks_hit"], "Found a duplicate in the metrics slice: postgresql.blocks_hit")
					validatedMetrics["postgresql.blocks_hit"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "The number of blocks found in the buffer cache.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.table.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.table.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("source")
					assert.True(t, ok)
					assert.Equal(t, "heap_read", attrVal.Str())
				case "postgresql.blocks_read":
					assert.False(t, validatedMetrics["postgresql.blocks_read"], "Found a duplicate in the metrics slice: postgresql.blocks_read")
					validatedMetrics["postgresql.blocks_read"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "The number of blocks read.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.table.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.table.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("source")
					assert.True(t, ok)
					assert.Equal(t, "heap_read", attrVal.Str())
				case "postgresql.commits":
					assert.False(t, validatedMetrics["postgresql.commits"], "Found a duplicate in the metrics slice: postgresql.commits")
					validatedMetrics["postgresql.commits"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "The number of commits.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
				case "postgresql.connection.count":
					assert.False(t, validatedMetrics["postgresql.connection.count"], "Found a duplicate in the metrics slice: postgresql.connection.count")
					validatedMetrics["postgresql.connection.count"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of user connections.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.False(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityUnspecified, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
				case "postgresql.connection.max":
					assert.False(t, validatedMetrics["postgresql.connection.max"], "Found a duplicate in the metrics slice: postgresql.connection.max")
					validatedMetrics["postgresql.connection.max"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Maximum number of client connections allowed.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "postgresql.database.count":
					assert.False(t, validatedMetrics["postgresql.database.count"], "Found a duplicate in the metrics slice: postgresql.database.count")
					validatedMetrics["postgresql.database.count"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of user databases.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.False(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityUnspecified, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "postgresql.database.locks":
					assert.False(t, validatedMetrics["postgresql.database.locks"], "Found a duplicate in the metrics slice: postgresql.database.locks")
					validatedMetrics["postgresql.database.locks"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "The number of database locks.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.False(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityUnspecified, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
				case "postgresql.db_size":
					assert.False(t, validatedMetrics["postgresql.db_size"], "Found a duplicate in the metrics slice: postgresql.db_size")
					validatedMetrics["postgresql.db_size"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "The database disk usage.", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					assert.False(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
				case "postgresql.deadlocks":
					assert.False(t, validatedMetrics["postgresql.deadlocks"], "Found a duplicate in the metrics slice: postgresql.deadlocks")
					validatedMetrics["postgresql.deadlocks"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of deadlocks detected in this database.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
				case "postgresql.execution_plan.actual_loops":
					assert.False(t, validatedMetrics["postgresql.execution_plan.actual_loops"], "Found a duplicate in the metrics slice: postgresql.execution_plan.actual_loops")
					validatedMetrics["postgresql.execution_plan.actual_loops"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of times the execution plan node was executed.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.node.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.node.type-val", attrVal.Str())
				case "postgresql.execution_plan.actual_rows":
					assert.False(t, validatedMetrics["postgresql.execution_plan.actual_rows"], "Found a duplicate in the metrics slice: postgresql.execution_plan.actual_rows")
					validatedMetrics["postgresql.execution_plan.actual_rows"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Actual number of rows processed by the execution plan node.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.node.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.node.type-val", attrVal.Str())
				case "postgresql.execution_plan.actual_total_time":
					assert.False(t, validatedMetrics["postgresql.execution_plan.actual_total_time"], "Found a duplicate in the metrics slice: postgresql.execution_plan.actual_total_time")
					validatedMetrics["postgresql.execution_plan.actual_total_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total time spent in the execution plan node in milliseconds.", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.node.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.node.type-val", attrVal.Str())
				case "postgresql.execution_plan.async_capable":
					assert.False(t, validatedMetrics["postgresql.execution_plan.async_capable"], "Found a duplicate in the metrics slice: postgresql.execution_plan.async_capable")
					validatedMetrics["postgresql.execution_plan.async_capable"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Whether the execution plan node is async capable.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.node.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.node.type-val", attrVal.Str())
				case "postgresql.execution_plan.cost_actual":
					assert.False(t, validatedMetrics["postgresql.execution_plan.cost_actual"], "Found a duplicate in the metrics slice: postgresql.execution_plan.cost_actual")
					validatedMetrics["postgresql.execution_plan.cost_actual"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Actual cost of the execution plan node.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.node.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.node.type-val", attrVal.Str())
				case "postgresql.execution_plan.cost_estimate":
					assert.False(t, validatedMetrics["postgresql.execution_plan.cost_estimate"], "Found a duplicate in the metrics slice: postgresql.execution_plan.cost_estimate")
					validatedMetrics["postgresql.execution_plan.cost_estimate"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Estimated cost of the execution plan node.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.node.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.node.type-val", attrVal.Str())
				case "postgresql.execution_plan.io_read_time":
					assert.False(t, validatedMetrics["postgresql.execution_plan.io_read_time"], "Found a duplicate in the metrics slice: postgresql.execution_plan.io_read_time")
					validatedMetrics["postgresql.execution_plan.io_read_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time spent reading blocks from disk in milliseconds.", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.node.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.node.type-val", attrVal.Str())
				case "postgresql.execution_plan.io_write_time":
					assert.False(t, validatedMetrics["postgresql.execution_plan.io_write_time"], "Found a duplicate in the metrics slice: postgresql.execution_plan.io_write_time")
					validatedMetrics["postgresql.execution_plan.io_write_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time spent writing blocks to disk in milliseconds.", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.node.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.node.type-val", attrVal.Str())
				case "postgresql.execution_plan.parallel_aware":
					assert.False(t, validatedMetrics["postgresql.execution_plan.parallel_aware"], "Found a duplicate in the metrics slice: postgresql.execution_plan.parallel_aware")
					validatedMetrics["postgresql.execution_plan.parallel_aware"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Whether the execution plan node is parallel aware.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.node.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.node.type-val", attrVal.Str())
				case "postgresql.execution_plan.plan_rows":
					assert.False(t, validatedMetrics["postgresql.execution_plan.plan_rows"], "Found a duplicate in the metrics slice: postgresql.execution_plan.plan_rows")
					validatedMetrics["postgresql.execution_plan.plan_rows"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Estimated number of rows to be processed by the execution plan node.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.node.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.node.type-val", attrVal.Str())
				case "postgresql.execution_plan.plan_width":
					assert.False(t, validatedMetrics["postgresql.execution_plan.plan_width"], "Found a duplicate in the metrics slice: postgresql.execution_plan.plan_width")
					validatedMetrics["postgresql.execution_plan.plan_width"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Estimated width of rows to be processed by the execution plan node.", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.node.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.node.type-val", attrVal.Str())
				case "postgresql.execution_plan.shared_hit_blocks":
					assert.False(t, validatedMetrics["postgresql.execution_plan.shared_hit_blocks"], "Found a duplicate in the metrics slice: postgresql.execution_plan.shared_hit_blocks")
					validatedMetrics["postgresql.execution_plan.shared_hit_blocks"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of shared blocks hit from cache.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.node.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.node.type-val", attrVal.Str())
				case "postgresql.execution_plan.shared_read_blocks":
					assert.False(t, validatedMetrics["postgresql.execution_plan.shared_read_blocks"], "Found a duplicate in the metrics slice: postgresql.execution_plan.shared_read_blocks")
					validatedMetrics["postgresql.execution_plan.shared_read_blocks"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of shared blocks read from disk.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.node.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.node.type-val", attrVal.Str())
				case "postgresql.execution_plan.shared_written_blocks":
					assert.False(t, validatedMetrics["postgresql.execution_plan.shared_written_blocks"], "Found a duplicate in the metrics slice: postgresql.execution_plan.shared_written_blocks")
					validatedMetrics["postgresql.execution_plan.shared_written_blocks"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of shared blocks written to disk.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.node.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.node.type-val", attrVal.Str())
				case "postgresql.execution_plan.startup_time":
					assert.False(t, validatedMetrics["postgresql.execution_plan.startup_time"], "Found a duplicate in the metrics slice: postgresql.execution_plan.startup_time")
					validatedMetrics["postgresql.execution_plan.startup_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time taken to start the execution plan node in milliseconds.", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.node.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.node.type-val", attrVal.Str())
				case "postgresql.execution_plan.temp_read_blocks":
					assert.False(t, validatedMetrics["postgresql.execution_plan.temp_read_blocks"], "Found a duplicate in the metrics slice: postgresql.execution_plan.temp_read_blocks")
					validatedMetrics["postgresql.execution_plan.temp_read_blocks"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of temporary blocks read from disk.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.node.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.node.type-val", attrVal.Str())
				case "postgresql.execution_plan.temp_written_blocks":
					assert.False(t, validatedMetrics["postgresql.execution_plan.temp_written_blocks"], "Found a duplicate in the metrics slice: postgresql.execution_plan.temp_written_blocks")
					validatedMetrics["postgresql.execution_plan.temp_written_blocks"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of temporary blocks written to disk.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.node.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.node.type-val", attrVal.Str())
				case "postgresql.index.scans":
					assert.False(t, validatedMetrics["postgresql.index.scans"], "Found a duplicate in the metrics slice: postgresql.index.scans")
					validatedMetrics["postgresql.index.scans"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "The number of index scans on a table.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.schema.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.schema.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.table.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.table.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.index.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.index.name-val", attrVal.Str())
				case "postgresql.index.size":
					assert.False(t, validatedMetrics["postgresql.index.size"], "Found a duplicate in the metrics slice: postgresql.index.size")
					validatedMetrics["postgresql.index.size"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "The size of the index on disk.", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					assert.False(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityUnspecified, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.schema.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.schema.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.table.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.table.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.index.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.index.name-val", attrVal.Str())
				case "postgresql.operations":
					assert.False(t, validatedMetrics["postgresql.operations"], "Found a duplicate in the metrics slice: postgresql.operations")
					validatedMetrics["postgresql.operations"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "The number of database operations.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.table.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.table.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("operation")
					assert.True(t, ok)
					assert.Equal(t, "ins", attrVal.Str())
				case "postgresql.query.avg_disk_reads":
					assert.False(t, validatedMetrics["postgresql.query.avg_disk_reads"], "Found a duplicate in the metrics slice: postgresql.query.avg_disk_reads")
					validatedMetrics["postgresql.query.avg_disk_reads"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Average number of disk reads per query execution.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.schema.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.schema.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.text")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.text-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.statement.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.statement.type-val", attrVal.Str())
				case "postgresql.query.avg_disk_writes":
					assert.False(t, validatedMetrics["postgresql.query.avg_disk_writes"], "Found a duplicate in the metrics slice: postgresql.query.avg_disk_writes")
					validatedMetrics["postgresql.query.avg_disk_writes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Average number of disk writes per query execution.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.schema.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.schema.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.text")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.text-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.statement.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.statement.type-val", attrVal.Str())
				case "postgresql.query.avg_elapsed_time":
					assert.False(t, validatedMetrics["postgresql.query.avg_elapsed_time"], "Found a duplicate in the metrics slice: postgresql.query.avg_elapsed_time")
					validatedMetrics["postgresql.query.avg_elapsed_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Average execution time for the query in milliseconds.", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.schema.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.schema.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.text")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.text-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.statement.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.statement.type-val", attrVal.Str())
				case "postgresql.query.cpu_time":
					assert.False(t, validatedMetrics["postgresql.query.cpu_time"], "Found a duplicate in the metrics slice: postgresql.query.cpu_time")
					validatedMetrics["postgresql.query.cpu_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "CPU time consumed by the query in milliseconds.", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.schema.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.schema.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.text")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.text-val", attrVal.Str())
				case "postgresql.query.execution.count":
					assert.False(t, validatedMetrics["postgresql.query.execution.count"], "Found a duplicate in the metrics slice: postgresql.query.execution.count")
					validatedMetrics["postgresql.query.execution.count"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times the query was executed.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.schema.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.schema.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.text")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.text-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.statement.type")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.statement.type-val", attrVal.Str())
				case "postgresql.replication.data_delay":
					assert.False(t, validatedMetrics["postgresql.replication.data_delay"], "Found a duplicate in the metrics slice: postgresql.replication.data_delay")
					validatedMetrics["postgresql.replication.data_delay"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "The amount of data delayed in replication.", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("replication_client")
					assert.True(t, ok)
					assert.Equal(t, "replication_client-val", attrVal.Str())
				case "postgresql.rollbacks":
					assert.False(t, validatedMetrics["postgresql.rollbacks"], "Found a duplicate in the metrics slice: postgresql.rollbacks")
					validatedMetrics["postgresql.rollbacks"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "The number of rollbacks.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
				case "postgresql.rows":
					assert.False(t, validatedMetrics["postgresql.rows"], "Found a duplicate in the metrics slice: postgresql.rows")
					validatedMetrics["postgresql.rows"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "The number of rows.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.table.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.table.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "dead", attrVal.Str())
				case "postgresql.sequential_scans":
					assert.False(t, validatedMetrics["postgresql.sequential_scans"], "Found a duplicate in the metrics slice: postgresql.sequential_scans")
					validatedMetrics["postgresql.sequential_scans"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of sequential scans initiated on this table.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.schema.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.schema.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.table.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.table.name-val", attrVal.Str())
				case "postgresql.table.count":
					assert.False(t, validatedMetrics["postgresql.table.count"], "Found a duplicate in the metrics slice: postgresql.table.count")
					validatedMetrics["postgresql.table.count"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of user tables in a database.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.False(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
				case "postgresql.table.scans":
					assert.False(t, validatedMetrics["postgresql.table.scans"], "Found a duplicate in the metrics slice: postgresql.table.scans")
					validatedMetrics["postgresql.table.scans"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "The number of sequential scans on a table.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.schema.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.schema.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.table.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.table.name-val", attrVal.Str())
				case "postgresql.table.size":
					assert.False(t, validatedMetrics["postgresql.table.size"], "Found a duplicate in the metrics slice: postgresql.table.size")
					validatedMetrics["postgresql.table.size"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Disk space used by a table.", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					assert.False(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityUnspecified, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.schema.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.schema.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.table.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.table.name-val", attrVal.Str())
				case "postgresql.table.vacuum.count":
					assert.False(t, validatedMetrics["postgresql.table.vacuum.count"], "Found a duplicate in the metrics slice: postgresql.table.vacuum.count")
					validatedMetrics["postgresql.table.vacuum.count"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times a table has been manually vacuumed.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.schema.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.schema.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.table.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.table.name-val", attrVal.Str())
				case "postgresql.temp_files":
					assert.False(t, validatedMetrics["postgresql.temp_files"], "Found a duplicate in the metrics slice: postgresql.temp_files")
					validatedMetrics["postgresql.temp_files"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of temporary files created by queries in this database.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
				case "postgresql.tup_deleted":
					assert.False(t, validatedMetrics["postgresql.tup_deleted"], "Found a duplicate in the metrics slice: postgresql.tup_deleted")
					validatedMetrics["postgresql.tup_deleted"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of rows deleted by queries in this database.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
				case "postgresql.tup_fetched":
					assert.False(t, validatedMetrics["postgresql.tup_fetched"], "Found a duplicate in the metrics slice: postgresql.tup_fetched")
					validatedMetrics["postgresql.tup_fetched"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of rows fetched by queries in this database.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
				case "postgresql.tup_inserted":
					assert.False(t, validatedMetrics["postgresql.tup_inserted"], "Found a duplicate in the metrics slice: postgresql.tup_inserted")
					validatedMetrics["postgresql.tup_inserted"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of rows inserted by queries in this database.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
				case "postgresql.tup_returned":
					assert.False(t, validatedMetrics["postgresql.tup_returned"], "Found a duplicate in the metrics slice: postgresql.tup_returned")
					validatedMetrics["postgresql.tup_returned"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of rows returned by queries in this database.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
				case "postgresql.tup_updated":
					assert.False(t, validatedMetrics["postgresql.tup_updated"], "Found a duplicate in the metrics slice: postgresql.tup_updated")
					validatedMetrics["postgresql.tup_updated"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of rows updated by queries in this database.", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
				case "postgresql.wait.event.total_time":
					assert.False(t, validatedMetrics["postgresql.wait.event.total_time"], "Found a duplicate in the metrics slice: postgresql.wait.event.total_time")
					validatedMetrics["postgresql.wait.event.total_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total wait time for the wait event in milliseconds.", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("postgresql.database.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.database.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.id")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.id-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.query.text")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.query.text-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.wait.event.name")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.wait.event.name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("postgresql.wait.category")
					assert.True(t, ok)
					assert.Equal(t, "postgresql.wait.category-val", attrVal.Str())
				case "postgresql.wal.age":
					assert.False(t, validatedMetrics["postgresql.wal.age"], "Found a duplicate in the metrics slice: postgresql.wal.age")
					validatedMetrics["postgresql.wal.age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Age of the oldest WAL file.", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "postgresql.wal.delay":
					assert.False(t, validatedMetrics["postgresql.wal.delay"], "Found a duplicate in the metrics slice: postgresql.wal.delay")
					validatedMetrics["postgresql.wal.delay"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time between flushing recent WAL locally and receiving notification that the standby server has completed an operation with it.", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("replication_client")
					assert.True(t, ok)
					assert.Equal(t, "replication_client-val", attrVal.Str())
				case "postgresql.wal.lag":
					assert.False(t, validatedMetrics["postgresql.wal.lag"], "Found a duplicate in the metrics slice: postgresql.wal.lag")
					validatedMetrics["postgresql.wal.lag"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time between flushing recent WAL locally and receiving notification that the standby server has completed an operation with it.", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				}
			}
		})
	}
}
