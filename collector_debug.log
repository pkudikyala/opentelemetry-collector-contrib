2025-07-10T14:49:41.711+0530	info	service@v0.129.1-0.20250707130321-ac9adbf016bf/service.go:197	Setting up own telemetry...	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}}
2025-07-10T14:49:41.712+0530	debug	builders/builders.go:24	Alpha component. May change in the future.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "file", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:41.712+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:41.712+0530	info	builders/builders.go:26	Development component. May change in the future.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "logs"}
2025-07-10T14:49:41.712+0530	debug	builders/builders.go:24	Alpha component. May change in the future.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "file", "otelcol.component.kind": "exporter", "otelcol.signal": "logs"}
2025-07-10T14:49:41.712+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "logs"}
2025-07-10T14:49:41.712+0530	debug	builders/builders.go:24	Beta component. May change in the future.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "batch", "otelcol.component.kind": "processor", "otelcol.pipeline.id": "logs", "otelcol.signal": "logs"}
2025-07-10T14:49:41.712+0530	info	builders/builders.go:26	Development component. May change in the future.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "traces"}
2025-07-10T14:49:41.712+0530	debug	builders/builders.go:24	Alpha component. May change in the future.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "file", "otelcol.component.kind": "exporter", "otelcol.signal": "traces"}
2025-07-10T14:49:41.712+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "traces"}
2025-07-10T14:49:41.712+0530	debug	builders/builders.go:24	Beta component. May change in the future.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "batch", "otelcol.component.kind": "processor", "otelcol.pipeline.id": "traces", "otelcol.signal": "traces"}
2025-07-10T14:49:41.712+0530	info	builders/builders.go:26	Development component. May change in the future.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "logs"}
2025-07-10T14:49:41.712+0530	debug	builders/builders.go:24	Beta component. May change in the future.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:41.712+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "traces"}
2025-07-10T14:49:41.712+0530	debug	Logger core does not support injecting component attributes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "traces"}
2025-07-10T14:49:41.712+0530	debug	otlpreceiver@v0.129.1-0.20250707130321-ac9adbf016bf/otlp.go:58	created signal-agnostic logger	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "traces"}
2025-07-10T14:49:41.712+0530	info	builders/builders.go:26	Development component. May change in the future.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:41.712+0530	debug	builders/builders.go:24	Beta component. May change in the future.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "batch", "otelcol.component.kind": "processor", "otelcol.pipeline.id": "metrics", "otelcol.signal": "metrics"}
2025-07-10T14:49:41.712+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:49:41.712+0530	debug	builders/builders.go:24	Beta component. May change in the future.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:49:41.712+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "logs"}
2025-07-10T14:49:41.712+0530	info	service@v0.129.1-0.20250707130321-ac9adbf016bf/service.go:257	Starting otelcontribcol...	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "Version": "0.129.0-dev", "NumCPU": 12}
2025-07-10T14:49:41.712+0530	info	extensions/extensions.go:41	Starting extensions...	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}}
2025-07-10T14:49:41.713+0530	info	grpc@v1.73.0/clientconn.go:176	[core] original dial target is: "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.713+0530	info	grpc@v1.73.0/clientconn.go:459	[core] [Channel #1]Channel created	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.713+0530	info	grpc@v1.73.0/clientconn.go:207	[core] [Channel #1]parsed dial target is: resolver.Target{URL:url.URL{Scheme:"passthrough", Opaque:"", User:(*url.Userinfo)(nil), Host:"", Path:"/otlp.nr-data.net:4317", RawPath:"", OmitHost:false, ForceQuery:false, RawQuery:"", Fragment:"", RawFragment:""}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.713+0530	info	grpc@v1.73.0/clientconn.go:208	[core] [Channel #1]Channel authority set to "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.713+0530	info	grpc@v1.73.0/resolver_wrapper.go:210	[core] [Channel #1]Resolver state updated: {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
} (resolver returned new addresses)	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.713+0530	info	grpc@v1.73.0/balancer_wrapper.go:122	[core] [Channel #1]Channel switches to new LB policy "pick_first"	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.713+0530	info	gracefulswitch/gracefulswitch.go:194	[pick-first-leaf-lb] [pick-first-leaf-lb 0x140017a0120] Received new config {
  "shuffleAddressList": false
}, resolver state {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #1]Channel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/balancer_wrapper.go:195	[core] [Channel #1 SubChannel #2]Subchannel created	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:364	[core] [Channel #1]Channel exiting idle mode	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #1 SubChannel #2]Subchannel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:1352	[core] [Channel #1 SubChannel #2]Subchannel picks a new address "otlp.nr-data.net:4317" to connect	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:176	[core] original dial target is: "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:459	[core] [Channel #3]Channel created	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:207	[core] [Channel #3]parsed dial target is: resolver.Target{URL:url.URL{Scheme:"passthrough", Opaque:"", User:(*url.Userinfo)(nil), Host:"", Path:"/otlp.nr-data.net:4317", RawPath:"", OmitHost:false, ForceQuery:false, RawQuery:"", Fragment:"", RawFragment:""}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:208	[core] [Channel #3]Channel authority set to "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/resolver_wrapper.go:210	[core] [Channel #3]Resolver state updated: {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
} (resolver returned new addresses)	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/balancer_wrapper.go:122	[core] [Channel #3]Channel switches to new LB policy "pick_first"	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	gracefulswitch/gracefulswitch.go:194	[pick-first-leaf-lb] [pick-first-leaf-lb 0x14000eefc20] Received new config {
  "shuffleAddressList": false
}, resolver state {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/balancer_wrapper.go:195	[core] [Channel #3 SubChannel #4]Subchannel created	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:364	[core] [Channel #3]Channel exiting idle mode	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:1352	[core] [Channel #3 SubChannel #4]Subchannel picks a new address "otlp.nr-data.net:4317" to connect	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/server.go:690	[core] [Server #5]Server created	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	otlpreceiver@v0.129.1-0.20250707130321-ac9adbf016bf/otlp.go:117	Starting GRPC server	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "traces", "endpoint": "0.0.0.0:4317"}
2025-07-10T14:49:41.714+0530	info	otlpreceiver@v0.129.1-0.20250707130321-ac9adbf016bf/otlp.go:175	Starting HTTP server	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "traces", "endpoint": "0.0.0.0:4318"}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:176	[core] original dial target is: "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:459	[core] [Channel #7]Channel created	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:207	[core] [Channel #7]parsed dial target is: resolver.Target{URL:url.URL{Scheme:"passthrough", Opaque:"", User:(*url.Userinfo)(nil), Host:"", Path:"/otlp.nr-data.net:4317", RawPath:"", OmitHost:false, ForceQuery:false, RawQuery:"", Fragment:"", RawFragment:""}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/server.go:886	[core] [Server #5 ListenSocket #6]ListenSocket created	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:208	[core] [Channel #7]Channel authority set to "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/resolver_wrapper.go:210	[core] [Channel #7]Resolver state updated: {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
} (resolver returned new addresses)	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/balancer_wrapper.go:122	[core] [Channel #7]Channel switches to new LB policy "pick_first"	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	gracefulswitch/gracefulswitch.go:194	[pick-first-leaf-lb] [pick-first-leaf-lb 0x140019ee3f0] Received new config {
  "shuffleAddressList": false
}, resolver state {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #7]Channel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/balancer_wrapper.go:195	[core] [Channel #7 SubChannel #8]Subchannel created	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:364	[core] [Channel #7]Channel exiting idle mode	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #7 SubChannel #8]Subchannel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.714+0530	info	grpc@v1.73.0/clientconn.go:1352	[core] [Channel #7 SubChannel #8]Subchannel picks a new address "otlp.nr-data.net:4317" to connect	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.715+0530	info	newrelicpostgresqlreceiver@v0.129.0/factory.go:154	Starting New Relic PostgreSQL logs receiver	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "logs"}
2025-07-10T14:49:41.715+0530	info	service@v0.129.1-0.20250707130321-ac9adbf016bf/service.go:280	Everything is ready. Begin running and processing data.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}}
2025-07-10T14:49:41.814+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #7 SubChannel #8]Subchannel Connectivity change to READY	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.814+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to READY	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.814+0530	info	pickfirstleaf/pickfirstleaf.go:197	[pick-first-leaf-lb] [pick-first-leaf-lb 0x140019ee3f0] SubConn 0x1400177f310 reported connectivity state READY and the health listener is disabled. Transitioning SubConn to READY.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.814+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #7]Channel Connectivity change to READY	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.814+0530	info	pickfirstleaf/pickfirstleaf.go:197	[pick-first-leaf-lb] [pick-first-leaf-lb 0x14000eefc20] SubConn 0x1400177eeb0 reported connectivity state READY and the health listener is disabled. Transitioning SubConn to READY.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.814+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to READY	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.820+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #1 SubChannel #2]Subchannel Connectivity change to READY	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.820+0530	info	pickfirstleaf/pickfirstleaf.go:197	[pick-first-leaf-lb] [pick-first-leaf-lb 0x140017a0120] SubConn 0x14000fa6190 reported connectivity state READY and the health listener is disabled. Transitioning SubConn to READY.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:41.820+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #1]Channel Connectivity change to READY	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:49:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:49:42.762+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:49:42.762+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:49:42.762+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:49:42.762+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:49:42.762+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:49:42.762+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:49:42.762+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:49:42.762+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:49:42.762+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:49:42.762+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:49:42.762+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:49:42.762+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:49:42.770+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database": "testdb"}
2025-07-10T14:49:42.773+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:556	Recording execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "database": "testdb", "query_id": "2194329260438961401", "node_type": "ProjectSet"}
2025-07-10T14:49:42.773+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:556	Recording execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "database": "testdb", "query_id": "2194329260438961401", "node_type": "Result"}
2025-07-10T14:49:42.773+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:527	Successfully recorded execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "plan_id": "plan_2194329260438961401_1752139182"}
2025-07-10T14:49:42.773+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:49:42.773+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:49:42.773+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database": "testdb"}
2025-07-10T14:49:42.774+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:556	Recording execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "database": "testdb", "query_id": "-3404018605099167039", "node_type": "Function Scan"}
2025-07-10T14:49:42.774+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:527	Successfully recorded execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "plan_id": "plan_-3404018605099167039_1752139182"}
2025-07-10T14:49:42.774+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database": "testdb"}
2025-07-10T14:49:42.775+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:556	Recording execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "database": "testdb", "query_id": "440101247839410938", "node_type": "Result"}
2025-07-10T14:49:42.775+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:527	Successfully recorded execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "plan_id": "plan_440101247839410938_1752139182"}
2025-07-10T14:49:42.775+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database": "testdb"}
2025-07-10T14:49:42.776+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:556	Recording execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "database": "testdb", "query_id": "2947340716630300180", "node_type": "ModifyTable"}
2025-07-10T14:49:42.776+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:556	Recording execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "database": "testdb", "query_id": "2947340716630300180", "node_type": "Index Scan"}
2025-07-10T14:49:42.776+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:527	Successfully recorded execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "plan_id": "plan_2947340716630300180_1752139182"}
2025-07-10T14:49:42.776+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:49:42.777+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:49:42.777+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:49:42.777+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:49:42.777+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:49:42.778+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:49:42.778+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database": "testdb"}
2025-07-10T14:49:42.779+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:556	Recording execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "database": "testdb", "query_id": "2920803561901199087", "node_type": "Result"}
2025-07-10T14:49:42.779+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:527	Successfully recorded execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "plan_id": "plan_2920803561901199087_1752139182"}
2025-07-10T14:49:42.779+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:49:42.779+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:49:42.779+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:49:42.920+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:42.920+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:42.920+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:42.920+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:42.920+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.execution_plan.async_capable	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:42.920+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.execution_plan.cost_estimate	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:42.920+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.execution_plan.parallel_aware	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:42.920+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.execution_plan.plan_rows	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:42.920+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.execution_plan.plan_width	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:42.920+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.execution_plan.startup_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:42.920+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:42.920+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:42.920+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:42.920+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:42.920+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:42.920+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:49:42.920+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 16, "data points": 101}
2025-07-10T14:49:42.920+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.715526 +0000 UTC
Value: 21893
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.715526 +0000 UTC
Value: 39935
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.715526 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.715526 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.715526 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.715526 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.715526 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.715526 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.execution_plan.async_capable
     -> Description: Whether the execution plan node is async capable.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.node.type: Str(ProjectSet)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.node.type: Str(Function Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.node.type: Str(ModifyTable)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.node.type: Str(Index Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0
Metric #5
Descriptor:
     -> Name: postgresql.execution_plan.cost_estimate
     -> Description: Estimated cost of the execution plan node.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.node.type: Str(ProjectSet)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 5.020000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0.010000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.node.type: Str(Function Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0.010000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0.010000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.node.type: Str(ModifyTable)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 8.170000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.node.type: Str(Index Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 8.170000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0.010000
Metric #6
Descriptor:
     -> Name: postgresql.execution_plan.parallel_aware
     -> Description: Whether the execution plan node is parallel aware.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.node.type: Str(ProjectSet)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.node.type: Str(Function Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.node.type: Str(ModifyTable)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.node.type: Str(Index Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0
Metric #7
Descriptor:
     -> Name: postgresql.execution_plan.plan_rows
     -> Description: Estimated number of rows to be processed by the execution plan node.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.node.type: Str(ProjectSet)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 1000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.node.type: Str(Function Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.node.type: Str(ModifyTable)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.node.type: Str(Index Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 1
Metric #8
Descriptor:
     -> Name: postgresql.execution_plan.plan_width
     -> Description: Estimated width of rows to be processed by the execution plan node.
     -> Unit: By
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.node.type: Str(ProjectSet)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 4
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.node.type: Str(Function Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 4
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 4
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.node.type: Str(ModifyTable)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.node.type: Str(Index Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 10
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 4
Metric #9
Descriptor:
     -> Name: postgresql.execution_plan.startup_time
     -> Description: Time taken to start the execution plan node in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.node.type: Str(ProjectSet)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.node.type: Str(Function Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.node.type: Str(ModifyTable)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0.150000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.node.type: Str(Index Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0.150000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.node.type: Str(Result)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770223 +0000 UTC
Value: 0.000000
Metric #10
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 43.000000
Metric #11
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 6.000000
Metric #12
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 11.230000
Metric #13
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.770193 +0000 UTC
Value: 0.000000
Metric #14
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.762505 +0000 UTC
Value: 1
Metric #15
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.715526 +0000 UTC
Value: 2303
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:19:42.715526 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:12.735+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:50:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:50:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:50:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:50:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:50:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:50:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:50:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:50:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:50:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:50:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:50:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:50:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:50:12.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:50:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:50:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:50:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:50:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:50:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:50:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:50:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:50:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:50:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:50:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:50:12.864+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:12.864+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:12.864+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:12.864+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:12.864+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:12.864+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:12.864+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:12.864+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:12.864+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:12.864+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:12.865+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:50:12.865+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.712158 +0000 UTC
Value: 21914
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.712158 +0000 UTC
Value: 39942
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.712158 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.712158 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.712158 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.712158 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.712158 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.712158 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.744874 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.741297 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.712158 +0000 UTC
Value: 2308
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:12.712158 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:50:42.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:50:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:50:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:50:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:50:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:50:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:50:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:50:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:50:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:50:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:50:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:50:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:50:42.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:50:42.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:50:42.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:50:42.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:50:42.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:50:42.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:50:42.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:50:42.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:50:42.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:50:42.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:50:42.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:50:42.813+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:42.813+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:42.813+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:42.813+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:42.813+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:42.813+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:42.813+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:42.814+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:42.814+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:42.814+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:42.814+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:50:42.814+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.710724 +0000 UTC
Value: 21929
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.710724 +0000 UTC
Value: 39947
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.710724 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.710724 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.710724 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.710724 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.710724 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.710724 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.755068 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.750982 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.710724 +0000 UTC
Value: 2313
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:20:42.710724 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.367+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:50:48.368+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:12.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:51:12.759+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:51:12.759+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:51:12.759+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:51:12.759+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:51:12.759+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:51:12.759+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:51:12.760+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:51:12.760+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:51:12.760+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:51:12.760+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:51:12.760+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:51:12.760+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:51:12.766+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:51:12.766+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:51:12.766+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:51:12.767+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:51:12.767+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:51:12.767+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:51:12.767+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:51:12.767+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:51:12.768+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:51:12.768+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:51:12.768+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:51:12.956+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:12.956+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:12.956+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:12.956+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:12.956+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:12.956+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:12.956+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:12.956+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:12.956+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:12.956+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:12.956+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:51:12.957+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.710262 +0000 UTC
Value: 21942
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.710262 +0000 UTC
Value: 39954
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.710262 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.710262 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.710262 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.710262 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.710262 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.710262 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.766482 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.759737 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.710262 +0000 UTC
Value: 2318
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:12.710262 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:42.736+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:51:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:51:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:51:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:51:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:51:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:51:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:51:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:51:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:51:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:51:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:51:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:51:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:51:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:51:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:51:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:51:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:51:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:51:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:51:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:51:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:51:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:51:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:51:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:51:42.901+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:42.901+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:42.901+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:42.901+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:42.901+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:42.901+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:42.901+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:42.901+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:42.901+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:42.901+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:51:42.901+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:51:42.901+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.709817 +0000 UTC
Value: 21957
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.709817 +0000 UTC
Value: 39959
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.709817 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.709817 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.709817 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.709817 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.709817 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.709817 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.747984 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.744104 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.709817 +0000 UTC
Value: 2323
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:21:42.709817 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:52:12.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:52:12.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:52:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:52:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:52:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:52:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:52:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:52:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:52:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:52:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:52:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:52:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:52:12.754+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:52:12.754+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:52:12.754+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:52:12.754+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:52:12.754+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:52:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:52:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:52:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:52:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:52:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:52:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:52:12.847+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:12.847+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:12.847+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:12.847+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:12.847+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:12.847+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:12.847+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:12.847+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:12.848+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:12.848+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:12.848+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:52:12.848+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.70953 +0000 UTC
Value: 21970
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.70953 +0000 UTC
Value: 39966
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.70953 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.70953 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.70953 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.70953 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.70953 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.70953 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.754017 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.749916 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.70953 +0000 UTC
Value: 2328
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:12.70953 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:42.733+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:52:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:52:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:52:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:52:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:52:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:52:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:52:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:52:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:52:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:52:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:52:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:52:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:52:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:52:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:52:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:52:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:52:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:52:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:52:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:52:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:52:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:52:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:52:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:52:42.787+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:42.787+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:42.787+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:42.787+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:42.787+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:42.787+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:42.787+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:42.787+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:42.787+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:42.787+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:52:42.787+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:52:42.787+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.709116 +0000 UTC
Value: 21985
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.709116 +0000 UTC
Value: 39971
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.709116 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.709116 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.709116 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.709116 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.709116 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.709116 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.742067 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.738652 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.709116 +0000 UTC
Value: 2333
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:22:42.709116 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:53:12.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:53:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:53:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:53:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:53:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:53:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:53:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:53:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:53:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:53:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:53:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:53:12.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:53:12.754+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:53:12.754+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:53:12.754+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:53:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:53:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:53:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:53:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:53:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:53:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:53:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:53:12.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:53:12.936+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:12.936+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:12.936+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:12.936+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:12.936+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:12.936+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:12.936+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:12.936+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:12.936+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:12.936+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:12.936+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:53:12.937+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.708841 +0000 UTC
Value: 21999
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.708841 +0000 UTC
Value: 39978
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.708841 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.708841 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.708841 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.708841 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.708841 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.708841 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.754385 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.750013 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.708841 +0000 UTC
Value: 2339
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:12.708841 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:42.735+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:53:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:53:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:53:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:53:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:53:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:53:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:53:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:53:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:53:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:53:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:53:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:53:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:53:42.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:53:42.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:53:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:53:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:53:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:53:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:53:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:53:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:53:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:53:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:53:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:53:42.881+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:42.881+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:42.882+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:42.882+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:42.882+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:42.882+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:42.882+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:42.882+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:42.882+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:42.882+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:53:42.882+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:53:42.883+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.708582 +0000 UTC
Value: 22020
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.708582 +0000 UTC
Value: 39983
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.708582 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.708582 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.708582 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.708582 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.708582 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.708582 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.747555 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.74359 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.708582 +0000 UTC
Value: 2346
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:23:42.708582 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:12.735+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:54:12.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:54:12.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:54:12.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:54:12.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:54:12.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:54:12.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:54:12.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:54:12.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:54:12.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:54:12.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:54:12.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:54:12.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:54:12.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:54:12.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:54:12.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:54:12.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:54:12.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:54:12.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:54:12.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:54:12.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:54:12.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:54:12.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:54:12.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:54:12.826+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:12.826+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:12.826+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:12.826+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:12.826+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:12.826+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:12.826+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:12.826+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:12.826+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:12.827+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:12.827+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:54:12.827+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.708238 +0000 UTC
Value: 22038
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.708238 +0000 UTC
Value: 39990
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.708238 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.708238 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.708238 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.708238 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.708238 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.708238 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.748038 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.742954 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.708238 +0000 UTC
Value: 2352
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:12.708238 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:42.736+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:54:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:54:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:54:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:54:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:54:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:54:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:54:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:54:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:54:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:54:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:54:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:54:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:54:42.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:54:42.757+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:54:42.757+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:54:42.758+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:54:42.758+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:54:42.759+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:54:42.759+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:54:42.759+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:54:42.759+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:54:42.759+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:54:42.759+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:54:42.771+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:42.771+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:42.771+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:42.771+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:42.771+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:42.771+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:42.771+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:42.771+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:42.771+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:42.771+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:54:42.771+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:54:42.771+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.707769 +0000 UTC
Value: 22061
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.707769 +0000 UTC
Value: 39995
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.707769 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.707769 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.707769 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.707769 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.707769 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.707769 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.756913 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.74469 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.707769 +0000 UTC
Value: 2357
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:24:42.707769 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:12.737+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:55:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:55:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:55:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:55:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:55:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:55:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:55:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:55:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:55:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:55:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:55:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:55:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:55:12.753+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:55:12.754+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:55:12.754+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:55:12.754+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:55:12.754+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:55:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:55:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:55:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:55:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:55:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:55:12.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:55:12.911+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:12.911+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:12.911+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:12.911+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:12.911+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:12.912+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:12.912+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:12.912+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:12.912+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:12.912+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:12.912+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:55:12.912+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.707474 +0000 UTC
Value: 22076
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.707474 +0000 UTC
Value: 40002
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.707474 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.707474 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.707474 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.707474 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.707474 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.707474 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.753798 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.745635 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.707474 +0000 UTC
Value: 2362
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:12.707474 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:42.736+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:55:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:55:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:55:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:55:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:55:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:55:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:55:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:55:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:55:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:55:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:55:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:55:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:55:42.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:55:42.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:55:42.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:55:42.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:55:42.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:55:42.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:55:42.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:55:42.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:55:42.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:55:42.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:55:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:55:42.866+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:42.866+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:42.866+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:42.866+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:42.866+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:42.866+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:42.866+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:42.866+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:42.866+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:42.866+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:55:42.867+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:55:42.867+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.707154 +0000 UTC
Value: 22093
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.707154 +0000 UTC
Value: 40007
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.707154 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.707154 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.707154 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.707154 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.707154 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.707154 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.746807 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.743056 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.707154 +0000 UTC
Value: 2367
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:25:42.707154 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:12.737+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:56:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:56:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:56:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:56:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:56:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:56:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:56:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:56:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:56:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:56:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:56:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:56:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:56:12.754+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:56:12.754+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:56:12.754+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:56:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:56:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:56:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:56:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:56:12.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:56:12.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:56:12.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:56:12.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:56:12.822+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:12.823+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:12.823+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:12.823+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:12.823+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:12.823+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:12.823+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:12.823+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:12.823+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:12.823+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:12.823+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:56:12.824+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.706859 +0000 UTC
Value: 22106
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.706859 +0000 UTC
Value: 40014
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.706859 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.706859 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.706859 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.706859 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.706859 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.706859 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.754331 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.746509 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.706859 +0000 UTC
Value: 2372
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:12.706859 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:42.736+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:56:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:56:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:56:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:56:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:56:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:56:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:56:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:56:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:56:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:56:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:56:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:56:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:56:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:56:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:56:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:56:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:56:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:56:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:56:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:56:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:56:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:56:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:56:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:56:42.770+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:42.770+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:42.770+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:42.770+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:42.770+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:42.770+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:42.770+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:42.770+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:42.771+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:42.771+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:56:42.771+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:56:42.771+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.706478 +0000 UTC
Value: 22121
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.706478 +0000 UTC
Value: 40019
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.706478 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.706478 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.706478 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.706478 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.706478 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.706478 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.748448 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.744537 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.706478 +0000 UTC
Value: 2377
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:26:42.706478 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:12.733+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:57:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:57:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:57:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:57:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:57:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:57:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:57:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:57:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:57:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:57:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:57:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:57:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:57:12.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:57:12.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:57:12.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:57:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:57:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:57:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:57:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:57:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:57:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:57:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:57:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:57:12.919+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:12.919+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:12.919+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:12.919+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:12.919+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:12.919+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:12.919+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:12.919+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:12.919+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:12.919+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:12.919+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:57:12.920+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.706116 +0000 UTC
Value: 22134
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.706116 +0000 UTC
Value: 40026
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.706116 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.706116 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.706116 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.706116 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.706116 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.706116 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.74458 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.740603 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.706116 +0000 UTC
Value: 2382
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:12.706116 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:42.735+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:57:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:57:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:57:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:57:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:57:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:57:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:57:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:57:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:57:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:57:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:57:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:57:42.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:57:42.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:57:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:57:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:57:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:57:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:57:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:57:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:57:42.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:57:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:57:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:57:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:57:42.866+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:42.867+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:42.867+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:42.867+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:42.867+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:42.867+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:42.867+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:42.867+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:42.867+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:42.867+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:57:42.867+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:57:42.868+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.705788 +0000 UTC
Value: 22149
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.705788 +0000 UTC
Value: 40031
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.705788 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.705788 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.705788 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.705788 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.705788 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.705788 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.747937 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.744128 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.705788 +0000 UTC
Value: 2387
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:27:42.705788 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:12.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:58:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:58:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:58:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:58:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:58:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:58:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:58:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:58:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:58:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:58:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:58:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:58:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:58:12.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:58:12.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:58:12.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:58:12.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:58:12.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:58:12.752+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:58:12.752+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:58:12.752+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:58:12.752+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:58:12.752+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:58:12.752+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:58:12.810+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:12.810+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:12.811+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:12.811+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:12.811+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:12.811+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:12.811+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:12.811+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:12.811+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:12.811+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:12.811+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:58:12.812+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.705544 +0000 UTC
Value: 22162
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.705544 +0000 UTC
Value: 40038
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.705544 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.705544 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.705544 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.705544 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.705544 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.705544 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.751186 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.746982 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.705544 +0000 UTC
Value: 2392
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:12.705544 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:42.731+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:58:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:58:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:58:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:58:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:58:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:58:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:58:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:58:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:58:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:58:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:58:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:58:42.738+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:58:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:58:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:58:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:58:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:58:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:58:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:58:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:58:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:58:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:58:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:58:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:58:42.753+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:42.753+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:42.753+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:42.753+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:42.753+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:42.753+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:42.753+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:42.753+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:42.753+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:42.753+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:58:42.753+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:58:42.753+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.705096 +0000 UTC
Value: 22179
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.705096 +0000 UTC
Value: 40043
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.705096 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.705096 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.705096 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.705096 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.705096 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.705096 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.741703 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.738263 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.705096 +0000 UTC
Value: 2397
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:28:42.705096 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:12.732+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:59:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:59:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:59:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:59:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:59:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:59:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:59:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:59:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:59:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:59:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:59:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:59:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:59:12.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:59:12.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:59:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:59:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:59:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:59:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:59:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:59:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:59:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:59:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:59:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:59:12.903+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:12.903+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:12.903+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:12.903+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:12.903+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:12.903+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:12.904+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:12.904+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:12.904+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:12.904+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:12.904+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:59:12.904+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.704755 +0000 UTC
Value: 22192
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.704755 +0000 UTC
Value: 40050
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.704755 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.704755 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.704755 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.704755 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.704755 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.704755 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.744595 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.740573 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.704755 +0000 UTC
Value: 2402
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:12.704755 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:42.729+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:59:42.734+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:59:42.734+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:59:42.734+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:59:42.734+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:59:42.734+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:59:42.734+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T14:59:42.734+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:59:42.734+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:59:42.734+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:59:42.734+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:59:42.734+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:59:42.734+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 12}
2025-07-10T14:59:42.739+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T14:59:42.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T14:59:42.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T14:59:42.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:59:42.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T14:59:42.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T14:59:42.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T14:59:42.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T14:59:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:59:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T14:59:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:59:42.849+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:42.849+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:42.849+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:42.849+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:42.849+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:42.849+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:42.849+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:42.849+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:42.849+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:42.849+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:59:42.849+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 59}
2025-07-10T14:59:42.849+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.704397 +0000 UTC
Value: 22207
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.704397 +0000 UTC
Value: 40055
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.704397 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.704397 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.704397 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.704397 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.704397 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.704397 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 255.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 918.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 28.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 24.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 1514.063000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 144.601000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 143.521000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 94.970000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 67.739000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 44.676000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 13.782000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.73991 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 3
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.734619 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.704397 +0000 UTC
Value: 2407
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:29:42.704397 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.157+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.157+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.async_capable	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.plan_rows	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.parallel_aware	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.parallel_aware	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.startup_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.plan_width	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.cost_estimate	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.plan_rows	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.parallel_aware	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.startup_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.parallel_aware	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.startup_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.parallel_aware	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.plan_width	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.plan_rows	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.parallel_aware	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.plan_rows	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.async_capable	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.async_capable	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.startup_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.plan_rows	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.plan_width	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.cost_estimate	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.startup_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.plan_width	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.parallel_aware	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.plan_rows	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.cost_estimate	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.async_capable	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.startup_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.plan_width	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.async_capable	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.cost_estimate	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.startup_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.cost_estimate	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.async_capable	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.cost_estimate	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.plan_rows	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.async_capable	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.cost_estimate	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.plan_width	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.plan_width	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.158+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.159+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:07.160+0530	debug	prometheusexporter@v0.129.0/collector.go:479	metric expired	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "instrument": "postgresql_execution_plan_plan_rows_ratio"}
2025-07-10T15:00:07.160+0530	debug	prometheusexporter@v0.129.0/collector.go:479	metric expired	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "instrument": "postgresql_execution_plan_startup_time_milliseconds"}
2025-07-10T15:00:07.160+0530	debug	prometheusexporter@v0.129.0/collector.go:479	metric expired	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "instrument": "postgresql_execution_plan_async_capable_ratio"}
2025-07-10T15:00:07.160+0530	debug	prometheusexporter@v0.129.0/collector.go:479	metric expired	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "instrument": "postgresql_execution_plan_cost_estimate_ratio"}
2025-07-10T15:00:07.160+0530	debug	prometheusexporter@v0.129.0/collector.go:479	metric expired	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "instrument": "postgresql_execution_plan_parallel_aware_ratio"}
2025-07-10T15:00:07.160+0530	debug	prometheusexporter@v0.129.0/collector.go:479	metric expired	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "instrument": "postgresql_execution_plan_plan_width_bytes"}
2025-07-10T15:00:12.733+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T15:00:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T15:00:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T15:00:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T15:00:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T15:00:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T15:00:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "4536804317005561087", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 2007.928}
2025-07-10T15:00:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T15:00:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T15:00:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T15:00:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T15:00:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T15:00:12.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 13}
2025-07-10T15:00:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T15:00:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T15:00:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T15:00:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T15:00:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T15:00:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T15:00:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T15:00:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T15:00:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T15:00:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T15:00:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T15:00:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "4536804317005561087", "database": "testdb"}
2025-07-10T15:00:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:556	Recording execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "database": "testdb", "query_id": "4536804317005561087", "node_type": "Limit"}
2025-07-10T15:00:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:556	Recording execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "database": "testdb", "query_id": "4536804317005561087", "node_type": "Aggregate"}
2025-07-10T15:00:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:556	Recording execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "database": "testdb", "query_id": "4536804317005561087", "node_type": "Nested Loop"}
2025-07-10T15:00:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:556	Recording execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "database": "testdb", "query_id": "4536804317005561087", "node_type": "Seq Scan"}
2025-07-10T15:00:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:556	Recording execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "database": "testdb", "query_id": "4536804317005561087", "node_type": "Materialize"}
2025-07-10T15:00:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:556	Recording execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "database": "testdb", "query_id": "4536804317005561087", "node_type": "Seq Scan"}
2025-07-10T15:00:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:527	Successfully recorded execution plan metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "4536804317005561087", "plan_id": "plan_4536804317005561087_1752139812"}
2025-07-10T15:00:12.791+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:12.792+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:12.792+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:12.792+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:12.792+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.execution_plan.async_capable	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:12.792+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.execution_plan.cost_estimate	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:12.792+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.execution_plan.parallel_aware	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:12.792+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.execution_plan.plan_rows	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:12.792+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.execution_plan.plan_width	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:12.792+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.execution_plan.startup_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:12.792+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:12.792+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:12.792+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:12.792+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:12.792+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:12.793+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:12.793+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 16, "data points": 99}
2025-07-10T15:00:12.793+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.704155 +0000 UTC
Value: 22222
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.704155 +0000 UTC
Value: 40062
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.704155 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.704155 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.704155 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.704155 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.704155 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.704155 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.execution_plan.async_capable
     -> Description: Whether the execution plan node is async capable.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Limit)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Aggregate)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Nested Loop)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Seq Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Materialize)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Seq Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0
Metric #5
Descriptor:
     -> Name: postgresql.execution_plan.cost_estimate
     -> Description: Estimated cost of the execution plan node.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Limit)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 282.960000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Aggregate)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 282.960000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Nested Loop)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 240.450000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Seq Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 11.700000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Materialize)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 16.500000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Seq Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 16.000000
Metric #6
Descriptor:
     -> Name: postgresql.execution_plan.parallel_aware
     -> Description: Whether the execution plan node is parallel aware.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Limit)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Aggregate)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Nested Loop)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Seq Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Materialize)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Seq Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0
Metric #7
Descriptor:
     -> Name: postgresql.execution_plan.plan_rows
     -> Description: Estimated number of rows to be processed by the execution plan node.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Limit)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 1
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Aggregate)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Nested Loop)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 17000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Seq Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 170
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Materialize)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 100
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Seq Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 100
Metric #8
Descriptor:
     -> Name: postgresql.execution_plan.plan_width
     -> Description: Estimated width of rows to be processed by the execution plan node.
     -> Unit: By
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Limit)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 12
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Aggregate)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 12
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Nested Loop)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Seq Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Materialize)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Seq Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0
Metric #9
Descriptor:
     -> Name: postgresql.execution_plan.startup_time
     -> Description: Time taken to start the execution plan node in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Limit)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 282.950000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Aggregate)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 282.950000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Nested Loop)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Seq Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Materialize)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.node.type: Str(Seq Scan)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745393 +0000 UTC
Value: 0.000000
Metric #10
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 255.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 918.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 28.000000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 43.000000
Metric #11
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 24.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 0.000000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 6.000000
Metric #12
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 2007.928000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 1514.063000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 144.601000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 143.521000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 94.970000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 67.739000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 44.676000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 13.782000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 11.230000
Metric #13
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.745372 +0000 UTC
Value: 0.000000
Metric #14
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 3
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 1
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.741489 +0000 UTC
Value: 1
Metric #15
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.704155 +0000 UTC
Value: 2412
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:12.704155 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:42.733+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T15:00:42.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T15:00:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T15:00:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T15:00:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T15:00:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T15:00:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "4536804317005561087", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 2007.928}
2025-07-10T15:00:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T15:00:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T15:00:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T15:00:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T15:00:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T15:00:42.743+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 13}
2025-07-10T15:00:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T15:00:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T15:00:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T15:00:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T15:00:42.749+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T15:00:42.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T15:00:42.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T15:00:42.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T15:00:42.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T15:00:42.750+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T15:00:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T15:00:42.934+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:42.934+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:42.934+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:42.934+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:42.934+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:42.934+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:42.934+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:42.934+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:42.934+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:42.934+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:42.934+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 63}
2025-07-10T15:00:42.934+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.703737 +0000 UTC
Value: 22238
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.703737 +0000 UTC
Value: 40067
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.703737 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.703737 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.703737 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.703737 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.703737 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.703737 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 255.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 918.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 28.000000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 24.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 0.000000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 2007.928000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 1514.063000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 144.601000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 143.521000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 94.970000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 67.739000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 44.676000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 13.782000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.749002 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 3
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 1
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.743022 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.703737 +0000 UTC
Value: 2417
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:30:42.703737 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.122+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:50.123+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.036+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.036+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:00:59.037+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.019+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_width_bytes", help: "Estimated width of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_plan_rows_ratio", help: "Estimated number of rows to be processed by the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_cost_estimate_ratio", help: "Estimated cost of the execution plan node.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:11.020+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_startup_time_milliseconds", help: "Time taken to start the execution plan node in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:12.733+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T15:01:12.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T15:01:12.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T15:01:12.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T15:01:12.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T15:01:12.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T15:01:12.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "4536804317005561087", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 2007.928}
2025-07-10T15:01:12.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T15:01:12.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T15:01:12.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T15:01:12.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T15:01:12.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T15:01:12.742+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 13}
2025-07-10T15:01:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T15:01:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T15:01:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T15:01:12.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T15:01:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T15:01:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T15:01:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T15:01:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T15:01:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T15:01:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T15:01:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T15:01:12.883+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:12.884+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:12.884+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:12.884+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:12.884+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:12.884+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:12.884+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:12.884+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:12.884+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:12.884+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:12.885+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 63}
2025-07-10T15:01:12.885+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.70343 +0000 UTC
Value: 22251
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.70343 +0000 UTC
Value: 40074
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.70343 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.70343 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.70343 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.70343 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.70343 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.70343 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 255.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 918.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 28.000000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 24.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 0.000000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 2007.928000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 1514.063000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 144.601000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 143.521000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 94.970000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 67.739000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 44.676000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 13.782000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.746382 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 3
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 1
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.74241 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.70343 +0000 UTC
Value: 2422
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:12.70343 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:42.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T15:01:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T15:01:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T15:01:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T15:01:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T15:01:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T15:01:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "4536804317005561087", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 2007.928}
2025-07-10T15:01:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T15:01:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T15:01:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T15:01:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T15:01:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T15:01:42.751+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 13}
2025-07-10T15:01:42.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T15:01:42.757+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T15:01:42.757+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T15:01:42.757+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T15:01:42.757+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T15:01:42.757+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T15:01:42.757+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T15:01:42.757+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T15:01:42.758+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T15:01:42.758+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T15:01:42.758+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T15:01:42.829+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:42.829+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:42.829+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:42.829+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:42.829+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:42.829+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:42.829+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:42.829+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:42.829+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:42.830+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:01:42.830+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 63}
2025-07-10T15:01:42.830+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.703133 +0000 UTC
Value: 22266
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.703133 +0000 UTC
Value: 40079
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.703133 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.703133 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.703133 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.703133 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.703133 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.703133 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 255.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 918.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 28.000000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 24.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 0.000000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 2007.928000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 1514.063000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 144.601000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 143.521000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 94.970000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 67.739000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 44.676000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 13.782000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.756604 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 3
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 1
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.751249 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.703133 +0000 UTC
Value: 2427
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:31:42.703133 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:12.732+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T15:02:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T15:02:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T15:02:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T15:02:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T15:02:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T15:02:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "4536804317005561087", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 2007.928}
2025-07-10T15:02:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T15:02:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T15:02:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T15:02:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T15:02:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T15:02:12.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 13}
2025-07-10T15:02:12.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T15:02:12.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T15:02:12.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T15:02:12.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T15:02:12.744+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T15:02:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T15:02:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T15:02:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T15:02:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T15:02:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T15:02:12.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T15:02:12.774+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:12.774+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:12.774+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:12.774+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:12.774+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:12.774+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:12.774+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:12.774+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:12.774+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:12.775+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:12.775+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 63}
2025-07-10T15:02:12.776+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.70283 +0000 UTC
Value: 22279
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.70283 +0000 UTC
Value: 40086
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.70283 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.70283 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.70283 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.70283 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.70283 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.70283 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 255.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 918.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 28.000000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 24.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 0.000000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 2007.928000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 1514.063000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 144.601000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 143.521000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 94.970000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 67.739000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 44.676000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 13.782000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.744342 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 3
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 1
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.740367 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.70283 +0000 UTC
Value: 2432
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:12.70283 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:13.853+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to IDLE	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:02:13.853+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to IDLE	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:02:13.858+0530	info	transport/controlbuf.go:580	[transport] [client-transport 0x14001a2e008] loopyWriter exiting with error: finished processing active streams while in draining mode	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:02:13.858+0530	info	transport/http2_client.go:1646	[transport] [client-transport 0x14001a2e008] Closing: connection error: desc = "error reading from server: read tcp 10.26.232.88:56418->162.247.243.27:4317: use of closed network connection"	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:02:42.734+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T15:02:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T15:02:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T15:02:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T15:02:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T15:02:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T15:02:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "4536804317005561087", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 2007.928}
2025-07-10T15:02:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T15:02:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T15:02:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T15:02:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T15:02:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T15:02:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 13}
2025-07-10T15:02:42.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T15:02:42.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T15:02:42.745+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T15:02:42.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T15:02:42.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T15:02:42.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T15:02:42.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T15:02:42.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T15:02:42.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T15:02:42.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T15:02:42.746+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T15:02:42.916+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:42.916+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:42.916+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:42.917+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:42.917+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:42.917+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:42.917+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:42.917+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:42.917+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:42.917+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:42.917+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 63}
2025-07-10T15:02:42.918+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.702414 +0000 UTC
Value: 22294
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.702414 +0000 UTC
Value: 40091
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.702414 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.702414 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.702414 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.702414 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.702414 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.702414 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 255.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 918.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 28.000000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 24.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 0.000000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 2007.928000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 1514.063000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 144.601000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 143.521000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 94.970000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 67.739000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 44.676000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 13.782000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.745558 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 3
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 1
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.741605 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.702414 +0000 UTC
Value: 2437
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:32:42.702414 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:02:42.922+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:02:42.922+0530	info	grpc@v1.73.0/clientconn.go:1352	[core] [Channel #3 SubChannel #4]Subchannel picks a new address "otlp.nr-data.net:4317" to connect	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:02:42.922+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:02:43.172+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to READY	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:02:43.172+0530	info	pickfirstleaf/pickfirstleaf.go:197	[pick-first-leaf-lb] [pick-first-leaf-lb 0x14000eefc20] SubConn 0x1400177eeb0 reported connectivity state READY and the health listener is disabled. Transitioning SubConn to READY.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:02:43.173+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to READY	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:12.735+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T15:03:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T15:03:12.747+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T15:03:12.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T15:03:12.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T15:03:12.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T15:03:12.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "4536804317005561087", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 2007.928}
2025-07-10T15:03:12.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T15:03:12.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T15:03:12.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T15:03:12.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T15:03:12.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T15:03:12.748+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 13}
2025-07-10T15:03:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T15:03:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T15:03:12.755+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T15:03:12.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T15:03:12.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T15:03:12.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T15:03:12.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T15:03:12.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T15:03:12.756+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T15:03:12.757+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T15:03:12.757+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T15:03:12.863+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:12.863+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:12.863+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:12.863+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:12.863+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:12.864+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:12.864+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:12.864+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:12.864+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:12.864+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:12.864+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 63}
2025-07-10T15:03:12.864+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.702106 +0000 UTC
Value: 22307
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.702106 +0000 UTC
Value: 40098
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.702106 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.702106 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.702106 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.702106 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.702106 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.702106 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 255.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 918.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 28.000000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 24.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 0.000000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 2007.928000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 1514.063000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 144.601000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 143.521000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 94.970000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 67.739000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 44.676000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 13.782000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.755274 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 3
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 1
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.747901 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.702106 +0000 UTC
Value: 2442
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:12.702106 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:42.730+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T15:03:42.736+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T15:03:42.736+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T15:03:42.736+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T15:03:42.736+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T15:03:42.736+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T15:03:42.736+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "4536804317005561087", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 2007.928}
2025-07-10T15:03:42.736+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 1514.063}
2025-07-10T15:03:42.736+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T15:03:42.736+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T15:03:42.736+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T15:03:42.736+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T15:03:42.736+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 13}
2025-07-10T15:03:42.739+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb"}
2025-07-10T15:03:42.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3139757513735403281", "database": "testdb", "error": "pq: syntax error at or near \"1\""}
2025-07-10T15:03:42.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres"}
2025-07-10T15:03:42.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database": "postgres", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T15:03:42.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres"}
2025-07-10T15:03:42.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database": "postgres", "error": "pq: function slow_calculation(integer) does not exist"}
2025-07-10T15:03:42.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:463	Skipping execution plan for query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "reason": "query type not suitable for EXPLAIN"}
2025-07-10T15:03:42.740+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres"}
2025-07-10T15:03:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database": "postgres", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T15:03:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:484	Getting execution plan for slow query	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres"}
2025-07-10T15:03:42.741+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:491	Failed to get execution plan	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database": "postgres", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T15:03:42.808+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:42.808+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:42.808+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:42.808+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:42.808+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:42.808+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:42.809+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:42.809+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:42.809+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:42.809+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:42.809+0530	info	Metrics	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 63}
2025-07-10T15:03:42.809+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.701759 +0000 UTC
Value: 22322
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.701759 +0000 UTC
Value: 40103
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.701759 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.701759 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.701759 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.701759 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.701759 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.701759 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 255.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 918.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 28.000000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 24.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 0.000000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 2007.928000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 1514.063000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 144.601000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 143.521000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 94.970000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 67.739000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 44.676000
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 13.782000
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.739926 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(4536804317005561087)
     -> postgresql.query.text: Str(-- Force a slow query by using pg_sleep
SELECT pg_sleep($1), COUNT(*) FROM users u CROSS JOIN posts p LIMIT $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3139757513735403281)
     -> postgresql.query.text: Str(-- Generate a slow query with artificial delay to trigger collection
SELECT 
    u.id,
    u.name,
    u.email,
    pg_sleep($1) as sleep_result,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM 
    users u
LEFT JOIN 
    orders o ON u.id = o.user_id
WHERE 
    u.created_at >= NOW() - INTERVAL $2
GROUP BY 
    u.id, u.name, u.email
ORDER BY 
    total_spent DESC)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 3
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 1
NumberDataPoints #11
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 1
NumberDataPoints #12
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.736168 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.701759 +0000 UTC
Value: 2447
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 09:19:41.712786 +0000 UTC
Timestamp: 2025-07-10 09:33:42.701759 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T15:03:43.826+0530	info	otelcol@v0.129.1-0.20250707130321-ac9adbf016bf/collector.go:358	Received signal from OS	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "signal": "terminated"}
2025-07-10T15:03:43.826+0530	info	service@v0.129.1-0.20250707130321-ac9adbf016bf/service.go:322	Starting shutdown...	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}}
2025-07-10T15:03:43.826+0530	info	grpc@v1.73.0/server.go:822	[core] [Server #5 ListenSocket #6]ListenSocket deleted	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.852+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to IDLE	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.852+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to IDLE	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.852+0530	info	transport/controlbuf.go:594	[transport] [client-transport 0x14001a2eb48] loopyWriter exiting with error: finished processing active streams while in draining mode	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.852+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to SHUTDOWN	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.852+0530	info	grpc@v1.73.0/resolver_wrapper.go:111	[core] [Channel #3]Closing the name resolver	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.852+0530	info	grpc@v1.73.0/balancer_wrapper.go:160	[core] [Channel #3]ccBalancerWrapper: closing	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.852+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to SHUTDOWN	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.852+0530	info	grpc@v1.73.0/clientconn.go:1179	[core] [Channel #3 SubChannel #4]Subchannel deleted	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.852+0530	info	grpc@v1.73.0/clientconn.go:1183	[core] [Channel #3]Channel deleted	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.852+0530	info	newrelicpostgresqlreceiver@v0.129.0/factory.go:160	Shutting down New Relic PostgreSQL logs receiver	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "logs"}
2025-07-10T15:03:43.852+0530	info	transport/http2_client.go:1646	[transport] [client-transport 0x14001a2eb48] Closing: connection error: desc = "error reading from server: read tcp 10.26.232.88:56802->162.247.243.27:4317: use of closed network connection"	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.852+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #7]Channel Connectivity change to SHUTDOWN	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.852+0530	info	grpc@v1.73.0/resolver_wrapper.go:111	[core] [Channel #7]Closing the name resolver	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.852+0530	info	grpc@v1.73.0/balancer_wrapper.go:160	[core] [Channel #7]ccBalancerWrapper: closing	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.852+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #7 SubChannel #8]Subchannel Connectivity change to SHUTDOWN	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.852+0530	info	grpc@v1.73.0/clientconn.go:1179	[core] [Channel #7 SubChannel #8]Subchannel deleted	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.853+0530	info	grpc@v1.73.0/clientconn.go:1593	[transport] [client-transport 0x1400174efc8] Closing: rpc error: code = Canceled desc = grpc: the client connection is closing	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.853+0530	info	transport/controlbuf.go:580	[transport] [client-transport 0x1400174efc8] loopyWriter exiting with error: rpc error: code = Canceled desc = grpc: the client connection is closing	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.853+0530	info	grpc@v1.73.0/clientconn.go:1183	[core] [Channel #7]Channel deleted	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.854+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #1]Channel Connectivity change to SHUTDOWN	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.854+0530	info	grpc@v1.73.0/resolver_wrapper.go:111	[core] [Channel #1]Closing the name resolver	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.854+0530	info	grpc@v1.73.0/balancer_wrapper.go:160	[core] [Channel #1]ccBalancerWrapper: closing	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.854+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #1 SubChannel #2]Subchannel Connectivity change to SHUTDOWN	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.854+0530	info	grpc@v1.73.0/clientconn.go:1179	[core] [Channel #1 SubChannel #2]Subchannel deleted	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.854+0530	info	grpc@v1.73.0/clientconn.go:1593	[transport] [client-transport 0x14001bde008] Closing: rpc error: code = Canceled desc = grpc: the client connection is closing	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.854+0530	info	transport/controlbuf.go:580	[transport] [client-transport 0x14001bde008] loopyWriter exiting with error: rpc error: code = Canceled desc = grpc: the client connection is closing	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.855+0530	info	grpc@v1.73.0/clientconn.go:1183	[core] [Channel #1]Channel deleted	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T15:03:43.856+0530	info	extensions/extensions.go:69	Stopping extensions...	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}}
2025-07-10T15:03:43.856+0530	info	service@v0.129.1-0.20250707130321-ac9adbf016bf/service.go:336	Shutdown complete.	{"resource": {"service.instance.id": "1a29c951-519a-435b-98a7-3645131897fa", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}}
