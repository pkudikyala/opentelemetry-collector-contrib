2025-07-10T13:56:20.102+0530	info	service@v0.129.1-0.20250707130321-ac9adbf016bf/service.go:197	Setting up own telemetry...	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}}
2025-07-10T13:56:20.102+0530	info	builders/builders.go:26	Development component. May change in the future.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:20.102+0530	debug	builders/builders.go:24	Alpha component. May change in the future.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "file", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:20.102+0530	debug	builders/builders.go:24	Beta component. May change in the future.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:20.102+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:20.102+0530	debug	builders/builders.go:24	Beta component. May change in the future.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "batch", "otelcol.component.kind": "processor", "otelcol.pipeline.id": "metrics", "otelcol.signal": "metrics"}
2025-07-10T13:56:20.103+0530	info	builders/builders.go:26	Development component. May change in the future.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "logs"}
2025-07-10T13:56:20.103+0530	debug	builders/builders.go:24	Alpha component. May change in the future.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "file", "otelcol.component.kind": "exporter", "otelcol.signal": "logs"}
2025-07-10T13:56:20.103+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "logs"}
2025-07-10T13:56:20.103+0530	debug	builders/builders.go:24	Beta component. May change in the future.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "batch", "otelcol.component.kind": "processor", "otelcol.pipeline.id": "logs", "otelcol.signal": "logs"}
2025-07-10T13:56:20.103+0530	debug	builders/builders.go:24	Alpha component. May change in the future.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "file", "otelcol.component.kind": "exporter", "otelcol.signal": "traces"}
2025-07-10T13:56:20.103+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "traces"}
2025-07-10T13:56:20.103+0530	info	builders/builders.go:26	Development component. May change in the future.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "traces"}
2025-07-10T13:56:20.103+0530	debug	builders/builders.go:24	Beta component. May change in the future.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "batch", "otelcol.component.kind": "processor", "otelcol.pipeline.id": "traces", "otelcol.signal": "traces"}
2025-07-10T13:56:20.103+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "traces"}
2025-07-10T13:56:20.103+0530	debug	Logger core does not support injecting component attributes	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "traces"}
2025-07-10T13:56:20.103+0530	debug	otlpreceiver@v0.129.1-0.20250707130321-ac9adbf016bf/otlp.go:58	created signal-agnostic logger	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "traces"}
2025-07-10T13:56:20.103+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "logs"}
2025-07-10T13:56:20.103+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T13:56:20.103+0530	debug	builders/builders.go:24	Beta component. May change in the future.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T13:56:20.103+0530	info	builders/builders.go:26	Development component. May change in the future.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "logs"}
2025-07-10T13:56:20.103+0530	info	service@v0.129.1-0.20250707130321-ac9adbf016bf/service.go:257	Starting otelcontribcol...	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "Version": "0.129.0-dev", "NumCPU": 12}
2025-07-10T13:56:20.103+0530	info	extensions/extensions.go:41	Starting extensions...	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}}
2025-07-10T13:56:20.104+0530	info	grpc@v1.73.0/clientconn.go:176	[core] original dial target is: "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.104+0530	info	grpc@v1.73.0/clientconn.go:459	[core] [Channel #1]Channel created	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.104+0530	info	grpc@v1.73.0/clientconn.go:207	[core] [Channel #1]parsed dial target is: resolver.Target{URL:url.URL{Scheme:"passthrough", Opaque:"", User:(*url.Userinfo)(nil), Host:"", Path:"/otlp.nr-data.net:4317", RawPath:"", OmitHost:false, ForceQuery:false, RawQuery:"", Fragment:"", RawFragment:""}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.104+0530	info	grpc@v1.73.0/clientconn.go:208	[core] [Channel #1]Channel authority set to "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.104+0530	info	grpc@v1.73.0/resolver_wrapper.go:210	[core] [Channel #1]Resolver state updated: {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
} (resolver returned new addresses)	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.104+0530	info	grpc@v1.73.0/balancer_wrapper.go:122	[core] [Channel #1]Channel switches to new LB policy "pick_first"	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.104+0530	info	gracefulswitch/gracefulswitch.go:194	[pick-first-leaf-lb] [pick-first-leaf-lb 0x14000a3e990] Received new config {
  "shuffleAddressList": false
}, resolver state {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.104+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #1]Channel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.104+0530	info	grpc@v1.73.0/balancer_wrapper.go:195	[core] [Channel #1 SubChannel #2]Subchannel created	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.104+0530	info	grpc@v1.73.0/clientconn.go:364	[core] [Channel #1]Channel exiting idle mode	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.104+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #1 SubChannel #2]Subchannel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.104+0530	info	grpc@v1.73.0/clientconn.go:1352	[core] [Channel #1 SubChannel #2]Subchannel picks a new address "otlp.nr-data.net:4317" to connect	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/clientconn.go:176	[core] original dial target is: "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/clientconn.go:459	[core] [Channel #3]Channel created	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/clientconn.go:207	[core] [Channel #3]parsed dial target is: resolver.Target{URL:url.URL{Scheme:"passthrough", Opaque:"", User:(*url.Userinfo)(nil), Host:"", Path:"/otlp.nr-data.net:4317", RawPath:"", OmitHost:false, ForceQuery:false, RawQuery:"", Fragment:"", RawFragment:""}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/clientconn.go:208	[core] [Channel #3]Channel authority set to "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/resolver_wrapper.go:210	[core] [Channel #3]Resolver state updated: {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
} (resolver returned new addresses)	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/balancer_wrapper.go:122	[core] [Channel #3]Channel switches to new LB policy "pick_first"	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	gracefulswitch/gracefulswitch.go:194	[pick-first-leaf-lb] [pick-first-leaf-lb 0x14001a241b0] Received new config {
  "shuffleAddressList": false
}, resolver state {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/balancer_wrapper.go:195	[core] [Channel #3 SubChannel #4]Subchannel created	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/clientconn.go:364	[core] [Channel #3]Channel exiting idle mode	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/clientconn.go:1352	[core] [Channel #3 SubChannel #4]Subchannel picks a new address "otlp.nr-data.net:4317" to connect	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/clientconn.go:176	[core] original dial target is: "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/clientconn.go:459	[core] [Channel #5]Channel created	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/clientconn.go:207	[core] [Channel #5]parsed dial target is: resolver.Target{URL:url.URL{Scheme:"passthrough", Opaque:"", User:(*url.Userinfo)(nil), Host:"", Path:"/otlp.nr-data.net:4317", RawPath:"", OmitHost:false, ForceQuery:false, RawQuery:"", Fragment:"", RawFragment:""}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/clientconn.go:208	[core] [Channel #5]Channel authority set to "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/resolver_wrapper.go:210	[core] [Channel #5]Resolver state updated: {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
} (resolver returned new addresses)	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/balancer_wrapper.go:122	[core] [Channel #5]Channel switches to new LB policy "pick_first"	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	gracefulswitch/gracefulswitch.go:194	[pick-first-leaf-lb] [pick-first-leaf-lb 0x14001a24870] Received new config {
  "shuffleAddressList": false
}, resolver state {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #5]Channel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/balancer_wrapper.go:195	[core] [Channel #5 SubChannel #6]Subchannel created	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/clientconn.go:364	[core] [Channel #5]Channel exiting idle mode	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #5 SubChannel #6]Subchannel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	grpc@v1.73.0/clientconn.go:1352	[core] [Channel #5 SubChannel #6]Subchannel picks a new address "otlp.nr-data.net:4317" to connect	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.105+0530	info	newrelicpostgresqlreceiver@v0.129.0/factory.go:154	Starting New Relic PostgreSQL logs receiver	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "logs"}
2025-07-10T13:56:20.106+0530	info	grpc@v1.73.0/server.go:690	[core] [Server #7]Server created	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.106+0530	info	otlpreceiver@v0.129.1-0.20250707130321-ac9adbf016bf/otlp.go:117	Starting GRPC server	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "traces", "endpoint": "0.0.0.0:4317"}
2025-07-10T13:56:20.106+0530	info	otlpreceiver@v0.129.1-0.20250707130321-ac9adbf016bf/otlp.go:175	Starting HTTP server	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "traces", "endpoint": "0.0.0.0:4318"}
2025-07-10T13:56:20.106+0530	info	service@v0.129.1-0.20250707130321-ac9adbf016bf/service.go:280	Everything is ready. Begin running and processing data.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}}
2025-07-10T13:56:20.106+0530	info	grpc@v1.73.0/server.go:886	[core] [Server #7 ListenSocket #8]ListenSocket created	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.340+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #1 SubChannel #2]Subchannel Connectivity change to READY	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.340+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to READY	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.340+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #5 SubChannel #6]Subchannel Connectivity change to READY	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.340+0530	info	pickfirstleaf/pickfirstleaf.go:197	[pick-first-leaf-lb] [pick-first-leaf-lb 0x14001a241b0] SubConn 0x14000fbc780 reported connectivity state READY and the health listener is disabled. Transitioning SubConn to READY.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.340+0530	info	pickfirstleaf/pickfirstleaf.go:197	[pick-first-leaf-lb] [pick-first-leaf-lb 0x14001a24870] SubConn 0x14000fbcaa0 reported connectivity state READY and the health listener is disabled. Transitioning SubConn to READY.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.340+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to READY	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.340+0530	info	pickfirstleaf/pickfirstleaf.go:197	[pick-first-leaf-lb] [pick-first-leaf-lb 0x14000a3e990] SubConn 0x14001362190 reported connectivity state READY and the health listener is disabled. Transitioning SubConn to READY.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.340+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #1]Channel Connectivity change to READY	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:20.340+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #5]Channel Connectivity change to READY	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T13:56:21.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T13:56:21.151+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T13:56:21.151+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T13:56:21.151+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T13:56:21.151+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T13:56:21.151+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T13:56:21.151+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T13:56:21.151+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T13:56:21.151+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T13:56:21.151+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T13:56:21.151+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T13:56:21.151+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T13:56:21.151+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T13:56:21.157+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T13:56:21.157+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T13:56:21.158+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T13:56:21.158+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T13:56:21.159+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T13:56:21.159+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T13:56:21.159+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T13:56:21.160+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T13:56:21.312+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:21.312+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:21.312+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:21.312+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:21.312+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.execution_plan.async_capable	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:21.312+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.execution_plan.parallel_aware	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:21.312+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:21.312+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:21.312+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:21.312+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:21.312+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:21.312+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:21.312+0530	info	Metrics	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 12, "data points": 53}
2025-07-10T13:56:21.313+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.106107 +0000 UTC
Value: 20368
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.106107 +0000 UTC
Value: 39299
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.106107 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.106107 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.106107 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.106107 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.106107 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.106107 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.execution_plan.async_capable
     -> Description: Whether the execution plan node is async capable.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.node.type: Str(ProjectSet)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.159088 +0000 UTC
Value: 0
Metric #5
Descriptor:
     -> Name: postgresql.execution_plan.parallel_aware
     -> Description: Whether the execution plan node is parallel aware.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.node.type: Str(ProjectSet)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.159088 +0000 UTC
Value: 0
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 43.000000
Metric #7
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 6.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 11.230000
Metric #9
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.157044 +0000 UTC
Value: 0.000000
Metric #10
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.151436 +0000 UTC
Value: 1
Metric #11
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.106107 +0000 UTC
Value: 1362
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:21.106107 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:51.132+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T13:56:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T13:56:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T13:56:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T13:56:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T13:56:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T13:56:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T13:56:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T13:56:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T13:56:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T13:56:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T13:56:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T13:56:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T13:56:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T13:56:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T13:56:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T13:56:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T13:56:51.146+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T13:56:51.146+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T13:56:51.146+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T13:56:51.146+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T13:56:51.262+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:51.262+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:51.262+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:51.262+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:51.262+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:51.263+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:51.263+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:51.263+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:51.263+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:51.263+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:56:51.263+0530	info	Metrics	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T13:56:51.263+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.105777 +0000 UTC
Value: 20385
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.105777 +0000 UTC
Value: 39306
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.105777 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.105777 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.105777 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.105777 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.105777 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.105777 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.144994 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.14135 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.105777 +0000 UTC
Value: 1370
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:26:51.105777 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:19.036+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:21.132+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T13:57:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T13:57:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T13:57:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T13:57:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T13:57:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T13:57:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T13:57:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T13:57:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T13:57:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T13:57:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T13:57:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T13:57:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T13:57:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T13:57:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T13:57:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T13:57:21.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T13:57:21.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T13:57:21.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T13:57:21.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T13:57:21.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T13:57:21.204+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:21.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:21.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:21.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:21.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:21.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:21.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:21.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:21.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:21.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:21.205+0530	info	Metrics	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T13:57:21.206+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.105557 +0000 UTC
Value: 20398
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.105557 +0000 UTC
Value: 39311
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.105557 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.105557 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.105557 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.105557 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.105557 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.105557 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.143179 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.1393 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.105557 +0000 UTC
Value: 1378
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:21.105557 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.566+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:30.567+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:51.133+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T13:57:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T13:57:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T13:57:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T13:57:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T13:57:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T13:57:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T13:57:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T13:57:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T13:57:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T13:57:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T13:57:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T13:57:51.141+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T13:57:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T13:57:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T13:57:51.146+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T13:57:51.146+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T13:57:51.146+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T13:57:51.146+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T13:57:51.146+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T13:57:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T13:57:51.347+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:51.347+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:51.347+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:51.347+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:51.347+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:51.347+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:51.347+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:51.347+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:51.348+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:51.348+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:57:51.348+0530	info	Metrics	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T13:57:51.348+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.105354 +0000 UTC
Value: 20413
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.105354 +0000 UTC
Value: 39318
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.105354 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.105354 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.105354 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.105354 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.105354 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.105354 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.145378 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.140975 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.105354 +0000 UTC
Value: 1386
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:27:51.105354 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:21.131+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T13:58:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T13:58:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T13:58:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T13:58:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T13:58:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T13:58:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T13:58:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T13:58:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T13:58:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T13:58:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T13:58:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T13:58:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T13:58:21.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T13:58:21.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T13:58:21.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T13:58:21.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T13:58:21.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T13:58:21.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T13:58:21.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T13:58:21.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T13:58:21.292+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:21.292+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:21.292+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:21.292+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:21.292+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:21.292+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:21.292+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:21.292+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:21.292+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:21.292+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:21.292+0530	info	Metrics	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T13:58:21.293+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.105296 +0000 UTC
Value: 20426
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.105296 +0000 UTC
Value: 39323
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.105296 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.105296 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.105296 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.105296 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.105296 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.105296 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.144066 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.139572 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.105296 +0000 UTC
Value: 1394
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:21.105296 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:51.137+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T13:58:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T13:58:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T13:58:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T13:58:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T13:58:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T13:58:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T13:58:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T13:58:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T13:58:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T13:58:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T13:58:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T13:58:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T13:58:51.154+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T13:58:51.154+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T13:58:51.154+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T13:58:51.155+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T13:58:51.155+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T13:58:51.155+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T13:58:51.155+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T13:58:51.156+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T13:58:51.234+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:51.234+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:51.234+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:51.234+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:51.234+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:51.234+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:51.234+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:51.234+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:51.234+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:51.234+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:58:51.234+0530	info	Metrics	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T13:58:51.235+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.105272 +0000 UTC
Value: 20441
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.105272 +0000 UTC
Value: 39330
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.105272 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.105272 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.105272 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.105272 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.105272 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.105272 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.153994 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.147575 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.105272 +0000 UTC
Value: 1402
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:28:51.105272 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:21.134+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T13:59:21.142+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T13:59:21.142+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T13:59:21.142+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T13:59:21.142+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T13:59:21.142+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T13:59:21.142+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T13:59:21.142+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T13:59:21.142+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T13:59:21.142+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T13:59:21.142+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T13:59:21.142+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T13:59:21.142+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T13:59:21.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T13:59:21.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T13:59:21.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T13:59:21.148+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T13:59:21.148+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T13:59:21.148+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T13:59:21.148+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T13:59:21.148+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T13:59:21.170+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:21.170+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:21.170+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:21.170+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:21.170+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:21.170+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:21.170+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:21.170+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:21.170+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:21.170+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:21.170+0530	info	Metrics	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T13:59:21.171+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.105097 +0000 UTC
Value: 20454
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.105097 +0000 UTC
Value: 39335
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.105097 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.105097 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.105097 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.105097 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.105097 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.105097 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.146675 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.142485 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.105097 +0000 UTC
Value: 1410
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:21.105097 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:51.138+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T13:59:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T13:59:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T13:59:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T13:59:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T13:59:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T13:59:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T13:59:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T13:59:51.147+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T13:59:51.148+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T13:59:51.148+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T13:59:51.148+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T13:59:51.148+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T13:59:51.153+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T13:59:51.153+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T13:59:51.154+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T13:59:51.154+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T13:59:51.154+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T13:59:51.154+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T13:59:51.155+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T13:59:51.155+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T13:59:51.308+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:51.308+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:51.308+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:51.308+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:51.308+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:51.308+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:51.308+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:51.308+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:51.308+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:51.309+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T13:59:51.309+0530	info	Metrics	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T13:59:51.309+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.104926 +0000 UTC
Value: 20469
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.104926 +0000 UTC
Value: 39342
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.104926 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.104926 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.104926 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.104926 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.104926 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.104926 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.153138 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.147679 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.104926 +0000 UTC
Value: 1418
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:29:51.104926 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:21.131+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:00:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:00:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:00:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:00:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T14:00:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:00:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:00:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:00:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:00:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:00:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:00:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:00:21.139+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:00:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:00:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:00:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:00:21.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:00:21.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:00:21.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:00:21.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:00:21.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:00:21.258+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:21.258+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:21.258+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:21.258+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:21.258+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:21.258+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:21.258+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:21.258+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:21.258+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:21.258+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:21.259+0530	info	Metrics	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T14:00:21.260+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.104741 +0000 UTC
Value: 20482
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.104741 +0000 UTC
Value: 39347
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.104741 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.104741 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.104741 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.104741 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.104741 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.104741 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.143185 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.139469 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.104741 +0000 UTC
Value: 1426
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:21.104741 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:51.132+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:00:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:00:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:00:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:00:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T14:00:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:00:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:00:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:00:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:00:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:00:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:00:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:00:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:00:51.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:00:51.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:00:51.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:00:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:00:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:00:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:00:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:00:51.146+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:00:51.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:51.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:51.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:51.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:51.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:51.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:51.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:51.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:51.205+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:51.206+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:00:51.206+0530	info	Metrics	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T14:00:51.206+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.10457 +0000 UTC
Value: 20497
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.10457 +0000 UTC
Value: 39354
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.10457 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.10457 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.10457 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.10457 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.10457 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.10457 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.144267 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.140397 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.10457 +0000 UTC
Value: 1434
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:30:51.10457 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:21.127+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:01:21.132+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:01:21.132+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:01:21.132+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:01:21.133+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T14:01:21.133+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:01:21.133+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:01:21.133+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:01:21.133+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:01:21.133+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:01:21.133+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:01:21.133+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:01:21.133+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:01:21.136+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:01:21.136+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:01:21.136+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:01:21.137+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:01:21.137+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:01:21.137+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:01:21.137+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:01:21.138+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:01:21.149+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:21.149+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:21.149+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:21.149+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:21.149+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:21.149+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:21.149+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:21.150+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:21.150+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:21.150+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:21.150+0530	info	Metrics	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T14:01:21.150+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.104397 +0000 UTC
Value: 20510
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.104397 +0000 UTC
Value: 39359
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.104397 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.104397 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.104397 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.104397 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.104397 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.104397 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.136408 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.132909 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.104397 +0000 UTC
Value: 1442
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:21.104397 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:51.133+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:01:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:01:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:01:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:01:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T14:01:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:01:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:01:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:01:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:01:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:01:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:01:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:01:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:01:51.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:01:51.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:01:51.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:01:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:01:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:01:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:01:51.146+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:01:51.146+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:01:51.295+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:51.295+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:51.295+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:51.295+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:51.295+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:51.295+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:51.295+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:51.295+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:51.295+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:51.295+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:01:51.295+0530	info	Metrics	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T14:01:51.295+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.104309 +0000 UTC
Value: 20525
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.104309 +0000 UTC
Value: 39366
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.104309 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.104309 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.104309 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.104309 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.104309 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.104309 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.144086 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.140107 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.104309 +0000 UTC
Value: 1450
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:31:51.104309 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:21.133+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:02:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:02:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:02:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:02:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T14:02:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:02:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:02:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:02:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:02:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:02:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:02:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:02:21.143+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:02:21.148+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:02:21.148+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:02:21.148+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:02:21.148+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:02:21.149+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:02:21.149+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:02:21.149+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:02:21.149+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:02:21.240+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:21.240+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:21.240+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:21.240+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:21.240+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:21.240+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:21.240+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:21.240+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:21.240+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:21.240+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:21.240+0530	info	Metrics	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T14:02:21.241+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.104119 +0000 UTC
Value: 20538
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.104119 +0000 UTC
Value: 39371
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.104119 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.104119 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.104119 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.104119 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.104119 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.104119 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.147993 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.143082 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.104119 +0000 UTC
Value: 1458
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:21.104119 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:51.132+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:02:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:02:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:02:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:02:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T14:02:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:02:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:02:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:02:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:02:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:02:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:02:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:02:51.140+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:02:51.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:02:51.144+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:02:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:02:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:02:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:02:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:02:51.145+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:02:51.146+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:02:51.186+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:51.186+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:51.186+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:51.186+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:51.186+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:51.186+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:51.186+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:51.186+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:51.186+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:51.186+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:51.186+0530	info	Metrics	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T14:02:51.187+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.103922 +0000 UTC
Value: 20553
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.103922 +0000 UTC
Value: 39378
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.103922 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.103922 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.103922 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.103922 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.103922 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.103922 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.144302 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.140536 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.103922 +0000 UTC
Value: 1466
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:32:51.103922 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:02:52.444+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to IDLE	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:02:52.444+0530	info	transport/controlbuf.go:594	[transport] [client-transport 0x140016e8d88] loopyWriter exiting with error: finished processing active streams while in draining mode	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:02:52.445+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to IDLE	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:02:52.445+0530	info	transport/http2_client.go:1646	[transport] [client-transport 0x140016e8d88] Closing: connection error: desc = "error reading from server: read tcp 192.168.31.224:54595->162.247.243.27:4317: use of closed network connection"	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:03:21.125+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:03:21.131+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:03:21.131+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:03:21.131+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:03:21.131+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T14:03:21.131+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:03:21.131+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:03:21.131+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:03:21.131+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:03:21.131+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:03:21.131+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:03:21.131+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:03:21.131+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:03:21.135+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:03:21.135+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:03:21.135+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:03:21.136+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:03:21.136+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:03:21.136+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:03:21.136+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:03:21.137+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:459	Failed to get execution plan	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:03:21.325+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:03:21.326+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:03:21.326+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:03:21.326+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:03:21.326+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:03:21.326+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:03:21.326+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:03:21.326+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:03:21.326+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:03:21.326+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:03:21.326+0530	info	Metrics	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T14:03:21.326+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.103759 +0000 UTC
Value: 20566
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.103759 +0000 UTC
Value: 39383
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.103759 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.103759 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.103759 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.103759 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.103759 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.103759 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.135237 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.131487 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.103759 +0000 UTC
Value: 1474
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:26:20.103383 +0000 UTC
Timestamp: 2025-07-10 08:33:21.103759 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:03:21.327+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:03:21.327+0530	info	grpc@v1.73.0/clientconn.go:1352	[core] [Channel #3 SubChannel #4]Subchannel picks a new address "otlp.nr-data.net:4317" to connect	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:03:21.327+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:03:21.715+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to READY	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:03:21.715+0530	info	pickfirstleaf/pickfirstleaf.go:197	[pick-first-leaf-lb] [pick-first-leaf-lb 0x14001a241b0] SubConn 0x14000fbc780 reported connectivity state READY and the health listener is disabled. Transitioning SubConn to READY.	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:03:21.715+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to READY	{"resource": {"service.instance.id": "f765b71a-6100-4eb8-8a18-32060aed5994", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
