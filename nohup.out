2025-07-10T14:08:49.484+0530	info	service@v0.129.1-0.20250707130321-ac9adbf016bf/service.go:197	Setting up own telemetry...	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}}
2025-07-10T14:08:49.485+0530	info	builders/builders.go:26	Development component. May change in the future.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "traces"}
2025-07-10T14:08:49.485+0530	debug	builders/builders.go:24	Alpha component. May change in the future.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "file", "otelcol.component.kind": "exporter", "otelcol.signal": "traces"}
2025-07-10T14:08:49.485+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "traces"}
2025-07-10T14:08:49.485+0530	debug	builders/builders.go:24	Beta component. May change in the future.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "batch", "otelcol.component.kind": "processor", "otelcol.pipeline.id": "traces", "otelcol.signal": "traces"}
2025-07-10T14:08:49.485+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "logs"}
2025-07-10T14:08:49.485+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:08:49.485+0530	info	builders/builders.go:26	Development component. May change in the future.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:08:49.485+0530	debug	builders/builders.go:24	Alpha component. May change in the future.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "file", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:08:49.485+0530	debug	builders/builders.go:24	Beta component. May change in the future.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:08:49.485+0530	debug	builders/builders.go:24	Beta component. May change in the future.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "batch", "otelcol.component.kind": "processor", "otelcol.pipeline.id": "metrics", "otelcol.signal": "metrics"}
2025-07-10T14:08:49.485+0530	debug	builders/builders.go:24	Beta component. May change in the future.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:08:49.485+0530	info	builders/builders.go:26	Development component. May change in the future.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "logs"}
2025-07-10T14:08:49.485+0530	debug	builders/builders.go:24	Alpha component. May change in the future.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "file", "otelcol.component.kind": "exporter", "otelcol.signal": "logs"}
2025-07-10T14:08:49.485+0530	debug	builders/builders.go:24	Beta component. May change in the future.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "batch", "otelcol.component.kind": "processor", "otelcol.pipeline.id": "logs", "otelcol.signal": "logs"}
2025-07-10T14:08:49.485+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:08:49.485+0530	debug	Logger core does not support injecting component attributes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:08:49.485+0530	debug	otlpreceiver@v0.129.1-0.20250707130321-ac9adbf016bf/otlp.go:58	created signal-agnostic logger	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:08:49.485+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "traces"}
2025-07-10T14:08:49.485+0530	debug	builders/builders.go:24	Stable component.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "logs"}
2025-07-10T14:08:49.485+0530	info	builders/builders.go:26	Development component. May change in the future.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "logs"}
2025-07-10T14:08:49.485+0530	info	service@v0.129.1-0.20250707130321-ac9adbf016bf/service.go:257	Starting otelcontribcol...	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "Version": "0.129.0-dev", "NumCPU": 12}
2025-07-10T14:08:49.485+0530	info	extensions/extensions.go:41	Starting extensions...	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}}
2025-07-10T14:08:49.488+0530	info	grpc@v1.73.0/clientconn.go:176	[core] original dial target is: "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.488+0530	info	grpc@v1.73.0/clientconn.go:459	[core] [Channel #1]Channel created	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.488+0530	info	grpc@v1.73.0/clientconn.go:207	[core] [Channel #1]parsed dial target is: resolver.Target{URL:url.URL{Scheme:"passthrough", Opaque:"", User:(*url.Userinfo)(nil), Host:"", Path:"/otlp.nr-data.net:4317", RawPath:"", OmitHost:false, ForceQuery:false, RawQuery:"", Fragment:"", RawFragment:""}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.488+0530	info	grpc@v1.73.0/clientconn.go:208	[core] [Channel #1]Channel authority set to "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.488+0530	info	grpc@v1.73.0/resolver_wrapper.go:210	[core] [Channel #1]Resolver state updated: {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
} (resolver returned new addresses)	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.488+0530	info	grpc@v1.73.0/balancer_wrapper.go:122	[core] [Channel #1]Channel switches to new LB policy "pick_first"	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.488+0530	info	gracefulswitch/gracefulswitch.go:194	[pick-first-leaf-lb] [pick-first-leaf-lb 0x14001614090] Received new config {
  "shuffleAddressList": false
}, resolver state {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.488+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #1]Channel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.488+0530	info	grpc@v1.73.0/balancer_wrapper.go:195	[core] [Channel #1 SubChannel #2]Subchannel created	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.488+0530	info	grpc@v1.73.0/clientconn.go:364	[core] [Channel #1]Channel exiting idle mode	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.488+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #1 SubChannel #2]Subchannel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.488+0530	info	grpc@v1.73.0/clientconn.go:1352	[core] [Channel #1 SubChannel #2]Subchannel picks a new address "otlp.nr-data.net:4317" to connect	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/clientconn.go:176	[core] original dial target is: "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/clientconn.go:459	[core] [Channel #3]Channel created	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/clientconn.go:207	[core] [Channel #3]parsed dial target is: resolver.Target{URL:url.URL{Scheme:"passthrough", Opaque:"", User:(*url.Userinfo)(nil), Host:"", Path:"/otlp.nr-data.net:4317", RawPath:"", OmitHost:false, ForceQuery:false, RawQuery:"", Fragment:"", RawFragment:""}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/clientconn.go:208	[core] [Channel #3]Channel authority set to "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/resolver_wrapper.go:210	[core] [Channel #3]Resolver state updated: {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
} (resolver returned new addresses)	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/balancer_wrapper.go:122	[core] [Channel #3]Channel switches to new LB policy "pick_first"	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	gracefulswitch/gracefulswitch.go:194	[pick-first-leaf-lb] [pick-first-leaf-lb 0x140011a4a20] Received new config {
  "shuffleAddressList": false
}, resolver state {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/balancer_wrapper.go:195	[core] [Channel #3 SubChannel #4]Subchannel created	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/clientconn.go:364	[core] [Channel #3]Channel exiting idle mode	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/clientconn.go:1352	[core] [Channel #3 SubChannel #4]Subchannel picks a new address "otlp.nr-data.net:4317" to connect	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/server.go:690	[core] [Server #5]Server created	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	otlpreceiver@v0.129.1-0.20250707130321-ac9adbf016bf/otlp.go:117	Starting GRPC server	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "endpoint": "0.0.0.0:4317"}
2025-07-10T14:08:49.489+0530	info	otlpreceiver@v0.129.1-0.20250707130321-ac9adbf016bf/otlp.go:175	Starting HTTP server	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "endpoint": "0.0.0.0:4318"}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/server.go:886	[core] [Server #5 ListenSocket #6]ListenSocket created	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/clientconn.go:176	[core] original dial target is: "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/clientconn.go:459	[core] [Channel #7]Channel created	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/clientconn.go:207	[core] [Channel #7]parsed dial target is: resolver.Target{URL:url.URL{Scheme:"passthrough", Opaque:"", User:(*url.Userinfo)(nil), Host:"", Path:"/otlp.nr-data.net:4317", RawPath:"", OmitHost:false, ForceQuery:false, RawQuery:"", Fragment:"", RawFragment:""}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/clientconn.go:208	[core] [Channel #7]Channel authority set to "otlp.nr-data.net:4317"	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/resolver_wrapper.go:210	[core] [Channel #7]Resolver state updated: {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
} (resolver returned new addresses)	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/balancer_wrapper.go:122	[core] [Channel #7]Channel switches to new LB policy "pick_first"	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	gracefulswitch/gracefulswitch.go:194	[pick-first-leaf-lb] [pick-first-leaf-lb 0x14001a90090] Received new config {
  "shuffleAddressList": false
}, resolver state {
  "Addresses": [
    {
      "Addr": "otlp.nr-data.net:4317",
      "ServerName": "",
      "Attributes": null,
      "BalancerAttributes": null,
      "Metadata": null
    }
  ],
  "Endpoints": [
    {
      "Addresses": [
        {
          "Addr": "otlp.nr-data.net:4317",
          "ServerName": "",
          "Attributes": null,
          "BalancerAttributes": null,
          "Metadata": null
        }
      ],
      "Attributes": null
    }
  ],
  "ServiceConfig": null,
  "Attributes": null
}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #7]Channel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/balancer_wrapper.go:195	[core] [Channel #7 SubChannel #8]Subchannel created	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/clientconn.go:364	[core] [Channel #7]Channel exiting idle mode	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #7 SubChannel #8]Subchannel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	grpc@v1.73.0/clientconn.go:1352	[core] [Channel #7 SubChannel #8]Subchannel picks a new address "otlp.nr-data.net:4317" to connect	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.489+0530	info	newrelicpostgresqlreceiver@v0.129.0/factory.go:154	Starting New Relic PostgreSQL logs receiver	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "logs"}
2025-07-10T14:08:49.489+0530	info	service@v0.129.1-0.20250707130321-ac9adbf016bf/service.go:280	Everything is ready. Begin running and processing data.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}}
2025-07-10T14:08:49.567+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #7 SubChannel #8]Subchannel Connectivity change to READY	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.567+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #1 SubChannel #2]Subchannel Connectivity change to READY	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.568+0530	info	pickfirstleaf/pickfirstleaf.go:197	[pick-first-leaf-lb] [pick-first-leaf-lb 0x14001a90090] SubConn 0x14001ab40f0 reported connectivity state READY and the health listener is disabled. Transitioning SubConn to READY.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.567+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to READY	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.568+0530	info	pickfirstleaf/pickfirstleaf.go:197	[pick-first-leaf-lb] [pick-first-leaf-lb 0x14001614090] SubConn 0x14000d21720 reported connectivity state READY and the health listener is disabled. Transitioning SubConn to READY.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.568+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #1]Channel Connectivity change to READY	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.568+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #7]Channel Connectivity change to READY	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.568+0530	info	pickfirstleaf/pickfirstleaf.go:197	[pick-first-leaf-lb] [pick-first-leaf-lb 0x140011a4a20] SubConn 0x140017f01e0 reported connectivity state READY and the health listener is disabled. Transitioning SubConn to READY.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:49.568+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to READY	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:08:50.509+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:08:50.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:08:50.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:08:50.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:08:50.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T14:08:50.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:08:50.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:08:50.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:08:50.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:08:50.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:08:50.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:08:50.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:08:50.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:08:50.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:08:50.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:08:50.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:08:50.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:08:50.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:08:50.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:08:50.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:08:50.521+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:08:50.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:08:50.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:08:50.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:08:50.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:08:50.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.execution_plan.async_capable	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:08:50.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.execution_plan.parallel_aware	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:08:50.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:08:50.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:08:50.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:08:50.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:08:50.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:08:50.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:08:50.695+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 12, "data points": 53}
2025-07-10T14:08:50.695+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.490175 +0000 UTC
Value: 20720
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.490175 +0000 UTC
Value: 39450
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.490175 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.490175 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.490175 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.490175 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.490175 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.490175 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.execution_plan.async_capable
     -> Description: Whether the execution plan node is async capable.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.node.type: Str(ProjectSet)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.52195 +0000 UTC
Value: 0
Metric #5
Descriptor:
     -> Name: postgresql.execution_plan.parallel_aware
     -> Description: Whether the execution plan node is parallel aware.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.node.type: Str(ProjectSet)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.52195 +0000 UTC
Value: 0
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 43.000000
Metric #7
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 6.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 11.230000
Metric #9
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51901 +0000 UTC
Value: 0.000000
Metric #10
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.51517 +0000 UTC
Value: 1
Metric #11
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.490175 +0000 UTC
Value: 1562
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:38:50.490175 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:20.505+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:09:20.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:09:20.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:09:20.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:09:20.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T14:09:20.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:09:20.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:09:20.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:09:20.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:09:20.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:09:20.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:09:20.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:09:20.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:09:20.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:09:20.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:09:20.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:09:20.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:09:20.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:09:20.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:09:20.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:09:20.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:09:20.642+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:20.642+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:20.642+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:20.642+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:20.642+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:20.642+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:20.642+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:20.642+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:20.642+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:20.642+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:20.643+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T14:09:20.643+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.490109 +0000 UTC
Value: 20735
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.490109 +0000 UTC
Value: 39455
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.490109 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.490109 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.490109 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.490109 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.490109 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.490109 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.514645 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.51106 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.490109 +0000 UTC
Value: 1570
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:20.490109 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:50.505+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:09:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:09:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:09:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:09:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T14:09:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:09:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:09:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:09:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:09:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:09:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:09:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:09:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:09:50.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:09:50.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:09:50.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:09:50.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:09:50.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:09:50.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:09:50.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:09:50.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:09:50.587+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:50.587+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:50.587+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:50.587+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:50.587+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:50.587+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:50.587+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:50.587+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:50.587+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:50.587+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:09:50.587+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T14:09:50.588+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.489979 +0000 UTC
Value: 20750
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.489979 +0000 UTC
Value: 39462
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.489979 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.489979 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.489979 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.489979 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.489979 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.489979 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.515382 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.511567 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.489979 +0000 UTC
Value: 1578
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:39:50.489979 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:06.299+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:12.438+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:12.439+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:12.439+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:12.439+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:12.439+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:12.439+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:12.439+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:12.439+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:12.439+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:12.439+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.525+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:10:20.525+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:10:20.525+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:10:20.525+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T14:10:20.525+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:10:20.526+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:10:20.526+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:10:20.526+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:10:20.526+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:10:20.526+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:10:20.526+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:10:20.526+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:10:20.531+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:10:20.532+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:10:20.532+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:10:20.532+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:10:20.533+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:10:20.533+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:10:20.533+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:10:20.534+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:10:20.734+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.734+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.734+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.734+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.734+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.734+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.734+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.734+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.734+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.734+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.734+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T14:10:20.734+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.489856 +0000 UTC
Value: 20763
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.489856 +0000 UTC
Value: 39467
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.489856 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.489856 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.489856 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.489856 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.489856 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.489856 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.531667 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.525825 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.489856 +0000 UTC
Value: 1586
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:20.489856 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:20.860+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:50.500+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:10:50.505+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:10:50.505+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:10:50.505+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:10:50.505+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T14:10:50.505+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:10:50.505+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:10:50.505+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:10:50.505+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:10:50.505+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:10:50.505+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:10:50.505+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:10:50.505+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:10:50.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:10:50.509+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:10:50.509+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:10:50.509+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:10:50.509+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:10:50.509+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:10:50.509+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:10:50.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:10:50.683+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:50.683+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:50.683+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:50.683+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:50.683+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:50.683+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:50.683+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:50.683+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:50.683+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:50.683+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:50.683+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T14:10:50.683+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.489715 +0000 UTC
Value: 20778
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.489715 +0000 UTC
Value: 39474
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.489715 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.489715 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.489715 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.489715 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.489715 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.489715 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.508651 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.505258 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.489715 +0000 UTC
Value: 1594
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:40:50.489715 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:10:55.683+0530	info	internal/retry_sender.go:133	Exporting failed. Will retry the request after interval.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "error": "rpc error: code = DeadlineExceeded desc = context deadline exceeded", "interval": "7.285341444s"}
2025-07-10T14:11:07.970+0530	info	internal/retry_sender.go:133	Exporting failed. Will retry the request after interval.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "error": "rpc error: code = DeadlineExceeded desc = context deadline exceeded", "interval": "3.9926696s"}
2025-07-10T14:11:16.965+0530	info	internal/retry_sender.go:133	Exporting failed. Will retry the request after interval.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "error": "rpc error: code = DeadlineExceeded desc = context deadline exceeded", "interval": "12.151586723s"}
2025-07-10T14:11:20.505+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:11:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:11:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:11:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:11:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T14:11:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:11:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:11:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:11:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:11:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:11:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:11:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:11:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:11:20.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:11:20.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:11:20.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:11:20.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:11:20.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:11:20.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:11:20.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:11:20.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:11:20.631+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:20.631+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:20.631+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:20.631+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:20.631+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:20.631+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:20.632+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:20.632+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:20.632+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:20.632+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:20.632+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T14:11:20.633+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.489691 +0000 UTC
Value: 20791
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.489691 +0000 UTC
Value: 39479
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.489691 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.489691 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.489691 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.489691 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.489691 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.489691 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.516136 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.512265 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.489691 +0000 UTC
Value: 1602
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:20.489691 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:25.633+0530	info	internal/retry_sender.go:133	Exporting failed. Will retry the request after interval.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "error": "rpc error: code = DeadlineExceeded desc = context deadline exceeded", "interval": "3.102242925s"}
2025-07-10T14:11:33.738+0530	info	internal/retry_sender.go:133	Exporting failed. Will retry the request after interval.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "error": "rpc error: code = DeadlineExceeded desc = context deadline exceeded", "interval": "4.04582381s"}
2025-07-10T14:11:34.118+0530	info	internal/retry_sender.go:133	Exporting failed. Will retry the request after interval.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "error": "rpc error: code = DeadlineExceeded desc = context deadline exceeded", "interval": "13.086204499s"}
2025-07-10T14:11:42.786+0530	info	internal/retry_sender.go:133	Exporting failed. Will retry the request after interval.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "error": "rpc error: code = DeadlineExceeded desc = context deadline exceeded", "interval": "16.653492546s"}
2025-07-10T14:11:50.505+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:11:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:11:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:11:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:11:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T14:11:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:11:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:11:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:11:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:11:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:11:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:11:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:11:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:11:50.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:11:50.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:11:50.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:11:50.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:11:50.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:11:50.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:11:50.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:11:50.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:11:50.569+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:50.570+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:50.570+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:50.570+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:50.570+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:50.570+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:50.570+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:50.570+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:50.570+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:50.570+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:50.571+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T14:11:50.571+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.489544 +0000 UTC
Value: 20806
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.489544 +0000 UTC
Value: 39486
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.489544 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.489544 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.489544 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.489544 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.489544 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.489544 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.515563 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.511631 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.489544 +0000 UTC
Value: 1610
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:41:50.489544 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:11:52.205+0530	info	internal/retry_sender.go:133	Exporting failed. Will retry the request after interval.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "error": "rpc error: code = DeadlineExceeded desc = context deadline exceeded", "interval": "13.485224802s"}
2025-07-10T14:11:55.572+0530	info	internal/retry_sender.go:133	Exporting failed. Will retry the request after interval.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "error": "rpc error: code = DeadlineExceeded desc = context deadline exceeded", "interval": "6.60605445s"}
2025-07-10T14:12:01.072+0530	info	transport/http2_client.go:1646	[transport] [client-transport 0x14001a5a248] Closing: connection error: desc = "error reading from server: read tcp 192.168.31.224:54960->162.247.241.110:4317: read: operation timed out"	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:12:01.073+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to IDLE	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:12:01.073+0530	info	transport/controlbuf.go:580	[transport] [client-transport 0x14001a5a248] loopyWriter exiting with error: connection error: desc = "error reading from server: read tcp 192.168.31.224:54960->162.247.241.110:4317: read: operation timed out"	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:12:01.073+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to IDLE	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:12:01.073+0530	info	internal/retry_sender.go:133	Exporting failed. Will retry the request after interval.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "otlp/newrelic", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "error": "rpc error: code = Unavailable desc = error reading from server: read tcp 192.168.31.224:54960->162.247.241.110:4317: read: operation timed out", "interval": "12.636353808s"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_async_capable_ratio", help: "Whether the execution plan node is async capable.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_execution_plan_parallel_aware_ratio", help: "Whether the execution plan node is parallel aware.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_node_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.282+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.283+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.283+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.283+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.283+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.283+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.283+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.283+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.283+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:01.283+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:02.179+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:12:02.179+0530	info	grpc@v1.73.0/clientconn.go:1352	[core] [Channel #3 SubChannel #4]Subchannel picks a new address "otlp.nr-data.net:4317" to connect	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:12:02.179+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:12:03.193+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to READY	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:12:03.193+0530	info	pickfirstleaf/pickfirstleaf.go:197	[pick-first-leaf-lb] [pick-first-leaf-lb 0x140011a4a20] SubConn 0x140017f01e0 reported connectivity state READY and the health listener is disabled. Transitioning SubConn to READY.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:12:03.193+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to READY	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:12:20.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:12:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:12:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:12:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:12:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T14:12:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:12:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:12:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:12:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:12:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:12:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:12:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:12:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:12:20.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:12:20.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:12:20.518+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:12:20.518+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:12:20.518+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:12:20.518+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:12:20.518+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:12:20.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:12:20.718+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:20.718+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:20.718+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:20.718+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:20.719+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:20.719+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:20.719+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:20.719+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:20.719+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:20.719+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:20.719+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T14:12:20.720+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.489441 +0000 UTC
Value: 20819
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.489441 +0000 UTC
Value: 39491
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.489441 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.489441 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.489441 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.489441 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.489441 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.489441 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.517397 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.512634 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.489441 +0000 UTC
Value: 1618
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:20.489441 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:50.501+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:12:50.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:12:50.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:12:50.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:12:50.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T14:12:50.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:12:50.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:12:50.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:12:50.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:12:50.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:12:50.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:12:50.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:12:50.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:12:50.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:12:50.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:12:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:12:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:12:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:12:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:12:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:12:50.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:12:50.665+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:50.665+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:50.665+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:50.665+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:50.665+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:50.665+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:50.665+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:50.665+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:50.665+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:50.665+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:12:50.665+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 51}
2025-07-10T14:12:50.666+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.489282 +0000 UTC
Value: 20834
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.489282 +0000 UTC
Value: 39498
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.489282 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.489282 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.489282 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.489282 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.489282 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.489282 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.510515 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.507087 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.489282 +0000 UTC
Value: 1626
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:42:50.489282 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:20.503+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:13:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:13:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:13:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:13:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 2, "avg_elapsed_time_ms": 1504.572}
2025-07-10T14:13:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:13:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:13:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:13:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:13:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:13:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:13:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:13:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:13:20.513+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:13:20.513+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:13:20.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:13:20.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:13:20.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:13:20.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:13:20.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:13:20.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:13:20.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:20.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:20.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:20.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:20.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:20.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:20.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:20.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:20.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:20.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:20.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.wait.event.total_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:20.611+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 11, "data points": 53}
2025-07-10T14:13:20.611+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.489211 +0000 UTC
Value: 20849
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.489211 +0000 UTC
Value: 39503
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.489211 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.489211 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.489211 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.489211 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.489211 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.489211 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 1504.572000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.513149 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(0f2f9613fe5539002a680dc6db8c4a48)
     -> postgresql.query.text: Str(
BEGIN; 
-- Create a table and lock it
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = 1 WHERE id = 1;
-- This will keep the transaction open (we'll close it manually)
SELECT 'Transaction started, table locked. Will sleep for 30 seconds to allow blocking test.';
SELECT pg_sleep(30);
COMMIT;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.513149 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 2
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.508789 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.489211 +0000 UTC
Value: 1635
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.489211 +0000 UTC
Value: 203
Metric #10
Descriptor:
     -> Name: postgresql.wait.event.total_time
     -> Description: Total wait time for the wait event in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(unknown)
     -> postgresql.query.text: Str(
BEGIN; 
-- Create a table and lock it
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = 1 WHERE id = 1;
-- This will keep the transaction open (we'll close it manually)
SELECT 'Transaction started, table locked. Will sleep for 30 seconds to allow blocking test.';
SELECT pg_sleep(30);
COMMIT;
)
     -> postgresql.wait.event.name: Str(Timeout:PgSleep)
     -> postgresql.wait.category: Str(Other)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:20.510777 +0000 UTC
Value: 19300.931000
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:50.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:13:50.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:13:50.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:13:50.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:13:50.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 11014.523}
2025-07-10T14:13:50.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:13:50.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:13:50.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:13:50.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:13:50.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:13:50.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:13:50.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:13:50.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:13:50.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:13:50.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:13:50.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:13:50.513+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:13:50.513+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:13:50.513+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:13:50.513+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:13:50.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:13:50.553+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:50.553+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:50.553+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:50.554+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:50.554+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:50.554+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:50.554+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:50.554+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:50.554+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:50.554+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:50.554+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.wait.event.total_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:13:50.554+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 11, "data points": 53}
2025-07-10T14:13:50.554+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.489112 +0000 UTC
Value: 20870
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.489112 +0000 UTC
Value: 39510
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.489112 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.489112 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.489112 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.489112 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.489112 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.489112 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 11014.523000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.512235 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(8370f3605d98902a9c881a1b04bdb863)
     -> postgresql.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.512235 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 3
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.508392 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.489112 +0000 UTC
Value: 1643
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.489112 +0000 UTC
Value: 203
Metric #10
Descriptor:
     -> Name: postgresql.wait.event.total_time
     -> Description: Total wait time for the wait event in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(unknown)
     -> postgresql.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
     -> postgresql.wait.event.name: Str(Timeout:PgSleep)
     -> postgresql.wait.category: Str(Other)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:43:50.510024 +0000 UTC
Value: 3313.013000
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.async_capable	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.execution_plan.parallel_aware	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:18.778+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.504+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:14:20.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:14:20.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:14:20.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 11014.523}
2025-07-10T14:14:20.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:14:20.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:14:20.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:14:20.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:14:20.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:14:20.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:14:20.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 11.23}
2025-07-10T14:14:20.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 10}
2025-07-10T14:14:20.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:14:20.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:14:20.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:14:20.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:14:20.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:14:20.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:14:20.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:14:20.516+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:14:20.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.blocked.session.pid	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.blocking.session.duration	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.blocking.session.pid	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.blocking.session.wait_event	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.blocking.session.wait_event_type	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.695+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.696+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.wait.event.total_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:20.696+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 16, "data points": 60}
2025-07-10T14:14:20.696+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.blocked.session.pid
     -> Description: Process ID of the blocked session.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.513604 +0000 UTC
Value: 16522
Metric #1
Descriptor:
     -> Name: postgresql.blocking.session.duration
     -> Description: Duration for which the session has been blocking.
     -> Unit: s
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.blocked.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
     -> postgresql.blocking.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.513604 +0000 UTC
Value: 26.250539
Metric #2
Descriptor:
     -> Name: postgresql.blocking.session.pid
     -> Description: Process ID of the blocking session.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.513604 +0000 UTC
Value: 16504
Metric #3
Descriptor:
     -> Name: postgresql.blocking.session.wait_event
     -> Description: Wait event for the blocking session.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.blocked.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
     -> postgresql.blocking.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
     -> postgresql.wait.event: Str(transactionid)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.513604 +0000 UTC
Value: 1
Metric #4
Descriptor:
     -> Name: postgresql.blocking.session.wait_event_type
     -> Description: Wait event type for the blocking session.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.blocked.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
     -> postgresql.blocking.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
     -> postgresql.wait.event.type: Str(Lock)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.513604 +0000 UTC
Value: 1
Metric #5
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.488986 +0000 UTC
Value: 20886
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.488986 +0000 UTC
Value: 39515
Metric #6
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.488986 +0000 UTC
Value: 4
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.488986 +0000 UTC
Value: 1
Metric #7
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.488986 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.488986 +0000 UTC
Value: 100
Metric #8
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.488986 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.488986 +0000 UTC
Value: 3
Metric #9
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 255.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 918.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 28.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 43.000000
Metric #10
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 24.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 0.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 6.000000
Metric #11
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 20014.432000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 11014.523000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 144.601000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 143.521000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 94.970000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 67.739000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 44.676000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 13.782000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 11.230000
Metric #12
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.514421 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(29fb734db43622759b3a6d90ead73070)
     -> postgresql.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.514421 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(8370f3605d98902a9c881a1b04bdb863)
     -> postgresql.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.514421 +0000 UTC
Value: 0.000000
Metric #13
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 1
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 3
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 1
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 3
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 1
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.51042 +0000 UTC
Value: 1
Metric #14
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.488986 +0000 UTC
Value: 1651
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.488986 +0000 UTC
Value: 203
Metric #15
Descriptor:
     -> Name: postgresql.wait.event.total_time
     -> Description: Total wait time for the wait event in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(unknown)
     -> postgresql.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
     -> postgresql.wait.event.name: Str(Timeout:PgSleep)
     -> postgresql.wait.category: Str(Other)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.512244 +0000 UTC
Value: 33315.296000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(unknown)
     -> postgresql.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
     -> postgresql.wait.event.name: Str(Lock:transactionid)
     -> postgresql.wait.category: Str(Locks)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:20.512244 +0000 UTC
Value: 26249.026000
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_type_ratio", help: "Wait event type for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_pid_ratio", help: "Process ID of the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_duration_seconds", help: "Duration for which the session has been blocking.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_ratio", help: "Wait event for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocked_session_pid_ratio", help: "Process ID of the blocked session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:44.688+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:50.501+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:14:50.506+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:14:50.506+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:14:50.506+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:14:50.506+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:14:50.506+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 17646.179}
2025-07-10T14:14:50.506+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:14:50.506+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:14:50.506+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:14:50.506+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:14:50.506+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:14:50.506+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:14:50.506+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:14:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:14:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:14:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:14:50.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:14:50.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:14:50.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:14:50.513+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:14:50.513+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:14:50.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:14:50.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:50.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:50.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:50.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:50.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:50.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:50.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:50.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:50.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:50.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:50.643+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:14:50.643+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.488866 +0000 UTC
Value: 20903
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.488866 +0000 UTC
Value: 39522
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.488866 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.488866 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.488866 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.488866 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.488866 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.488866 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 17646.179000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.510866 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 3
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.506563 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.488866 +0000 UTC
Value: 1659
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:44:50.488866 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.635+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.635+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.635+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.635+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_type_ratio", help: "Wait event type for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.635+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.635+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.635+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.635+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.635+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.635+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_pid_ratio", help: "Process ID of the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_duration_seconds", help: "Duration for which the session has been blocking.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_ratio", help: "Wait event for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocked_session_pid_ratio", help: "Process ID of the blocked session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:14:58.636+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_type_ratio", help: "Wait event type for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_pid_ratio", help: "Process ID of the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_duration_seconds", help: "Duration for which the session has been blocking.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_ratio", help: "Wait event for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocked_session_pid_ratio", help: "Process ID of the blocked session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:10.034+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:20.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:15:20.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:15:20.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:15:20.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:15:20.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:15:20.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 17646.179}
2025-07-10T14:15:20.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:15:20.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:15:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:15:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:15:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:15:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:15:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:15:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:15:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:15:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:15:20.513+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:15:20.513+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:15:20.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:15:20.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:15:20.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:15:20.515+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:15:20.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:20.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:20.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:20.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:20.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:20.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:20.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:20.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:20.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:20.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:20.588+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:15:20.589+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.488801 +0000 UTC
Value: 20916
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.488801 +0000 UTC
Value: 39527
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.488801 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.488801 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.488801 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.488801 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.488801 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.488801 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 17646.179000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.511901 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 3
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.507869 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.488801 +0000 UTC
Value: 1668
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:20.488801 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:50.507+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:15:50.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:15:50.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:15:50.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:15:50.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:15:50.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 17646.179}
2025-07-10T14:15:50.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:15:50.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:15:50.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:15:50.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:15:50.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:15:50.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:15:50.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:15:50.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:15:50.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:15:50.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:15:50.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:15:50.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:15:50.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:15:50.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:15:50.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:15:50.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:15:50.530+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:50.530+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:50.530+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:50.530+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:50.530+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:50.530+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:50.530+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:50.530+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:50.530+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:50.530+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:15:50.530+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:15:50.531+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.488707 +0000 UTC
Value: 20931
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.488707 +0000 UTC
Value: 39534
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.488707 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.488707 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.488707 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.488707 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.488707 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.488707 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 17646.179000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.518725 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 3
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.514509 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.488707 +0000 UTC
Value: 1677
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:45:50.488707 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:16:20.522+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:16:20.522+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:16:20.522+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:16:20.522+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:16:20.522+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 17646.179}
2025-07-10T14:16:20.522+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:16:20.522+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:16:20.522+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:16:20.523+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:16:20.523+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:16:20.523+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:16:20.523+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:16:20.529+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:16:20.529+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:16:20.529+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:16:20.530+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:16:20.530+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:16:20.530+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:16:20.531+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:16:20.531+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:16:20.531+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:16:20.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:20.673+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:20.673+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:20.673+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:20.673+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:20.673+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:20.673+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:20.673+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:20.673+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:20.673+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:20.673+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:16:20.674+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.488589 +0000 UTC
Value: 20944
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.488589 +0000 UTC
Value: 39539
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.488589 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.488589 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.488589 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.488589 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.488589 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.488589 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 17646.179000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.528821 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 3
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.522831 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.488589 +0000 UTC
Value: 1686
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:20.488589 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:16:50.518+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:16:50.518+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:16:50.518+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:16:50.518+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:16:50.518+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 17646.179}
2025-07-10T14:16:50.518+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:16:50.518+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:16:50.518+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:16:50.518+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:16:50.518+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:16:50.518+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:16:50.518+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:16:50.522+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:16:50.522+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:16:50.523+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:16:50.523+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:16:50.523+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:16:50.523+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:16:50.523+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:16:50.524+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:16:50.524+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:16:50.619+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:50.619+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:50.619+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:50.619+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:50.619+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:50.619+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:50.619+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:50.619+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:50.619+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:50.619+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:16:50.619+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:16:50.620+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.488538 +0000 UTC
Value: 20959
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.488538 +0000 UTC
Value: 39546
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.488538 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.488538 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.488538 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.488538 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.488538 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.488538 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 17646.179000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.5223 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 3
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.518108 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.488538 +0000 UTC
Value: 1695
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:46:50.488538 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:17:20.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:17:20.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:17:20.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:17:20.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:17:20.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 17646.179}
2025-07-10T14:17:20.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:17:20.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:17:20.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:17:20.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:17:20.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:17:20.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:17:20.519+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:17:20.523+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:17:20.523+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:17:20.524+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:17:20.524+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:17:20.524+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:17:20.525+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:17:20.525+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:17:20.525+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:17:20.525+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:17:20.565+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:20.565+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:20.565+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:20.565+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:20.565+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:20.565+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:20.565+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:20.565+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:20.565+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:20.565+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:20.565+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:17:20.565+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.488398 +0000 UTC
Value: 20972
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.488398 +0000 UTC
Value: 39551
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.488398 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.488398 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.488398 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.488398 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.488398 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.488398 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 17646.179000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.52347 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 3
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.519117 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.488398 +0000 UTC
Value: 1704
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:20.488398 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:17:50.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:17:50.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:17:50.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:17:50.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:17:50.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 17646.179}
2025-07-10T14:17:50.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:17:50.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:17:50.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:17:50.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:17:50.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:17:50.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:17:50.517+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:17:50.522+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:17:50.522+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:17:50.523+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:17:50.523+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:17:50.523+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:17:50.524+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:17:50.524+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:17:50.524+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:17:50.524+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:17:50.710+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:50.710+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:50.710+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:50.710+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:50.710+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:50.711+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:50.711+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:50.711+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:50.711+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:50.711+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:17:50.711+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:17:50.712+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.488248 +0000 UTC
Value: 20987
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.488248 +0000 UTC
Value: 39558
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.488248 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.488248 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.488248 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.488248 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.488248 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.488248 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 17646.179000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.522225 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 3
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.51733 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.488248 +0000 UTC
Value: 1713
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:47:50.488248 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.133+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.133+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.133+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.133+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_type_ratio", help: "Wait event type for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.133+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.133+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.133+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.133+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.133+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.133+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.133+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.133+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.133+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.133+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_pid_ratio", help: "Process ID of the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_duration_seconds", help: "Duration for which the session has been blocking.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.134+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.135+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_ratio", help: "Wait event for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.135+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.135+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocked_session_pid_ratio", help: "Process ID of the blocked session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.135+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.135+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.135+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.135+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.135+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.135+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.135+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.135+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.135+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.136+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.136+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.136+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.136+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.136+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.136+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.136+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.136+0530	debug	prometheusexporter@v0.129.0/collector.go:479	metric expired	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "instrument": "postgresql_execution_plan_async_capable_ratio"}
2025-07-10T14:18:20.136+0530	debug	prometheusexporter@v0.129.0/collector.go:479	metric expired	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "instrument": "postgresql_execution_plan_parallel_aware_ratio"}
2025-07-10T14:18:20.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:18:20.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:18:20.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:18:20.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:18:20.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 17646.179}
2025-07-10T14:18:20.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:18:20.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:18:20.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:18:20.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:18:20.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:18:20.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:18:20.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:18:20.525+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:18:20.525+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:18:20.525+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:18:20.526+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:18:20.526+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:18:20.526+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:18:20.526+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:18:20.527+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:18:20.527+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:18:20.656+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.656+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.656+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.656+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.656+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.656+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.656+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.657+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.657+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.657+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:20.657+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:18:20.657+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.488208 +0000 UTC
Value: 21000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.488208 +0000 UTC
Value: 39563
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.488208 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.488208 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.488208 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.488208 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.488208 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.488208 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 17646.179000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.525155 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 3
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.520354 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.488208 +0000 UTC
Value: 1722
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:20.488208 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.836+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.836+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/accumulator.go:311	metric expired: postgresql.wait.event.total_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_type_ratio", help: "Wait event type for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.837+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_pid_ratio", help: "Process ID of the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_duration_seconds", help: "Duration for which the session has been blocking.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_ratio", help: "Wait event for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocked_session_pid_ratio", help: "Process ID of the blocked session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:46.838+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:47.684+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:47.684+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:47.685+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_type_ratio", help: "Wait event type for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:47.685+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:47.685+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:47.685+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:47.685+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:47.685+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_pid_ratio", help: "Process ID of the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:47.685+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:47.686+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_duration_seconds", help: "Duration for which the session has been blocking.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:47.686+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_ratio", help: "Wait event for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:47.686+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:47.686+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocked_session_pid_ratio", help: "Process ID of the blocked session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:47.686+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:47.686+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:47.686+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:47.686+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.331+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.331+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.331+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_type_ratio", help: "Wait event type for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.331+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.331+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.331+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.331+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.331+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_pid_ratio", help: "Process ID of the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.331+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.331+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_duration_seconds", help: "Duration for which the session has been blocking.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.331+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_ratio", help: "Wait event for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.331+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.331+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocked_session_pid_ratio", help: "Process ID of the blocked session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.332+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.332+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.332+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.332+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.902+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.902+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.903+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_type_ratio", help: "Wait event type for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.903+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.903+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.903+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_cpu_time_milliseconds", help: "CPU time consumed by the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.903+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.903+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_pid_ratio", help: "Process ID of the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.903+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.903+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_duration_seconds", help: "Duration for which the session has been blocking.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.903+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_ratio", help: "Wait event for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.903+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.903+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocked_session_pid_ratio", help: "Process ID of the blocked session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.903+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:48.903+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.450+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.450+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.450+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_type_ratio", help: "Wait event type for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.450+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.450+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.450+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.451+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_pid_ratio", help: "Process ID of the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.451+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_wait_event_total_time_milliseconds", help: "Total wait time for the wait event in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_wait_event_name,postgresql_wait_category,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.451+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_duration_seconds", help: "Duration for which the session has been blocking.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.451+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_ratio", help: "Wait event for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.451+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_rollbacks_total", help: "The number of rollbacks.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.451+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocked_session_pid_ratio", help: "Process ID of the blocked session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.451+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.451+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_commits_total", help: "The number of commits.", constLabels: {}, variableLabels: {postgresql_database_name,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.899+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.899+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.899+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_type_ratio", help: "Wait event type for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.900+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_pid_ratio", help: "Process ID of the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.900+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_duration_seconds", help: "Duration for which the session has been blocking.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.900+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_ratio", help: "Wait event for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.900+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocked_session_pid_ratio", help: "Process ID of the blocked session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:49.900+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.483+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.483+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.483+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_type_ratio", help: "Wait event type for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.483+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_pid_ratio", help: "Process ID of the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.483+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_duration_seconds", help: "Duration for which the session has been blocking.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.483+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_ratio", help: "Wait event for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.483+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocked_session_pid_ratio", help: "Process ID of the blocked session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.483+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:18:50.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:18:50.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:18:50.520+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:18:50.521+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 17646.179}
2025-07-10T14:18:50.521+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:18:50.521+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:18:50.521+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:18:50.521+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:18:50.521+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:18:50.521+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:18:50.521+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:18:50.525+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:18:50.525+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:18:50.525+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:18:50.526+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:18:50.526+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:18:50.526+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:18:50.526+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:18:50.526+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:18:50.527+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:18:50.603+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.603+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.603+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.603+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.603+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.603+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.603+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.603+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.603+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.604+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:50.604+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:18:50.604+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.488069 +0000 UTC
Value: 21015
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.488069 +0000 UTC
Value: 39570
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.488069 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.488069 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.488069 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.488069 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.488069 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.488069 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 17646.179000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.525111 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 3
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.520865 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.488069 +0000 UTC
Value: 1731
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:48:50.488069 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:51.317+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:51.317+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:51.317+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_type_ratio", help: "Wait event type for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:51.318+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_pid_ratio", help: "Process ID of the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:51.318+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_duration_seconds", help: "Duration for which the session has been blocking.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:51.318+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_ratio", help: "Wait event for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:51.318+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocked_session_pid_ratio", help: "Process ID of the blocked session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:51.318+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:53.048+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:53.048+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:53.048+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_type_ratio", help: "Wait event type for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:53.048+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_pid_ratio", help: "Process ID of the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:53.048+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_duration_seconds", help: "Duration for which the session has been blocking.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:53.049+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_ratio", help: "Wait event for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:53.049+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocked_session_pid_ratio", help: "Process ID of the blocked session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:53.049+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:54.265+0530	debug	prometheusexporter@v0.129.0/collector.go:413	collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:54.265+0530	debug	prometheusexporter@v0.129.0/accumulator.go:298	Accumulator collect called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:54.265+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_type_ratio", help: "Wait event type for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:54.265+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_pid_ratio", help: "Process ID of the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:54.265+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_duration_seconds", help: "Duration for which the session has been blocking.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:54.265+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocking_session_wait_event_ratio", help: "Wait event for the blocking session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_blocked_query_text,postgresql_blocking_query_text,postgresql_wait_event,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:54.265+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_blocked_session_pid_ratio", help: "Process ID of the blocked session.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_text,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:54.266+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_connection_max_ratio", help: "Maximum number of client connections allowed.", constLabels: {}, variableLabels: {otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:54.266+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_writes_ratio", help: "Average number of disk writes per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:54.266+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_disk_reads_ratio", help: "Average number of disk reads per query execution.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:54.266+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_avg_elapsed_time_milliseconds", help: "Average execution time for the query in milliseconds.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:18:54.266+0530	debug	prometheusexporter@v0.129.0/collector.go:437	metric served: Desc{fqName: "postgresql_query_execution_count_total", help: "Number of times the query was executed.", constLabels: {}, variableLabels: {postgresql_database_name,postgresql_query_id,postgresql_query_text,postgresql_statement_type,otel_scope_name,otel_scope_version,otel_scope_schema_url}}	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:20.499+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:19:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:19:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:19:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:19:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:19:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 17646.179}
2025-07-10T14:19:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:19:20.508+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:19:20.509+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:19:20.509+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:19:20.509+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:19:20.509+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:19:20.509+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:19:20.513+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:19:20.513+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:19:20.513+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:19:20.513+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:19:20.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:19:20.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:19:20.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:19:20.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:19:20.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:19:20.527+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:20.527+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:20.527+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:20.527+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:20.527+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:20.527+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:20.527+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:20.527+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:20.527+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:20.527+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:20.527+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:19:20.527+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.464906 +0000 UTC
Value: 21028
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.464906 +0000 UTC
Value: 39575
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.464906 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.464906 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.464906 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.464906 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.464906 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.464906 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 17646.179000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.512953 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 3
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.508631 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.464906 +0000 UTC
Value: 1740
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:20.464906 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:19:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:19:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:19:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:19:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:19:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 17646.179}
2025-07-10T14:19:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:19:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:19:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:19:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:19:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:19:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:19:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:19:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:19:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:19:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:19:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:19:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:19:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:19:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:19:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:19:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:19:50.667+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:50.668+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:50.668+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:50.668+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:50.668+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:50.668+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:50.668+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:50.668+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:50.668+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:50.669+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:19:50.669+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:19:50.670+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.458395 +0000 UTC
Value: 21043
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.458395 +0000 UTC
Value: 39582
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.458395 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.458395 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.458395 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.458395 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.458395 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.458395 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 17646.179000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.490727 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 3
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.48564 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.458395 +0000 UTC
Value: 1749
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:49:50.458395 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:20:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:20:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:20:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:20:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:20:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 17646.179}
2025-07-10T14:20:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:20:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:20:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:20:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:20:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:20:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:20:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:20:20.499+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:20:20.499+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:20:20.499+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:20:20.500+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:20:20.500+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:20:20.500+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:20:20.500+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:20:20.500+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:20:20.501+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:20:20.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:20.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:20.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:20.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:20.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:20.612+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:20.612+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:20.612+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:20.612+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:20.612+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:20.612+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:20:20.612+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.457279 +0000 UTC
Value: 21056
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.457279 +0000 UTC
Value: 39587
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.457279 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.457279 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.457279 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.457279 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.457279 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.457279 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 17646.179000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.499105 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 3
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.495483 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.457279 +0000 UTC
Value: 1758
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:20.457279 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:20:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:20:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:20:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:20:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:20:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 17646.179}
2025-07-10T14:20:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:20:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:20:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:20:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:20:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:20:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:20:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:20:50.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:20:50.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:20:50.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:20:50.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:20:50.498+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:20:50.498+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:20:50.498+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:20:50.498+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:20:50.498+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:20:50.557+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:50.557+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:50.557+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:50.557+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:50.557+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:50.557+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:50.557+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:50.558+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:50.558+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:50.558+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:20:50.558+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:20:50.558+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.456876 +0000 UTC
Value: 21071
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.456876 +0000 UTC
Value: 39594
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.456876 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.456876 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.456876 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.456876 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.456876 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.456876 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 17646.179000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.497124 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 3
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.493234 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.456876 +0000 UTC
Value: 1767
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:50:50.456876 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:21:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:21:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:21:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:21:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:21:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 17646.179}
2025-07-10T14:21:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:21:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:21:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:21:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:21:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:21:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:21:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:21:20.498+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:21:20.498+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:21:20.499+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:21:20.499+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:21:20.499+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:21:20.499+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:21:20.499+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:21:20.500+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:21:20.500+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:21:20.699+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:20.699+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:20.699+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:20.699+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:20.699+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:20.700+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:20.700+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:20.700+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:20.700+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:20.700+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:20.700+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:21:20.700+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.456606 +0000 UTC
Value: 21084
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.456606 +0000 UTC
Value: 39599
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.456606 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.456606 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.456606 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.456606 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.456606 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.456606 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 17646.179000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.4982 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 3
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.494449 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.456606 +0000 UTC
Value: 1776
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:20.456606 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:50.480+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:21:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:21:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:21:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:21:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:21:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 17646.179}
2025-07-10T14:21:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:21:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:21:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:21:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:21:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:21:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:21:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:21:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:21:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:21:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:21:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:21:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:21:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:21:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:21:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:21:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:21:50.647+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:50.647+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:50.647+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:50.647+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:50.647+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:50.648+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:50.648+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:50.648+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:50.648+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:50.648+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:21:50.648+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:21:50.648+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.45626 +0000 UTC
Value: 21099
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.45626 +0000 UTC
Value: 39606
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.45626 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.45626 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.45626 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.45626 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.45626 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.45626 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 17646.179000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.490363 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 3
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.486585 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.45626 +0000 UTC
Value: 1785
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:51:50.45626 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:22:20.504+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:22:20.504+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:22:20.504+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:22:20.504+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:22:20.504+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 17646.179}
2025-07-10T14:22:20.504+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:22:20.504+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:22:20.504+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:22:20.504+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:22:20.504+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:22:20.504+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:22:20.505+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:22:20.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:22:20.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:22:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:22:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:22:20.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:22:20.513+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:22:20.513+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:22:20.513+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:22:20.514+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:22:20.589+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:20.589+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:20.589+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:20.589+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:20.589+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:20.589+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:20.589+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:20.589+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:20.589+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:20.589+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:20.589+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:22:20.589+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.456018 +0000 UTC
Value: 21114
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.456018 +0000 UTC
Value: 39611
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.456018 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.456018 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.456018 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.456018 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.456018 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.456018 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 17646.179000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.511084 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 3
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.504699 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.456018 +0000 UTC
Value: 1794
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:20.456018 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:50.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:22:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:22:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:22:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:22:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:22:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 5, "avg_elapsed_time_ms": 10587.712}
2025-07-10T14:22:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:22:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:22:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:22:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:22:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:22:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:22:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:22:50.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:22:50.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:22:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:22:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:22:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:22:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:22:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:22:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:22:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:22:50.534+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:50.534+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:50.534+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:50.534+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:50.534+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:50.534+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:50.534+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:50.534+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:50.534+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:50.534+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:50.534+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.wait.event.total_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:22:50.534+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 11, "data points": 57}
2025-07-10T14:22:50.534+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.455667 +0000 UTC
Value: 21132
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.455667 +0000 UTC
Value: 39618
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.455667 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.455667 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.455667 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.455667 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.455667 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.455667 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 10587.712000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.488217 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(8370f3605d98902a9c881a1b04bdb863)
     -> postgresql.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.488217 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 5
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.484166 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.455667 +0000 UTC
Value: 1803
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.455667 +0000 UTC
Value: 203
Metric #10
Descriptor:
     -> Name: postgresql.wait.event.total_time
     -> Description: Total wait time for the wait event in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(unknown)
     -> postgresql.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
     -> postgresql.wait.event.name: Str(Timeout:PgSleep)
     -> postgresql.wait.category: Str(Other)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:52:50.485824 +0000 UTC
Value: 23697.068000
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:23:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:23:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:23:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 4, "avg_elapsed_time_ms": 23261.372}
2025-07-10T14:23:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:23:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 5, "avg_elapsed_time_ms": 10587.712}
2025-07-10T14:23:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:23:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:23:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:23:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:23:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:23:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:23:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:23:20.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:23:20.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:23:20.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:23:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:23:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:23:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:23:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:23:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:23:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:23:20.671+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:20.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:20.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:20.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:20.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:20.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:20.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:20.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:20.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:20.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:20.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.wait.event.total_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:20.672+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 11, "data points": 57}
2025-07-10T14:23:20.672+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.455388 +0000 UTC
Value: 21148
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.455388 +0000 UTC
Value: 39623
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.455388 +0000 UTC
Value: 4
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.455388 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.455388 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.455388 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.455388 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.455388 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 23261.372000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 10587.712000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.488153 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(8370f3605d98902a9c881a1b04bdb863)
     -> postgresql.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.488153 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 4
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 5
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.484523 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.455388 +0000 UTC
Value: 1812
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.455388 +0000 UTC
Value: 203
Metric #10
Descriptor:
     -> Name: postgresql.wait.event.total_time
     -> Description: Total wait time for the wait event in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(unknown)
     -> postgresql.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
     -> postgresql.wait.event.name: Str(Timeout:PgSleep)
     -> postgresql.wait.category: Str(Other)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:20.48608 +0000 UTC
Value: 53697.832000
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.480+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:23:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:23:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 5, "avg_elapsed_time_ms": 30609.377}
2025-07-10T14:23:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:23:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:23:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:23:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:23:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:23:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:23:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:23:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:23:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:23:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:23:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:23:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:23:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:23:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:23:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:23:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:23:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:23:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:23:50.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.blocked.session.pid	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.blocking.session.duration	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.blocking.session.pid	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.blocking.session.wait_event	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.blocking.session.wait_event_type	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.611+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.wait.event.total_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:23:50.611+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 16, "data points": 64}
2025-07-10T14:23:50.611+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.blocked.session.pid
     -> Description: Process ID of the blocked session.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.488709 +0000 UTC
Value: 17072
Metric #1
Descriptor:
     -> Name: postgresql.blocking.session.duration
     -> Description: Duration for which the session has been blocking.
     -> Unit: s
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.blocked.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
     -> postgresql.blocking.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.488709 +0000 UTC
Value: 14.101403
Metric #2
Descriptor:
     -> Name: postgresql.blocking.session.pid
     -> Description: Process ID of the blocking session.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.488709 +0000 UTC
Value: 17057
Metric #3
Descriptor:
     -> Name: postgresql.blocking.session.wait_event
     -> Description: Wait event for the blocking session.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.blocked.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
     -> postgresql.blocking.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
     -> postgresql.wait.event: Str(transactionid)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.488709 +0000 UTC
Value: 1
Metric #4
Descriptor:
     -> Name: postgresql.blocking.session.wait_event_type
     -> Description: Wait event type for the blocking session.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.blocked.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
     -> postgresql.blocking.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
     -> postgresql.wait.event.type: Str(Lock)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.488709 +0000 UTC
Value: 1
Metric #5
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.455141 +0000 UTC
Value: 21167
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.455141 +0000 UTC
Value: 39630
Metric #6
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.455141 +0000 UTC
Value: 5
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.455141 +0000 UTC
Value: 1
Metric #7
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.455141 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.455141 +0000 UTC
Value: 100
Metric #8
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.455141 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.455141 +0000 UTC
Value: 3
Metric #9
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 43.000000
Metric #10
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 6.000000
Metric #11
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 30609.377000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 11.230000
Metric #12
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.489531 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(29fb734db43622759b3a6d90ead73070)
     -> postgresql.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.489531 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(8370f3605d98902a9c881a1b04bdb863)
     -> postgresql.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.489531 +0000 UTC
Value: 0.000000
Metric #13
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 5
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.4854 +0000 UTC
Value: 1
Metric #14
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.455141 +0000 UTC
Value: 1821
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.455141 +0000 UTC
Value: 203
Metric #15
Descriptor:
     -> Name: postgresql.wait.event.total_time
     -> Description: Total wait time for the wait event in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(unknown)
     -> postgresql.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
     -> postgresql.wait.event.name: Str(Timeout:PgSleep)
     -> postgresql.wait.category: Str(Other)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.487216 +0000 UTC
Value: 21852.534000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(unknown)
     -> postgresql.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
     -> postgresql.wait.event.name: Str(Lock:transactionid)
     -> postgresql.wait.category: Str(Locks)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:53:50.487216 +0000 UTC
Value: 14099.693000
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.480+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:24:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:24:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 5, "avg_elapsed_time_ms": 30609.377}
2025-07-10T14:24:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:24:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:24:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:24:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:24:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:24:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:24:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:24:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:24:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:24:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:24:20.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:24:20.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:24:20.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:24:20.498+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:24:20.498+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:24:20.498+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:24:20.499+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:24:20.500+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:24:20.562+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.blocked.session.pid	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.562+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.blocking.session.duration	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.562+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.blocking.session.pid	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.562+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.blocking.session.wait_event	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.562+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.blocking.session.wait_event_type	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.563+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.563+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.563+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.563+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.563+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.563+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.563+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.563+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.563+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.563+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.563+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.wait.event.total_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:20.564+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 16, "data points": 64}
2025-07-10T14:24:20.564+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.blocked.session.pid
     -> Description: Process ID of the blocked session.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.493788 +0000 UTC
Value: 17072
Metric #1
Descriptor:
     -> Name: postgresql.blocking.session.duration
     -> Description: Duration for which the session has been blocking.
     -> Unit: s
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.blocked.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
     -> postgresql.blocking.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.493788 +0000 UTC
Value: 44.106386
Metric #2
Descriptor:
     -> Name: postgresql.blocking.session.pid
     -> Description: Process ID of the blocking session.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.493788 +0000 UTC
Value: 17057
Metric #3
Descriptor:
     -> Name: postgresql.blocking.session.wait_event
     -> Description: Wait event for the blocking session.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.blocked.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
     -> postgresql.blocking.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
     -> postgresql.wait.event: Str(transactionid)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.493788 +0000 UTC
Value: 1
Metric #4
Descriptor:
     -> Name: postgresql.blocking.session.wait_event_type
     -> Description: Wait event type for the blocking session.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.blocked.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
     -> postgresql.blocking.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
     -> postgresql.wait.event.type: Str(Lock)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.493788 +0000 UTC
Value: 1
Metric #5
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.454814 +0000 UTC
Value: 21182
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.454814 +0000 UTC
Value: 39635
Metric #6
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.454814 +0000 UTC
Value: 5
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.454814 +0000 UTC
Value: 1
Metric #7
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.454814 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.454814 +0000 UTC
Value: 100
Metric #8
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.454814 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.454814 +0000 UTC
Value: 3
Metric #9
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 43.000000
Metric #10
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 6.000000
Metric #11
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 30609.377000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 11.230000
Metric #12
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.495646 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(29fb734db43622759b3a6d90ead73070)
     -> postgresql.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.495646 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(8370f3605d98902a9c881a1b04bdb863)
     -> postgresql.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.495646 +0000 UTC
Value: 0.000000
Metric #13
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 5
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.49003 +0000 UTC
Value: 1
Metric #14
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.454814 +0000 UTC
Value: 1830
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.454814 +0000 UTC
Value: 203
Metric #15
Descriptor:
     -> Name: postgresql.wait.event.total_time
     -> Description: Total wait time for the wait event in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(unknown)
     -> postgresql.query.text: Str(
BEGIN; 
CREATE TABLE IF NOT EXISTS test_lock_table (id INTEGER PRIMARY KEY);
INSERT INTO test_lock_table VALUES (1) ON CONFLICT DO NOTHING;
UPDATE test_lock_table SET id = 1 WHERE id = 1;
SELECT pg_sleep(60);
COMMIT;
)
     -> postgresql.wait.event.name: Str(Timeout:PgSleep)
     -> postgresql.wait.category: Str(Other)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.492121 +0000 UTC
Value: 51857.303000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(unknown)
     -> postgresql.query.text: Str(
UPDATE test_lock_table SET id = 2 WHERE id = 1;
)
     -> postgresql.wait.event.name: Str(Lock:transactionid)
     -> postgresql.wait.category: Str(Locks)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:20.492121 +0000 UTC
Value: 44104.462000
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:24:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:24:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:24:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:24:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:24:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:24:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:24:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:24:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:24:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:24:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:24:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:24:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:24:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:24:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:24:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:24:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:24:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:24:50.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:24:50.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:24:50.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:24:50.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:24:50.503+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:50.503+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:50.503+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:50.503+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:50.503+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:50.503+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:50.503+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:50.503+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:50.503+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:50.503+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:24:50.503+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:24:50.503+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.454568 +0000 UTC
Value: 21198
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.454568 +0000 UTC
Value: 39642
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.454568 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.454568 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.454568 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.454568 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.454568 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.454568 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.495793 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.491488 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.454568 +0000 UTC
Value: 1840
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:54:50.454568 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:20.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:25:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:25:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:25:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:25:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:25:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:25:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:25:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:25:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:25:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:25:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:25:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:25:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:25:20.499+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:25:20.500+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:25:20.500+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:25:20.500+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:25:20.501+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:25:20.501+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:25:20.501+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:25:20.501+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:25:20.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:25:20.649+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:20.649+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:20.649+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:20.649+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:20.649+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:20.649+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:20.650+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:20.650+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:20.650+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:20.650+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:20.650+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:25:20.650+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.454289 +0000 UTC
Value: 21211
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.454289 +0000 UTC
Value: 39647
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.454289 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.454289 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.454289 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.454289 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.454289 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.454289 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.499605 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.494172 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.454289 +0000 UTC
Value: 1849
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:20.454289 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:50.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:25:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:25:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:25:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:25:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:25:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:25:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:25:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:25:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:25:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:25:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:25:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:25:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:25:50.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:25:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:25:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:25:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:25:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:25:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:25:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:25:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:25:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:25:50.594+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:50.594+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:50.594+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:50.594+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:50.594+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:50.594+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:50.594+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:50.595+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:50.595+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:50.595+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:25:50.595+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:25:50.595+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.454023 +0000 UTC
Value: 21226
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.454023 +0000 UTC
Value: 39654
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.454023 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.454023 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.454023 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.454023 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.454023 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.454023 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.494721 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.490926 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.454023 +0000 UTC
Value: 1858
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:55:50.454023 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:20.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:26:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:26:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:26:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:26:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:26:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:26:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:26:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:26:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:26:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:26:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:26:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:26:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:26:20.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:26:20.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:26:20.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:26:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:26:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:26:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:26:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:26:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:26:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:26:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:20.535+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:26:20.536+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.453751 +0000 UTC
Value: 21239
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.453751 +0000 UTC
Value: 39659
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.453751 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.453751 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.453751 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.453751 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.453751 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.453751 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.493042 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.489138 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.453751 +0000 UTC
Value: 1867
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:20.453751 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:26:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:26:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:26:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:26:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:26:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:26:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:26:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:26:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:26:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:26:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:26:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:26:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:26:50.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:26:50.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:26:50.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:26:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:26:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:26:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:26:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:26:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:26:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:26:50.693+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:50.693+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:50.693+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:50.693+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:50.693+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:50.693+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:50.693+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:50.693+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:50.693+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:50.693+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:26:50.693+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:26:50.693+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.453444 +0000 UTC
Value: 21254
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.453444 +0000 UTC
Value: 39666
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.453444 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.453444 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.453444 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.453444 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.453444 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.453444 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.494092 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.490335 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.453444 +0000 UTC
Value: 1876
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:56:50.453444 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:20.474+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:27:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:27:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:27:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:27:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:27:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:27:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:27:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:27:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:27:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:27:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:27:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:27:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:27:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:27:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:27:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:27:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:27:20.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:27:20.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:27:20.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:27:20.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:27:20.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:27:20.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:20.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:20.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:20.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:20.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:20.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:20.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:20.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:20.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:20.643+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:20.644+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:27:20.644+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.453143 +0000 UTC
Value: 21267
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.453143 +0000 UTC
Value: 39671
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.453143 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.453143 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.453143 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.453143 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.453143 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.453143 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.490624 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.483839 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.453143 +0000 UTC
Value: 1885
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:20.453143 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:27:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:27:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:27:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:27:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:27:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:27:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:27:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:27:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:27:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:27:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:27:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:27:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:27:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:27:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:27:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:27:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:27:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:27:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:27:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:27:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:27:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:27:50.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:50.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:50.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:50.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:50.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:50.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:50.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:50.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:50.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:50.588+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:27:50.588+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:27:50.589+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.452848 +0000 UTC
Value: 21282
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.452848 +0000 UTC
Value: 39678
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.452848 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.452848 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.452848 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.452848 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.452848 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.452848 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.489792 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.485904 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.452848 +0000 UTC
Value: 1894
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:57:50.452848 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:20.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:28:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:28:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:28:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:28:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:28:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:28:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:28:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:28:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:28:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:28:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:28:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:28:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:28:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:28:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:28:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:28:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:28:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:28:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:28:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:28:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:28:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:28:20.536+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:20.536+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:20.536+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:20.536+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:20.537+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:20.537+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:20.537+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:20.537+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:20.537+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:20.537+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:20.537+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:28:20.537+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.452601 +0000 UTC
Value: 21295
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.452601 +0000 UTC
Value: 39683
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.452601 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.452601 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.452601 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.452601 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.452601 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.452601 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.4938 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.489966 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.452601 +0000 UTC
Value: 1903
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:20.452601 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:50.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:28:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:28:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:28:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:28:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:28:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:28:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:28:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:28:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:28:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:28:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:28:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:28:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:28:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:28:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:28:50.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:28:50.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:28:50.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:28:50.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:28:50.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:28:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:28:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:28:50.677+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:50.677+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:50.677+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:50.677+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:50.677+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:50.677+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:50.677+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:50.677+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:50.677+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:50.678+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:28:50.678+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:28:50.678+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.452279 +0000 UTC
Value: 21310
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.452279 +0000 UTC
Value: 39690
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.452279 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.452279 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.452279 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.452279 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.452279 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.452279 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.493191 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.489435 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.452279 +0000 UTC
Value: 1912
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:58:50.452279 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:29:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:29:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:29:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:29:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:29:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:29:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:29:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:29:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:29:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:29:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:29:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:29:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:29:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:29:20.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:29:20.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:29:20.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:29:20.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:29:20.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:29:20.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:29:20.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:29:20.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:29:20.622+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:20.622+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:20.622+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:20.622+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:20.622+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:20.622+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:20.622+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:20.622+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:20.622+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:20.622+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:20.622+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:29:20.622+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.45208 +0000 UTC
Value: 21323
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.45208 +0000 UTC
Value: 39695
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.45208 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.45208 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.45208 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.45208 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.45208 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.45208 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.495506 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.491564 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.45208 +0000 UTC
Value: 1921
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:20.45208 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:29:50.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:29:50.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:29:50.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:29:50.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:29:50.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:29:50.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:29:50.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:29:50.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:29:50.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:29:50.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:29:50.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:29:50.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:29:50.509+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:29:50.509+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:29:50.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:29:50.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:29:50.510+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:29:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:29:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:29:50.511+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:29:50.512+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:29:50.562+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:50.562+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:50.562+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:50.562+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:50.562+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:50.562+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:50.562+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:50.562+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:50.562+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:50.562+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:29:50.562+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:29:50.563+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.45176 +0000 UTC
Value: 21338
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.45176 +0000 UTC
Value: 39702
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.45176 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.45176 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.45176 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.45176 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.45176 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.45176 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.509051 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.502193 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.45176 +0000 UTC
Value: 1930
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 08:59:50.45176 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:30:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:30:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:30:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:30:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:30:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:30:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:30:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:30:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:30:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:30:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:30:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:30:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:30:20.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:30:20.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:30:20.502+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:30:20.503+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:30:20.503+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:30:20.504+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:30:20.504+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:30:20.504+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:30:20.504+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:30:20.511+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:20.511+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:20.511+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:20.511+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:20.511+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:20.511+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:20.511+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:20.511+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:20.511+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:20.511+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:20.512+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:30:20.512+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.451456 +0000 UTC
Value: 21351
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.451456 +0000 UTC
Value: 39707
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.451456 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.451456 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.451456 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.451456 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.451456 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.451456 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.501839 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.494648 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.451456 +0000 UTC
Value: 1939
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:20.451456 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:50.480+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:30:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:30:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:30:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:30:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:30:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:30:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:30:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:30:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:30:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:30:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:30:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:30:50.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:30:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:30:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:30:50.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:30:50.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:30:50.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:30:50.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:30:50.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:30:50.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:30:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:30:50.651+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:50.651+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:50.651+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:50.651+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:50.651+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:50.651+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:50.651+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:50.652+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:50.652+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:50.652+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:30:50.652+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:30:50.653+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.451177 +0000 UTC
Value: 21366
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.451177 +0000 UTC
Value: 39714
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.451177 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.451177 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.451177 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.451177 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.451177 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.451177 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.49307 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.489106 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.451177 +0000 UTC
Value: 1948
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:00:50.451177 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:20.475+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:31:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:31:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:31:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:31:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:31:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:31:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:31:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:31:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:31:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:31:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:31:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:31:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:31:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:31:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:31:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:31:20.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:31:20.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:31:20.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:31:20.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:31:20.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:31:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:31:20.590+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:20.590+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:20.590+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:20.590+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:20.590+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:20.590+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:20.590+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:20.590+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:20.590+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:20.590+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:20.591+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:31:20.591+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.450877 +0000 UTC
Value: 21379
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.450877 +0000 UTC
Value: 39719
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.450877 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.450877 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.450877 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.450877 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.450877 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.450877 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.48713 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.483507 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.450877 +0000 UTC
Value: 1957
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:20.450877 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:31:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:31:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:31:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:31:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:31:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:31:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:31:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:31:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:31:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:31:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:31:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:31:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:31:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:31:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:31:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:31:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:31:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:31:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:31:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:31:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:31:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:31:50.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:50.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:50.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:50.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:50.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:50.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:50.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:50.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:50.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:50.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:31:50.535+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:31:50.536+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.45062 +0000 UTC
Value: 21394
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.45062 +0000 UTC
Value: 39726
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.45062 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.45062 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.45062 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.45062 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.45062 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.45062 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.494852 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.490532 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.45062 +0000 UTC
Value: 1966
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:01:50.45062 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:20.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:32:20.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:32:20.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:32:20.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:32:20.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:32:20.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:32:20.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:32:20.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:32:20.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:32:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:32:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:32:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:32:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:32:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:32:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:32:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:32:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:32:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:32:20.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:32:20.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:32:20.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:32:20.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:32:20.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:20.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:20.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:20.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:20.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:20.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:20.673+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:20.673+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:20.673+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:20.673+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:20.673+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:32:20.673+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.450328 +0000 UTC
Value: 21407
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.450328 +0000 UTC
Value: 39731
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.450328 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.450328 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.450328 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.450328 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.450328 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.450328 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.490737 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.486745 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.450328 +0000 UTC
Value: 1975
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:20.450328 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:32:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:32:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:32:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:32:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:32:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:32:50.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:32:50.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:32:50.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:32:50.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:32:50.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:32:50.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:32:50.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:32:50.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:32:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:32:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:32:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:32:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:32:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:32:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:32:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:32:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:32:50.615+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:50.615+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:50.615+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:50.615+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:50.615+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:50.615+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:50.616+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:50.616+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:50.616+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:50.616+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:32:50.616+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:32:50.617+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.45006 +0000 UTC
Value: 21422
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.45006 +0000 UTC
Value: 39738
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.45006 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.45006 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.45006 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.45006 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.45006 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.45006 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.490564 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.486837 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.45006 +0000 UTC
Value: 1984
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:02:50.45006 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:20.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:33:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:33:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:33:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:33:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:33:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:33:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:33:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:33:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:33:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:33:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:33:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:33:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:33:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:33:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:33:20.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:33:20.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:33:20.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:33:20.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:33:20.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:33:20.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:33:20.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:33:20.561+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:20.561+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:20.561+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:20.561+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:20.561+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:20.561+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:20.561+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:20.561+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:20.562+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:20.562+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:20.562+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:33:20.562+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.449794 +0000 UTC
Value: 21435
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.449794 +0000 UTC
Value: 39743
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.449794 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.449794 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.449794 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.449794 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.449794 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.449794 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.491257 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.487362 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.449794 +0000 UTC
Value: 1993
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:20.449794 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:50.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:33:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:33:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:33:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:33:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:33:50.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:33:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:33:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:33:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:33:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:33:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:33:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:33:50.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:33:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:33:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:33:50.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:33:50.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:33:50.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:33:50.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:33:50.498+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:33:50.498+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:33:50.498+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:33:50.507+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:50.507+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:50.507+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:50.507+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:50.507+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:50.507+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:50.507+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:50.507+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:50.507+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:50.507+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:33:50.507+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:33:50.508+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.449477 +0000 UTC
Value: 21450
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.449477 +0000 UTC
Value: 39750
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.449477 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.449477 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.449477 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.449477 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.449477 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.449477 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.496289 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.491686 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.449477 +0000 UTC
Value: 2002
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:03:50.449477 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:20.480+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:34:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:34:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:34:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:34:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:34:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:34:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:34:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:34:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:34:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:34:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:34:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:34:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:34:20.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:34:20.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:34:20.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:34:20.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:34:20.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:34:20.498+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:34:20.498+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:34:20.498+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:34:20.499+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:34:20.651+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:20.651+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:20.651+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:20.651+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:20.651+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:20.652+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:20.652+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:20.652+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:20.652+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:20.652+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:20.652+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:34:20.653+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.44921 +0000 UTC
Value: 21463
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.44921 +0000 UTC
Value: 39755
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.44921 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.44921 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.44921 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.44921 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.44921 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.44921 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.496312 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.490079 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.44921 +0000 UTC
Value: 2011
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:20.44921 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:50.474+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:34:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:34:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:34:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:34:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:34:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:34:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:34:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:34:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:34:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:34:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:34:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:34:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:34:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:34:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:34:50.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:34:50.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:34:50.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:34:50.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:34:50.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:34:50.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:34:50.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:34:50.596+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:50.596+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:50.596+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:50.596+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:50.596+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:50.596+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:50.596+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:50.596+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:50.596+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:50.596+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:34:50.596+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:34:50.596+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.445408 +0000 UTC
Value: 21478
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.445408 +0000 UTC
Value: 39762
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.445408 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.445408 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.445408 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.445408 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.445408 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.445408 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.486426 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.482656 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.445408 +0000 UTC
Value: 2020
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:04:50.445408 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:20.472+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:35:20.480+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:35:20.480+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:35:20.480+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:35:20.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:35:20.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:35:20.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:35:20.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:35:20.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:35:20.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:35:20.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:35:20.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:35:20.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:35:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:35:20.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:35:20.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:35:20.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:35:20.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:35:20.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:35:20.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:35:20.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:35:20.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:35:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:20.535+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:20.535+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:35:20.535+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.443804 +0000 UTC
Value: 21491
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.443804 +0000 UTC
Value: 39767
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.443804 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.443804 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.443804 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.443804 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.443804 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.443804 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.484746 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.48092 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.443804 +0000 UTC
Value: 2029
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:20.443804 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:50.464+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:35:50.472+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:35:50.472+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:35:50.472+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:35:50.472+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:35:50.472+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:35:50.472+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:35:50.472+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:35:50.472+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:35:50.472+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:35:50.472+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:35:50.472+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:35:50.472+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:35:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:35:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:35:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:35:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:35:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:35:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:35:50.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:35:50.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:35:50.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:35:50.483+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:50.483+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:50.483+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:50.483+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:50.483+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:50.483+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:50.483+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:50.483+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:50.483+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:50.483+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:35:50.483+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:35:50.483+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.443214 +0000 UTC
Value: 21506
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.443214 +0000 UTC
Value: 39774
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.443214 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.443214 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.443214 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.443214 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.443214 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.443214 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.476336 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.472631 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.443214 +0000 UTC
Value: 2038
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:05:50.443214 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:20.470+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:36:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:36:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:36:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:36:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:36:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:36:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:36:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:36:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:36:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:36:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:36:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:36:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:36:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:36:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:36:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:36:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:36:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:36:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:36:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:36:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:36:20.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:36:20.632+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:20.632+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:20.632+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:20.632+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:20.632+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:20.632+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:20.632+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:20.632+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:20.632+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:20.632+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:20.632+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:36:20.632+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.442932 +0000 UTC
Value: 21519
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.442932 +0000 UTC
Value: 39779
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.442932 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.442932 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.442932 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.442932 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.442932 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.442932 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.483083 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.479207 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.442932 +0000 UTC
Value: 2047
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:20.442932 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:20.669+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to IDLE	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:36:20.669+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to IDLE	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:36:21.231+0530	info	transport/http2_client.go:1646	[transport] [client-transport 0x14001aeab48] Closing: connection error: desc = "error reading from server: EOF"	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:36:21.232+0530	info	transport/controlbuf.go:580	[transport] [client-transport 0x14001aeab48] loopyWriter exiting with error: finished processing active streams while in draining mode	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:36:50.471+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:36:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:36:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:36:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:36:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:36:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:36:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:36:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:36:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:36:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:36:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:36:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:36:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:36:50.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:36:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:36:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:36:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:36:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:36:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:36:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:36:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:36:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:36:50.579+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:50.579+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:50.579+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:50.580+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:50.580+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:50.580+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:50.580+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:50.580+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:50.580+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:50.580+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:50.580+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:36:50.580+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:36:50.580+0530	info	grpc@v1.73.0/clientconn.go:1352	[core] [Channel #3 SubChannel #4]Subchannel picks a new address "otlp.nr-data.net:4317" to connect	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:36:50.580+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:36:50.580+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.44265 +0000 UTC
Value: 21534
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.44265 +0000 UTC
Value: 39786
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.44265 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.44265 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.44265 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.44265 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.44265 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.44265 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.483294 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.479174 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.44265 +0000 UTC
Value: 2056
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:06:50.44265 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:36:50.809+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to READY	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:36:50.809+0530	info	pickfirstleaf/pickfirstleaf.go:197	[pick-first-leaf-lb] [pick-first-leaf-lb 0x140011a4a20] SubConn 0x140017f01e0 reported connectivity state READY and the health listener is disabled. Transitioning SubConn to READY.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:36:50.810+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to READY	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:37:20.471+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:37:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:37:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:37:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:37:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:37:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:37:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:37:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:37:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:37:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:37:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:37:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:37:20.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:37:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:37:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:37:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:37:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:37:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:37:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:37:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:37:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:37:20.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:37:20.522+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:20.523+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:20.523+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:20.523+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:20.523+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:20.523+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:20.523+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:20.523+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:20.523+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:20.523+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:20.523+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:37:20.524+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.442325 +0000 UTC
Value: 21547
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.442325 +0000 UTC
Value: 39791
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.442325 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.442325 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.442325 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.442325 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.442325 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.442325 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.483016 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.47914 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.442325 +0000 UTC
Value: 2065
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:20.442325 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:50.469+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:37:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:37:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:37:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:37:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:37:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:37:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:37:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:37:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:37:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:37:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:37:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:37:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:37:50.480+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:37:50.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:37:50.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:37:50.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:37:50.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:37:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:37:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:37:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:37:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:37:50.671+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:50.671+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:50.671+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:50.671+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:50.671+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:50.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:50.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:50.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:50.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:50.672+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:37:50.672+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:37:50.673+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.44197 +0000 UTC
Value: 21562
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.44197 +0000 UTC
Value: 39798
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.44197 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.44197 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.44197 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.44197 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.44197 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.44197 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.480493 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.476196 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.44197 +0000 UTC
Value: 2074
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:07:50.44197 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:20.473+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:38:20.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:38:20.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:38:20.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:38:20.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:38:20.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:38:20.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:38:20.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:38:20.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:38:20.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:38:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:38:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:38:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:38:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:38:20.489+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:38:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:38:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:38:20.490+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:38:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:38:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:38:20.491+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:38:20.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:38:20.624+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:20.624+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:20.624+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:20.624+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:20.624+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:20.625+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:20.625+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:20.625+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:20.625+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:20.625+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:20.625+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:38:20.626+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.441692 +0000 UTC
Value: 21575
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.441692 +0000 UTC
Value: 39803
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.441692 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.441692 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.441692 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.441692 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.441692 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.441692 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.48911 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.482524 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.441692 +0000 UTC
Value: 2083
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:20.441692 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:49.440+0530	info	grpc@v1.73.0/resolver_wrapper.go:111	[core] [Channel #1]Closing the name resolver	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:49.440+0530	info	grpc@v1.73.0/balancer_wrapper.go:160	[core] [Channel #1]ccBalancerWrapper: closing	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:49.440+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #1]Channel Connectivity change to IDLE	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:49.440+0530	info	grpc@v1.73.0/clientconn.go:398	[core] [Channel #1]Channel entering idle mode	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:49.440+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #1 SubChannel #2]Subchannel Connectivity change to SHUTDOWN	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:49.440+0530	info	grpc@v1.73.0/clientconn.go:890	[core] [Channel #1 SubChannel #2]Subchannel deleted	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:49.440+0530	info	grpc@v1.73.0/clientconn.go:1584	[transport] [client-transport 0x140017798c8] GracefulClose called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:49.440+0530	info	transport/http2_client.go:1085	[transport] [client-transport 0x140017798c8] Closing: connection error: desc = "no active streams left to process while draining"	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:49.440+0530	info	transport/controlbuf.go:580	[transport] [client-transport 0x140017798c8] loopyWriter exiting with error: connection error: desc = "no active streams left to process while draining"	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:49.441+0530	info	grpc@v1.73.0/resolver_wrapper.go:111	[core] [Channel #7]Closing the name resolver	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:49.441+0530	info	grpc@v1.73.0/balancer_wrapper.go:160	[core] [Channel #7]ccBalancerWrapper: closing	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:49.441+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #7]Channel Connectivity change to IDLE	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:49.441+0530	info	grpc@v1.73.0/clientconn.go:398	[core] [Channel #7]Channel entering idle mode	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:49.441+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #7 SubChannel #8]Subchannel Connectivity change to SHUTDOWN	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:49.441+0530	info	grpc@v1.73.0/clientconn.go:890	[core] [Channel #7 SubChannel #8]Subchannel deleted	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:49.441+0530	info	grpc@v1.73.0/clientconn.go:1584	[transport] [client-transport 0x14001aea008] GracefulClose called	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:49.441+0530	info	transport/http2_client.go:1085	[transport] [client-transport 0x14001aea008] Closing: connection error: desc = "no active streams left to process while draining"	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:49.441+0530	info	transport/controlbuf.go:580	[transport] [client-transport 0x14001aea008] loopyWriter exiting with error: connection error: desc = "no active streams left to process while draining"	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:38:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:38:50.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:38:50.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:38:50.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:38:50.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:38:50.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:38:50.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:38:50.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:38:50.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:38:50.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:38:50.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:38:50.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:38:50.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:38:50.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:38:50.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:38:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:38:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:38:50.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:38:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:38:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:38:50.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:38:50.497+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:38:50.567+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:50.567+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:50.567+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:50.567+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:50.567+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:50.567+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:50.567+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:50.567+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:50.567+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:50.568+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:38:50.568+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:38:50.568+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.441392 +0000 UTC
Value: 21590
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.441392 +0000 UTC
Value: 39810
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.441392 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.441392 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.441392 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.441392 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.441392 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.441392 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.494171 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.488358 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.441392 +0000 UTC
Value: 2092
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:08:50.441392 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:20.480+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:39:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:39:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:39:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:39:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:39:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:39:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:39:20.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:39:20.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:39:20.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:39:20.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:39:20.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:39:20.488+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:39:20.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:39:20.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:39:20.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:39:20.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:39:20.492+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:39:20.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:39:20.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:39:20.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:39:20.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:39:20.512+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:20.512+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:20.512+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:20.512+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:20.512+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:20.512+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:20.512+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:20.513+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:20.513+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:20.513+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:20.513+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:39:20.514+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.441114 +0000 UTC
Value: 21603
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.441114 +0000 UTC
Value: 39815
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.441114 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.441114 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.441114 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.441114 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.441114 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.441114 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.491863 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.487774 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.441114 +0000 UTC
Value: 2101
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:20.441114 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:50.465+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:39:50.471+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:39:50.471+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:39:50.471+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:39:50.471+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:39:50.471+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:39:50.471+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:39:50.471+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:39:50.471+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:39:50.471+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:39:50.471+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:39:50.471+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:39:50.471+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:39:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:39:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:39:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:39:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:39:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:39:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:39:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:39:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:39:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:39:50.660+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:50.660+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:50.660+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:50.660+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:50.660+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:50.660+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:50.660+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:50.660+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:50.660+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:50.660+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:39:50.660+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:39:50.660+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.44068 +0000 UTC
Value: 21617
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.44068 +0000 UTC
Value: 39822
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.44068 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.44068 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.44068 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.44068 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.44068 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.44068 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.475847 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.47159 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.44068 +0000 UTC
Value: 2110
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:09:50.44068 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:20.470+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:40:20.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:40:20.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:40:20.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:40:20.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:40:20.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:40:20.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:40:20.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:40:20.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:40:20.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:40:20.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:40:20.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:40:20.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:40:20.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:40:20.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:40:20.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:40:20.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:40:20.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:40:20.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:40:20.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:40:20.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:40:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:40:20.610+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:20.610+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:20.610+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:20.610+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:20.610+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:20.610+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:20.610+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:20.610+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:20.610+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:20.610+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:20.610+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:40:20.611+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.440378 +0000 UTC
Value: 21630
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.440378 +0000 UTC
Value: 39827
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.440378 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.440378 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.440378 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.440378 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.440378 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.440378 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.481078 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.477125 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.440378 +0000 UTC
Value: 2119
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:20.440378 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:50.470+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:40:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:40:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:40:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:40:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:40:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:40:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:40:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:40:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:40:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:40:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:40:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:40:50.477+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:40:50.480+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:40:50.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:40:50.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:40:50.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:40:50.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:40:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:40:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:40:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:40:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:40:50.560+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:50.560+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:50.560+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:50.560+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:50.560+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:50.560+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:50.560+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:50.561+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:50.561+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:50.561+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:40:50.561+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:40:50.562+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.440074 +0000 UTC
Value: 21645
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.440074 +0000 UTC
Value: 39834
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.440074 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.440074 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.440074 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.440074 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.440074 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.440074 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.480705 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.476908 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.440074 +0000 UTC
Value: 2128
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:10:50.440074 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:20.470+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:41:20.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:41:20.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:41:20.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:41:20.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:41:20.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:41:20.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:41:20.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:41:20.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:41:20.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:41:20.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:41:20.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:41:20.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:41:20.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:41:20.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:41:20.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:41:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:41:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:41:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:41:20.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:41:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:41:20.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:41:20.503+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:20.503+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:20.503+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:20.503+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:20.503+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:20.503+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:20.504+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:20.504+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:20.504+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:20.504+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:20.504+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:41:20.505+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.439785 +0000 UTC
Value: 21658
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.439785 +0000 UTC
Value: 39839
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.439785 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.439785 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.439785 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.439785 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.439785 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.439785 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.482239 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.47856 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.439785 +0000 UTC
Value: 2137
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:20.439785 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:20.536+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to IDLE	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:41:20.537+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to IDLE	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:41:21.242+0530	info	transport/http2_client.go:1646	[transport] [client-transport 0x1400002e908] Closing: connection error: desc = "error reading from server: EOF"	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:41:21.242+0530	info	transport/controlbuf.go:594	[transport] [client-transport 0x1400002e908] loopyWriter exiting with error: finished processing active streams while in draining mode	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:41:50.470+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:41:50.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:41:50.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:41:50.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:41:50.478+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:41:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:41:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:41:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:41:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:41:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:41:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:41:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:41:50.479+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:41:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:41:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:41:50.485+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:41:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:41:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:41:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:41:50.486+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:41:50.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:41:50.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:41:50.649+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:50.649+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:50.649+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:50.649+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:50.649+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:50.649+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:50.649+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:50.649+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:50.649+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:50.649+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:50.649+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:41:50.649+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:41:50.649+0530	info	grpc@v1.73.0/clientconn.go:1352	[core] [Channel #3 SubChannel #4]Subchannel picks a new address "otlp.nr-data.net:4317" to connect	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:41:50.649+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to CONNECTING	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:41:50.650+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.439451 +0000 UTC
Value: 21673
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.439451 +0000 UTC
Value: 39846
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.439451 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.439451 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.439451 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.439451 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.439451 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.439451 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.484732 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.478872 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.439451 +0000 UTC
Value: 2146
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:11:50.439451 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:41:51.287+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to READY	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:41:51.287+0530	info	pickfirstleaf/pickfirstleaf.go:197	[pick-first-leaf-lb] [pick-first-leaf-lb 0x140011a4a20] SubConn 0x140017f01e0 reported connectivity state READY and the health listener is disabled. Transitioning SubConn to READY.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:41:51.287+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to READY	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:42:20.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:42:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:42:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:42:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:42:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:42:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:42:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:42:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:42:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:42:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:42:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:42:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:42:20.487+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:42:20.493+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:42:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:42:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:42:20.494+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:42:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:42:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:42:20.495+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:42:20.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:42:20.496+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:42:20.598+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:20.598+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:20.598+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:20.598+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:20.598+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:20.599+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:20.599+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:20.599+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:20.599+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:20.599+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:20.599+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:42:20.599+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.439159 +0000 UTC
Value: 21686
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.439159 +0000 UTC
Value: 39851
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.439159 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.439159 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.439159 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.439159 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.439159 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.439159 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.493578 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.487289 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.439159 +0000 UTC
Value: 2155
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:20.439159 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:50.468+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:109	Starting New Relic query performance metrics collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics"}
2025-07-10T14:42:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:194	Executing slow queries collection	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query": "\n\t\tSELECT \n\t\t\tpss.queryid AS query_id,\n\t\t\tLEFT(pss.query, 4095) AS query_text,\n\t\t\tpd.datname AS database_name,\n\t\t\tcurrent_schema() AS schema_name,\n\t\t\tpss.calls AS execution_count,\n\t\t\tROUND((pss.total_exec_time / pss.calls)::numeric, 3) AS avg_elapsed_time_ms,\n\t\t\tpss.shared_blks_read / pss.calls AS avg_disk_reads,\n\t\t\tpss.shared_blks_written / pss.calls AS avg_disk_writes,\n\t\t\tCASE\n\t\t\t\tWHEN pss.query ILIKE 'SELECT%' THEN 'SELECT'\n\t\t\t\tWHEN pss.query ILIKE 'INSERT%' THEN 'INSERT'\n\t\t\t\tWHEN pss.query ILIKE 'UPDATE%' THEN 'UPDATE'\n\t\t\t\tWHEN pss.query ILIKE 'DELETE%' THEN 'DELETE'\n\t\t\t\tELSE 'OTHER'\n\t\t\tEND AS statement_type,\n\t\t\tto_char(NOW() AT TIME ZONE 'UTC', 'YYYY-MM-DD\"T\"HH24:MI:SS\"Z\"') AS collection_timestamp\n\t\tFROM \n\t\t\tpg_stat_statements pss\n\t\tJOIN \n\t\t\tpg_database pd ON pss.dbid = pd.oid\n\t\tWHERE \n\t\t\tpd.datname IN ('testdb', 'postgres')\n\t\t\tAND pss.calls >= 1\n\t\t\tAND (pss.total_exec_time / pss.calls) >= 10\n\t\tORDER BY \n\t\t\tavg_elapsed_time_ms DESC\n\t\tLIMIT 100"}
2025-07-10T14:42:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "postgres", "execution_count": 3, "avg_elapsed_time_ms": 46705.434}
2025-07-10T14:42:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 35508.363}
2025-07-10T14:42:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 20014.432}
2025-07-10T14:42:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "database_name": "testdb", "execution_count": 6, "avg_elapsed_time_ms": 8823.1}
2025-07-10T14:42:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 144.601}
2025-07-10T14:42:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 143.521}
2025-07-10T14:42:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "database_name": "testdb", "execution_count": 3, "avg_elapsed_time_ms": 94.97}
2025-07-10T14:42:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 67.739}
2025-07-10T14:42:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "database_name": "postgres", "execution_count": 1, "avg_elapsed_time_ms": 44.676}
2025-07-10T14:42:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:221	Found slow query	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2194329260438961401", "database_name": "testdb", "execution_count": 1, "avg_elapsed_time_ms": 13.782}
2025-07-10T14:42:50.476+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:241	Slow query collection completed	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "slow_query_count": 11}
2025-07-10T14:42:50.481+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "440101247839410938", "error": "pq: there is no parameter $1"}
2025-07-10T14:42:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-8330292678256039428", "error": "pq: syntax error at or near \"DO\""}
2025-07-10T14:42:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "7679276192979657576", "error": "pq: there is no parameter $1"}
2025-07-10T14:42:50.482+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2920803561901199087", "error": "pq: there is no parameter $1"}
2025-07-10T14:42:50.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-680770601819606026", "error": "pq: syntax error at or near \"SERIAL\""}
2025-07-10T14:42:50.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-3404018605099167039", "error": "pq: there is no parameter $1"}
2025-07-10T14:42:50.483+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "-7843470278038126227", "error": "pq: syntax error at or near \"ANALYZE\""}
2025-07-10T14:42:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2572271098470785670", "error": "pq: syntax error at or near \"DATABASE\""}
2025-07-10T14:42:50.484+0530	debug	newrelicpostgresqlreceiver@v0.129.0/newrelic_performance.go:464	Failed to get execution plan	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "metrics", "query_id": "2947340716630300180", "error": "pq: there is no parameter $2"}
2025-07-10T14:42:50.544+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.commits	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:50.544+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:50.544+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.connection.max	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:50.544+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.database.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:50.544+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_reads	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:50.544+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_disk_writes	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:50.544+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.avg_elapsed_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:50.544+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.cpu_time	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:50.544+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.query.execution.count	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:50.544+0530	debug	prometheusexporter@v0.129.0/accumulator.go:82	accumulating metric: postgresql.rollbacks	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "prometheus", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:42:50.544+0530	info	Metrics	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 1, "metrics": 10, "data points": 55}
2025-07-10T14:42:50.544+0530	info	ResourceMetrics #0
Resource SchemaURL: 
ScopeMetrics #0
ScopeMetrics SchemaURL: 
InstrumentationScope github.com/open-telemetry/opentelemetry-collector-contrib/receiver/newrelicpostgresqlreceiver 0.129.0-dev
Metric #0
Descriptor:
     -> Name: postgresql.commits
     -> Description: The number of commits.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.439151 +0000 UTC
Value: 21701
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.439151 +0000 UTC
Value: 39858
Metric #1
Descriptor:
     -> Name: postgresql.connection.count
     -> Description: Number of user connections.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.439151 +0000 UTC
Value: 2
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.439151 +0000 UTC
Value: 1
Metric #2
Descriptor:
     -> Name: postgresql.connection.max
     -> Description: Maximum number of client connections allowed.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.439151 +0000 UTC
Value: 100
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.439151 +0000 UTC
Value: 100
Metric #3
Descriptor:
     -> Name: postgresql.database.count
     -> Description: Number of user databases.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: false
     -> AggregationTemporality: Unspecified
NumberDataPoints #0
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.439151 +0000 UTC
Value: 3
NumberDataPoints #1
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.439151 +0000 UTC
Value: 3
Metric #4
Descriptor:
     -> Name: postgresql.query.avg_disk_reads
     -> Description: Average number of disk reads per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 255.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 918.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 28.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 43.000000
Metric #5
Descriptor:
     -> Name: postgresql.query.avg_disk_writes
     -> Description: Average number of disk writes per query execution.
     -> Unit: 1
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 0.000000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 0.000000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 0.000000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 0.000000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 0.000000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 0.000000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 0.000000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 24.000000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 0.000000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 0.000000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 6.000000
Metric #6
Descriptor:
     -> Name: postgresql.query.avg_elapsed_time
     -> Description: Average execution time for the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 46705.434000
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 35508.363000
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 20014.432000
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 8823.100000
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 144.601000
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 143.521000
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 94.970000
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 67.739000
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 44.676000
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 13.782000
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 11.230000
Metric #7
Descriptor:
     -> Name: postgresql.query.cpu_time
     -> Description: CPU time consumed by the query in milliseconds.
     -> Unit: ms
     -> DataType: Gauge
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(9de2b22310490e3e53ca788f3ba250e1)
     -> postgresql.query.text: Str(
		SELECT 
			COALESCE(pss.queryid::text, md5(sa.query)) AS query_id,
			LEFT(sa.query, 4095) AS query_text,
			pd.datname AS database_name,
			md5(sa.query || NOW()::text) AS plan_id,
			0 AS cpu_time_ms,
			EXTRACT(EPOCH FROM (NOW() - sa.query_start)) * 1000 AS exec_time_ms,
			sa.query AS real_query_text
		FROM 
			pg_stat_activity sa
		LEFT JOIN 
			pg_stat_statements pss ON pss.query = sa.query AND pss.dbid = sa.datid
		LEFT JOIN 
			pg_database pd ON pd.oid = sa.datid
		WHERE 
			pd.datname IN ('testdb', 'postgres')
			AND sa.query IS NOT NULL
			AND sa.query != ''
			AND sa.state = 'active'
			AND sa.query NOT LIKE 'EXPLAIN (FORMAT JSON) %'
		LIMIT 100)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.48148 +0000 UTC
Value: 0.000000
Metric #8
Descriptor:
     -> Name: postgresql.query.execution.count
     -> Description: Number of times the query was executed.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 3
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(440101247839410938)
     -> postgresql.query.text: Str(SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 6
NumberDataPoints #2
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(-3404018605099167039)
     -> postgresql.query.text: Str(select * from pg_sleep($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 1
NumberDataPoints #3
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2947340716630300180)
     -> postgresql.query.text: Str(-- Keep the transaction open for blocking test
UPDATE test_lock_table SET id = $1 WHERE id = $2)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 6
NumberDataPoints #4
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-8330292678256039428)
     -> postgresql.query.text: Str(DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'slow_calculation') THEN
    PERFORM slow_calculation(50);
  END IF;
END $$)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 1
NumberDataPoints #5
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(7679276192979657576)
     -> postgresql.query.text: Str(SELECT slow_calculation($1))
     -> postgresql.statement.type: Str(SELECT)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 1
NumberDataPoints #6
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2920803561901199087)
     -> postgresql.query.text: Str(-- Create some slow queries to trigger slow query collection
SELECT pg_sleep($1))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 3
NumberDataPoints #7
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-7843470278038126227)
     -> postgresql.query.text: Str(ANALYZE)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 1
NumberDataPoints #8
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(2572271098470785670)
     -> postgresql.query.text: Str(CREATE DATABASE test_monitoring)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 1
NumberDataPoints #9
Data point attributes:
     -> postgresql.database.name: Str(testdb)
     -> postgresql.query.id: Str(2194329260438961401)
     -> postgresql.query.text: Str(-- This should be captured as a slow query now
CREATE TEMP TABLE test_table AS SELECT generate_series(1,1000) as id)
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 1
NumberDataPoints #10
Data point attributes:
     -> postgresql.database.name: Str(postgres)
     -> postgresql.query.id: Str(-680770601819606026)
     -> postgresql.query.text: Str(CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
))
     -> postgresql.statement.type: Str(OTHER)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.476192 +0000 UTC
Value: 1
Metric #9
Descriptor:
     -> Name: postgresql.rollbacks
     -> Description: The number of rollbacks.
     -> Unit: 1
     -> DataType: Sum
     -> IsMonotonic: true
     -> AggregationTemporality: Cumulative
NumberDataPoints #0
Data point attributes:
     -> postgresql.database.name: Str(testdb)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.439151 +0000 UTC
Value: 2164
NumberDataPoints #1
Data point attributes:
     -> postgresql.database.name: Str(postgres)
StartTimestamp: 2025-07-10 08:38:49.485661 +0000 UTC
Timestamp: 2025-07-10 09:12:50.439151 +0000 UTC
Value: 203
	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-10T14:43:14.958+0530	info	otelcol@v0.129.1-0.20250707130321-ac9adbf016bf/collector.go:358	Received signal from OS	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "signal": "terminated"}
2025-07-10T14:43:14.958+0530	info	service@v0.129.1-0.20250707130321-ac9adbf016bf/service.go:322	Starting shutdown...	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}}
2025-07-10T14:43:14.958+0530	info	newrelicpostgresqlreceiver@v0.129.0/factory.go:160	Shutting down New Relic PostgreSQL logs receiver	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "otelcol.component.id": "newrelicpostgresql", "otelcol.component.kind": "receiver", "otelcol.signal": "logs"}
2025-07-10T14:43:14.958+0530	info	grpc@v1.73.0/server.go:822	[core] [Server #5 ListenSocket #6]ListenSocket deleted	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:43:14.959+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #7]Channel Connectivity change to SHUTDOWN	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:43:14.959+0530	info	grpc@v1.73.0/resolver_wrapper.go:111	[core] [Channel #7]Closing the name resolver	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:43:14.959+0530	info	grpc@v1.73.0/balancer_wrapper.go:160	[core] [Channel #7]ccBalancerWrapper: closing	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:43:14.959+0530	info	grpc@v1.73.0/clientconn.go:1183	[core] [Channel #7]Channel deleted	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:43:14.960+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #3]Channel Connectivity change to SHUTDOWN	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:43:14.960+0530	info	grpc@v1.73.0/resolver_wrapper.go:111	[core] [Channel #3]Closing the name resolver	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:43:14.960+0530	info	grpc@v1.73.0/balancer_wrapper.go:160	[core] [Channel #3]ccBalancerWrapper: closing	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:43:14.960+0530	info	grpc@v1.73.0/clientconn.go:1233	[core] [Channel #3 SubChannel #4]Subchannel Connectivity change to SHUTDOWN	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:43:14.960+0530	info	grpc@v1.73.0/clientconn.go:1179	[core] [Channel #3 SubChannel #4]Subchannel deleted	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:43:14.960+0530	info	grpc@v1.73.0/clientconn.go:1593	[transport] [client-transport 0x14001e2e488] Closing: rpc error: code = Canceled desc = grpc: the client connection is closing	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:43:14.960+0530	info	transport/controlbuf.go:580	[transport] [client-transport 0x14001e2e488] loopyWriter exiting with error: rpc error: code = Canceled desc = grpc: the client connection is closing	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:43:14.961+0530	info	grpc@v1.73.0/clientconn.go:1183	[core] [Channel #3]Channel deleted	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:43:14.964+0530	info	grpc@v1.73.0/clientconn.go:563	[core] [Channel #1]Channel Connectivity change to SHUTDOWN	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:43:14.964+0530	info	grpc@v1.73.0/resolver_wrapper.go:111	[core] [Channel #1]Closing the name resolver	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:43:14.964+0530	info	grpc@v1.73.0/balancer_wrapper.go:160	[core] [Channel #1]ccBalancerWrapper: closing	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:43:14.964+0530	info	grpc@v1.73.0/clientconn.go:1183	[core] [Channel #1]Channel deleted	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}, "grpc_log": true}
2025-07-10T14:43:14.964+0530	info	extensions/extensions.go:69	Stopping extensions...	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}}
2025-07-10T14:43:14.964+0530	info	service@v0.129.1-0.20250707130321-ac9adbf016bf/service.go:336	Shutdown complete.	{"resource": {"service.instance.id": "52394ef5-91df-4927-bdbb-ed57a02e263c", "service.name": "otelcontribcol", "service.version": "0.129.0-dev"}}
